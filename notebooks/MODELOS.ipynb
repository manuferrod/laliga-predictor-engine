{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EzFV5f4-L4Ox"
      },
      "outputs": [],
      "source": [
        "# --- Parámetros (se pueden sobreescribir en CI) ---\n",
        "RUN_DATE = \"2025-09-15\"\n",
        "SEASON   = \"2025_26\"\n",
        "MATCHDAY = None\n",
        "MODEL_VERSION = \"xgb-local\"\n",
        "\n",
        "# --- Rutas coherentes local/CI ---\n",
        "from pathlib import Path\n",
        "ROOT   = Path.cwd()\n",
        "DATA   = ROOT / \"data\"\n",
        "RAW    = DATA / \"01_raw\"\n",
        "PROC   = DATA / \"02_processed\"\n",
        "FEAT   = DATA / \"03_features\"\n",
        "MODELS = DATA / \"04_models\"\n",
        "OUT    = ROOT / \"outputs\"\n",
        "\n",
        "for p in [RAW, PROC, FEAT, MODELS, OUT]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Reproducibilidad\n",
        "import random, numpy as np\n",
        "random.seed(42); np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZs2bMOYL7I7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, json\n",
        "\n",
        "def load_feat(name: str):\n",
        "    return pd.read_parquet(FEAT / name)\n",
        "\n",
        "def save_model(obj, name: str):\n",
        "    from joblib import dump\n",
        "    MODELS.mkdir(parents=True, exist_ok=True)\n",
        "    dump(obj, MODELS / name)\n",
        "\n",
        "def save_predictions(df: pd.DataFrame, name: str = \"predictions_next.csv\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(OUT / name, index=False)\n",
        "\n",
        "def save_json(obj, name: str = \"metrics_overview.json\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    with open(OUT / name, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny_spsZP25IM"
      },
      "source": [
        "# **MODELOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6i6bPn0tuc4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-LZWUpHKgiI"
      },
      "source": [
        "# **PREDICCIÓN: Logistic Regression multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "oqodyksQuVIn",
        "outputId": "8a9240c1-9c58-4f0e-aec2-3a53c5d08330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leído: /content/data/03_features/df_final.parquet · filas= 7271 · cols= 74\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-62393532-e015-48d6-a632-863fa06a0e80\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B365A</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365H</th>\n",
              "      <th>Date</th>\n",
              "      <th>FTR</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>h_elo</th>\n",
              "      <th>a_elo</th>\n",
              "      <th>Season</th>\n",
              "      <th>...</th>\n",
              "      <th>a_squad_size_prev_season</th>\n",
              "      <th>a_pct_foreigners_prev_season</th>\n",
              "      <th>has_xg_data</th>\n",
              "      <th>target</th>\n",
              "      <th>home_playstyle_defensivo</th>\n",
              "      <th>home_playstyle_equilibrado</th>\n",
              "      <th>home_playstyle_ofensivo</th>\n",
              "      <th>away_playstyle_defensivo</th>\n",
              "      <th>away_playstyle_equilibrado</th>\n",
              "      <th>away_playstyle_ofensivo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.00</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2006-08-26</td>\n",
              "      <td>H</td>\n",
              "      <td>valencia</td>\n",
              "      <td>betis</td>\n",
              "      <td>1857.375122</td>\n",
              "      <td>1726.076904</td>\n",
              "      <td>2006</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>D</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1755.359253</td>\n",
              "      <td>1701.137573</td>\n",
              "      <td>2006</td>\n",
              "      <td>...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>22.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 74 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62393532-e015-48d6-a632-863fa06a0e80')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62393532-e015-48d6-a632-863fa06a0e80 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62393532-e015-48d6-a632-863fa06a0e80');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fb57f03d-40d0-46bc-8dfb-fb51603fa897\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb57f03d-40d0-46bc-8dfb-fb51603fa897')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fb57f03d-40d0-46bc-8dfb-fb51603fa897 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   B365A  B365D  B365H        Date FTR HomeTeam_norm AwayTeam_norm  \\\n",
              "0   6.00    3.6   1.57  2006-08-26   H      valencia         betis   \n",
              "1   3.75    3.2   2.00  2006-08-27   D    ath bilbao      sociedad   \n",
              "\n",
              "         h_elo        a_elo  Season  ...  a_squad_size_prev_season  \\\n",
              "0  1857.375122  1726.076904    2006  ...                      33.0   \n",
              "1  1755.359253  1701.137573    2006  ...                      31.0   \n",
              "\n",
              "   a_pct_foreigners_prev_season  has_xg_data  target  \\\n",
              "0                         24.24            0     2.0   \n",
              "1                         22.58            0     1.0   \n",
              "\n",
              "   home_playstyle_defensivo  home_playstyle_equilibrado  \\\n",
              "0                     False                       False   \n",
              "1                     False                        True   \n",
              "\n",
              "   home_playstyle_ofensivo  away_playstyle_defensivo  \\\n",
              "0                     True                      True   \n",
              "1                    False                     False   \n",
              "\n",
              "   away_playstyle_equilibrado  away_playstyle_ofensivo  \n",
              "0                       False                    False  \n",
              "1                        True                    False  \n",
              "\n",
              "[2 rows x 74 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)\n",
        "\n",
        "print(\"Leído:\", IN_PATH, \"· filas=\", len(df), \"· cols=\", df.shape[1])\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9p6IXV2flpz"
      },
      "source": [
        "Sin SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "YBqo8IsxMfij",
        "outputId": "940d018f-6164-49d5-fe12-7a6e7896320f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[BASE] partidos a predecir: 10 en 2025-09-19–2025-09-21\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"Exportado BASE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-19\",\n        \"max\": \"2025-09-21\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2025-09-19\",\n          \"2025-09-20\",\n          \"2025-09-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"mallorca\",\n          \"girona\",\n          \"valencia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ath madrid\",\n          \"levante\",\n          \"ath bilbao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118322155930233,\n        \"min\": 1.22,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          1.9,\n          3.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4406884928163108,\n        \"min\": 3.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.1,\n          3.5,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0604511286918323,\n        \"min\": 1.75,\n        \"max\": 11.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.75,\n          3.9,\n          2.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"H\",\n          \"D\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21865478734963248,\n        \"min\": 0.20392756281958432,\n        \"max\": 0.8182598556244115,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.20392756281958432,\n          0.406478752052089,\n          0.23310303282761966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0999521160526657,\n        \"min\": 0.12938660504749738,\n        \"max\": 0.4344616553637417,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3091760384872759,\n          0.3508930240460812,\n          0.4344616553637417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1330655131474865,\n        \"min\": 0.0513281975903017,\n        \"max\": 0.48689639869313983,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48689639869313983,\n          0.24262822390182973,\n          0.3324353118086386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18608518362988613,\n        \"min\": 0.1891891891891892,\n        \"max\": 0.7780921584478578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1891891891891892,\n          0.4926019487549621,\n          0.2964905203711174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06574690146674969,\n        \"min\": 0.13561034761519808,\n        \"max\": 0.3162565550625252,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.27027027027027023,\n          0.2674124864669794,\n          0.3162565550625252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1362471014572106,\n        \"min\": 0.08629749393694423,\n        \"max\": 0.5405405405405405,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5405405405405405,\n          0.23998556477805852,\n          0.3872529245663574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0068431771743474945,\n        \"min\": 1.0534383649137746,\n        \"max\": 1.0725806451612903,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0571428571428572,\n          1.0684403315982263,\n          1.0539965986394557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-17392db0-606e-46ab-a99b-67ba211d18e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>betis</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>0.323314</td>\n",
              "      <td>0.268144</td>\n",
              "      <td>0.460026</td>\n",
              "      <td>0.304211</td>\n",
              "      <td>0.235763</td>\n",
              "      <td>1.060386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>girona</td>\n",
              "      <td>levante</td>\n",
              "      <td>1.90</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.90</td>\n",
              "      <td>H</td>\n",
              "      <td>0.406479</td>\n",
              "      <td>0.350893</td>\n",
              "      <td>0.242628</td>\n",
              "      <td>0.492602</td>\n",
              "      <td>0.267412</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>1.068440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.811867</td>\n",
              "      <td>0.136805</td>\n",
              "      <td>0.051328</td>\n",
              "      <td>0.778092</td>\n",
              "      <td>0.135610</td>\n",
              "      <td>0.086297</td>\n",
              "      <td>1.053438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>alaves</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.308216</td>\n",
              "      <td>0.392619</td>\n",
              "      <td>0.299165</td>\n",
              "      <td>0.388471</td>\n",
              "      <td>0.300752</td>\n",
              "      <td>0.310777</td>\n",
              "      <td>1.072581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.10</td>\n",
              "      <td>5.75</td>\n",
              "      <td>H</td>\n",
              "      <td>0.607126</td>\n",
              "      <td>0.262557</td>\n",
              "      <td>0.130317</td>\n",
              "      <td>0.610032</td>\n",
              "      <td>0.227646</td>\n",
              "      <td>0.162322</td>\n",
              "      <td>1.071410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>valencia</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>D</td>\n",
              "      <td>0.233103</td>\n",
              "      <td>0.434462</td>\n",
              "      <td>0.332435</td>\n",
              "      <td>0.296491</td>\n",
              "      <td>0.316257</td>\n",
              "      <td>0.387253</td>\n",
              "      <td>1.053997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>elche</td>\n",
              "      <td>oviedo</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.10</td>\n",
              "      <td>H</td>\n",
              "      <td>0.373651</td>\n",
              "      <td>0.349079</td>\n",
              "      <td>0.277270</td>\n",
              "      <td>0.458015</td>\n",
              "      <td>0.312977</td>\n",
              "      <td>0.229008</td>\n",
              "      <td>1.065041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.10</td>\n",
              "      <td>H</td>\n",
              "      <td>0.400853</td>\n",
              "      <td>0.322284</td>\n",
              "      <td>0.276864</td>\n",
              "      <td>0.410020</td>\n",
              "      <td>0.285772</td>\n",
              "      <td>0.304208</td>\n",
              "      <td>1.060394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.75</td>\n",
              "      <td>A</td>\n",
              "      <td>0.203928</td>\n",
              "      <td>0.309176</td>\n",
              "      <td>0.486896</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>1.057143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>getafe</td>\n",
              "      <td>1.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.818260</td>\n",
              "      <td>0.129387</td>\n",
              "      <td>0.052354</td>\n",
              "      <td>0.750988</td>\n",
              "      <td>0.150198</td>\n",
              "      <td>0.098814</td>\n",
              "      <td>1.065263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17392db0-606e-46ab-a99b-67ba211d18e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17392db0-606e-46ab-a99b-67ba211d18e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17392db0-606e-46ab-a99b-67ba211d18e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cf0908f8-7d82-4527-b8f1-efb03a7f16b0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf0908f8-7d82-4527-b8f1-efb03a7f16b0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cf0908f8-7d82-4527-b8f1-efb03a7f16b0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Date HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred    Prob_H  \\\n",
              "0  2025-09-19         betis      sociedad   2.05   3.10   4.00    H  0.408542   \n",
              "1  2025-09-20        girona       levante   1.90   3.50   3.90    H  0.406479   \n",
              "2  2025-09-20   real madrid       espanol   1.22   7.00  11.00    H  0.811867   \n",
              "3  2025-09-20        alaves       sevilla   2.40   3.10   3.00    D  0.308216   \n",
              "4  2025-09-20    villarreal       osasuna   1.53   4.10   5.75    H  0.607126   \n",
              "5  2025-09-20      valencia    ath bilbao   3.20   3.00   2.45    D  0.233103   \n",
              "6  2025-09-21         elche        oviedo   2.05   3.00   4.10    H  0.373651   \n",
              "7  2025-09-21     vallecano         celta   2.30   3.30   3.10    H  0.400853   \n",
              "8  2025-09-21      mallorca    ath madrid   5.00   3.50   1.75    A  0.203928   \n",
              "9  2025-09-21     barcelona        getafe   1.25   6.25   9.50    H  0.818260   \n",
              "\n",
              "     Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.323314  0.268144  0.460026  0.304211  0.235763   1.060386  \n",
              "1  0.350893  0.242628  0.492602  0.267412  0.239986   1.068440  \n",
              "2  0.136805  0.051328  0.778092  0.135610  0.086297   1.053438  \n",
              "3  0.392619  0.299165  0.388471  0.300752  0.310777   1.072581  \n",
              "4  0.262557  0.130317  0.610032  0.227646  0.162322   1.071410  \n",
              "5  0.434462  0.332435  0.296491  0.316257  0.387253   1.053997  \n",
              "6  0.349079  0.277270  0.458015  0.312977  0.229008   1.065041  \n",
              "7  0.322284  0.276864  0.410020  0.285772  0.304208   1.060394  \n",
              "8  0.309176  0.486896  0.189189  0.270270  0.540541   1.057143  \n",
              "9  0.129387  0.052354  0.750988  0.150198  0.098814   1.065263  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exportado BASE en: /content/outputs\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (BASELINE, sin SMOTE) + B365 + export (sin df_old)\n",
        "# =========================\n",
        "\n",
        "# --- Parámetros del rango a predecir ---\n",
        "PRED_SEASON = 2025\n",
        "start_date  = pd.to_datetime(\"2025-09-19\").date()\n",
        "end_date    = pd.to_datetime(\"2025-09-21\").date()\n",
        "\n",
        "# --- Normaliza fechas en df (df_final ya cargado) ---\n",
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "# --- Índices a predecir (orden estable por fecha+índice) ---\n",
        "mask_pred = (\n",
        "    (df[\"Season\"] == PRED_SEASON) &\n",
        "    (df[\"Date\"] >= start_date) &\n",
        "    (df[\"Date\"] <= end_date)\n",
        ")\n",
        "pred_idx_sorted = (\n",
        "    df.loc[mask_pred]\n",
        "      .assign(_idx=lambda x: x.index)\n",
        "      .sort_values([\"Date\",\"_idx\"]).index.tolist()\n",
        ")\n",
        "print(f\"[BASE] partidos a predecir: {len(pred_idx_sorted)} en {start_date}–{end_date}\")\n",
        "\n",
        "# --- X,y evitando fugas (añadimos los nombres para NO usarlos como features) ---\n",
        "drop_cols = [\n",
        "    'FTR','target','Date','has_xg_data','overround','pimp2','B365D',\n",
        "    'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "    'HomeTeam_norm','AwayTeam_norm',  # <- NUEVO: excluir nombres del modelo\n",
        "    'row_id'                          # <- por si existiera\n",
        "]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df[\"target\"]\n",
        "\n",
        "mask_train = (~mask_pred) & (y.notna())\n",
        "X_train = X.loc[mask_train].copy()\n",
        "y_train = y.loc[mask_train].astype(int)\n",
        "\n",
        "# X de predicción en el MISMO orden que exportaremos\n",
        "X_pred  = X.loc[pred_idx_sorted].copy()\n",
        "\n",
        "# quitar 'Season' si queda y alinear columnas\n",
        "for D in (X_train, X_pred):\n",
        "    if \"Season\" in D.columns:\n",
        "        D.drop(columns=[\"Season\"], inplace=True)\n",
        "X_pred = X_pred.reindex(columns=X_train.columns, fill_value=np.nan)\n",
        "\n",
        "# --- Modelo baseline ---\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# --- Predicción (ya en orden final) ---\n",
        "proba_pred  = pipe.predict_proba(X_pred)\n",
        "pred_labels = pipe.predict(X_pred)\n",
        "\n",
        "# map de clases a 1X2\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes    = list(pipe.named_steps[\"logreg\"].classes_)  # e.g. [0,1,2]\n",
        "pred_1x2   = pd.Series(pred_labels).map(class_map).values\n",
        "\n",
        "# probabilidades por H/D/A robustas a orden de clases\n",
        "proba_df = pd.DataFrame(proba_pred, columns=[class_map[c] for c in classes])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df.columns:\n",
        "        proba_df[lab] = np.nan\n",
        "proba_df = proba_df[[\"H\",\"D\",\"A\"]].reset_index(drop=True)\n",
        "\n",
        "# --- Nombres, cuotas y fechas directamente de df (ordenadas como pred_idx_sorted) ---\n",
        "need_cols = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "missing = [c for c in need_cols if c not in df.columns]\n",
        "assert not missing, f\"Faltan columnas en df_final: {missing}\"\n",
        "\n",
        "meta_ord = df.loc[pred_idx_sorted, need_cols].copy().reset_index(drop=True)\n",
        "\n",
        "# probabilidades implícitas y overround\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / meta_ord[[\"B365H\",\"B365D\",\"B365A\"]]\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "# --- Resultado final + export ---\n",
        "out_base = pd.concat([\n",
        "    meta_ord[[\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]],\n",
        "    pd.Series(pred_1x2, name=\"Pred\"),\n",
        "    proba_df.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1)\n",
        "\n",
        "# Asegura carpeta OUT\n",
        "try:\n",
        "    OUT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "    OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "# con sufijo (histórico)\n",
        "out_base.to_csv( OUT / f\"predictions_{suffix}_base.csv\", index=False)\n",
        "out_base.to_json(OUT / f\"predictions_{suffix}_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "# “current” (para la app)\n",
        "out_base.to_csv( OUT / \"predictions_current_base.csv\", index=False)\n",
        "out_base.to_json(OUT / \"predictions_current_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_base.head(10))\n",
        "print(\"Exportado BASE en:\", OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCI5w60foc4"
      },
      "source": [
        "Con SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "IZXKDk_DNuSg",
        "outputId": "3b0cde3a-bded-44e1-cb92-7af7f953faed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SMOTE] partidos a predecir: 10 en 2025-09-19–2025-09-21\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"print(\\\"Exportado SMOTE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-19\",\n        \"max\": \"2025-09-21\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2025-09-19\",\n          \"2025-09-20\",\n          \"2025-09-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"mallorca\",\n          \"girona\",\n          \"valencia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ath madrid\",\n          \"levante\",\n          \"ath bilbao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118322155930233,\n        \"min\": 1.22,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          1.9,\n          3.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4406884928163108,\n        \"min\": 3.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.1,\n          3.5,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0604511286918323,\n        \"min\": 1.75,\n        \"max\": 11.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.75,\n          3.9,\n          2.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\",\n          \"H\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22396364440953034,\n        \"min\": 0.12373772626332337,\n        \"max\": 0.7239602733272985,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.12373772626332337,\n          0.2754307517377617,\n          0.13800143759945918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11601158650948261,\n        \"min\": 0.21172916243315967,\n        \"max\": 0.5507587425518293,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4006916206079566,\n          0.4494038023478946,\n          0.5282017981855056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12564685257410635,\n        \"min\": 0.06431056423954178,\n        \"max\": 0.47557065312872,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.47557065312872,\n          0.2751654459143438,\n          0.3337967642150351\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18608518362988613,\n        \"min\": 0.1891891891891892,\n        \"max\": 0.7780921584478578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1891891891891892,\n          0.4926019487549621,\n          0.2964905203711174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06574690146674969,\n        \"min\": 0.13561034761519808,\n        \"max\": 0.3162565550625252,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.27027027027027023,\n          0.2674124864669794,\n          0.3162565550625252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1362471014572106,\n        \"min\": 0.08629749393694423,\n        \"max\": 0.5405405405405405,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5405405405405405,\n          0.23998556477805852,\n          0.3872529245663574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0068431771743474945,\n        \"min\": 1.0534383649137746,\n        \"max\": 1.0725806451612903,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0571428571428572,\n          1.0684403315982263,\n          1.0539965986394557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7749ddf2-b9a2-41c0-b5ce-26584a26d8f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>betis</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.247164</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>0.284345</td>\n",
              "      <td>0.460026</td>\n",
              "      <td>0.304211</td>\n",
              "      <td>0.235763</td>\n",
              "      <td>1.060386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>girona</td>\n",
              "      <td>levante</td>\n",
              "      <td>1.90</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.90</td>\n",
              "      <td>D</td>\n",
              "      <td>0.275431</td>\n",
              "      <td>0.449404</td>\n",
              "      <td>0.275165</td>\n",
              "      <td>0.492602</td>\n",
              "      <td>0.267412</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>1.068440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.723960</td>\n",
              "      <td>0.211729</td>\n",
              "      <td>0.064311</td>\n",
              "      <td>0.778092</td>\n",
              "      <td>0.135610</td>\n",
              "      <td>0.086297</td>\n",
              "      <td>1.053438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>alaves</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.179639</td>\n",
              "      <td>0.550759</td>\n",
              "      <td>0.269602</td>\n",
              "      <td>0.388471</td>\n",
              "      <td>0.300752</td>\n",
              "      <td>0.310777</td>\n",
              "      <td>1.072581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.10</td>\n",
              "      <td>5.75</td>\n",
              "      <td>H</td>\n",
              "      <td>0.481312</td>\n",
              "      <td>0.348460</td>\n",
              "      <td>0.170228</td>\n",
              "      <td>0.610032</td>\n",
              "      <td>0.227646</td>\n",
              "      <td>0.162322</td>\n",
              "      <td>1.071410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>valencia</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>D</td>\n",
              "      <td>0.138001</td>\n",
              "      <td>0.528202</td>\n",
              "      <td>0.333797</td>\n",
              "      <td>0.296491</td>\n",
              "      <td>0.316257</td>\n",
              "      <td>0.387253</td>\n",
              "      <td>1.053997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>elche</td>\n",
              "      <td>oviedo</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.254901</td>\n",
              "      <td>0.422445</td>\n",
              "      <td>0.322654</td>\n",
              "      <td>0.458015</td>\n",
              "      <td>0.312977</td>\n",
              "      <td>0.229008</td>\n",
              "      <td>1.065041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.243360</td>\n",
              "      <td>0.459598</td>\n",
              "      <td>0.297042</td>\n",
              "      <td>0.410020</td>\n",
              "      <td>0.285772</td>\n",
              "      <td>0.304208</td>\n",
              "      <td>1.060394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.75</td>\n",
              "      <td>A</td>\n",
              "      <td>0.123738</td>\n",
              "      <td>0.400692</td>\n",
              "      <td>0.475571</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>1.057143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>getafe</td>\n",
              "      <td>1.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>0.218309</td>\n",
              "      <td>0.065642</td>\n",
              "      <td>0.750988</td>\n",
              "      <td>0.150198</td>\n",
              "      <td>0.098814</td>\n",
              "      <td>1.065263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7749ddf2-b9a2-41c0-b5ce-26584a26d8f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7749ddf2-b9a2-41c0-b5ce-26584a26d8f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7749ddf2-b9a2-41c0-b5ce-26584a26d8f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-236fa284-abe7-4020-ba2d-ba37b3dc73f7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-236fa284-abe7-4020-ba2d-ba37b3dc73f7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-236fa284-abe7-4020-ba2d-ba37b3dc73f7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         Date HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred    Prob_H  \\\n",
              "0  2025-09-19         betis      sociedad   2.05   3.10   4.00    D  0.247164   \n",
              "1  2025-09-20        girona       levante   1.90   3.50   3.90    D  0.275431   \n",
              "2  2025-09-20   real madrid       espanol   1.22   7.00  11.00    H  0.723960   \n",
              "3  2025-09-20        alaves       sevilla   2.40   3.10   3.00    D  0.179639   \n",
              "4  2025-09-20    villarreal       osasuna   1.53   4.10   5.75    H  0.481312   \n",
              "5  2025-09-20      valencia    ath bilbao   3.20   3.00   2.45    D  0.138001   \n",
              "6  2025-09-21         elche        oviedo   2.05   3.00   4.10    D  0.254901   \n",
              "7  2025-09-21     vallecano         celta   2.30   3.30   3.10    D  0.243360   \n",
              "8  2025-09-21      mallorca    ath madrid   5.00   3.50   1.75    A  0.123738   \n",
              "9  2025-09-21     barcelona        getafe   1.25   6.25   9.50    H  0.716049   \n",
              "\n",
              "     Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.468492  0.284345  0.460026  0.304211  0.235763   1.060386  \n",
              "1  0.449404  0.275165  0.492602  0.267412  0.239986   1.068440  \n",
              "2  0.211729  0.064311  0.778092  0.135610  0.086297   1.053438  \n",
              "3  0.550759  0.269602  0.388471  0.300752  0.310777   1.072581  \n",
              "4  0.348460  0.170228  0.610032  0.227646  0.162322   1.071410  \n",
              "5  0.528202  0.333797  0.296491  0.316257  0.387253   1.053997  \n",
              "6  0.422445  0.322654  0.458015  0.312977  0.229008   1.065041  \n",
              "7  0.459598  0.297042  0.410020  0.285772  0.304208   1.060394  \n",
              "8  0.400692  0.475571  0.189189  0.270270  0.540541   1.057143  \n",
              "9  0.218309  0.065642  0.750988  0.150198  0.098814   1.065263  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exportado SMOTE en: /content/outputs\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (SMOTE) + B365 + export (sin df_old)\n",
        "# =========================\n",
        "\n",
        "# --- Parámetros del rango a predecir (usa los mismos que en baseline) ---\n",
        "PRED_SEASON = 2025\n",
        "start_date  = pd.to_datetime(\"2025-09-19\").date()\n",
        "end_date    = pd.to_datetime(\"2025-09-21\").date()\n",
        "\n",
        "# --- Normaliza fechas en df (df_final ya cargado) ---\n",
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "# --- Índices a predecir (orden estable por fecha+índice) ---\n",
        "mask_pred = (\n",
        "    (df[\"Season\"] == PRED_SEASON) &\n",
        "    (df[\"Date\"] >= start_date) &\n",
        "    (df[\"Date\"] <= end_date)\n",
        ")\n",
        "pred_idx_sorted = (\n",
        "    df.loc[mask_pred]\n",
        "      .assign(_idx=lambda x: x.index)\n",
        "      .sort_values([\"Date\",\"_idx\"]).index.tolist()\n",
        ")\n",
        "print(f\"[SMOTE] partidos a predecir: {len(pred_idx_sorted)} en {start_date}–{end_date}\")\n",
        "\n",
        "# --- X,y evitando fugas (excluye nombres de equipos de las features) ---\n",
        "drop_cols = [\n",
        "    'FTR','target','Date','has_xg_data','overround','pimp2','B365D',\n",
        "    'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "    'HomeTeam_norm','AwayTeam_norm',  # <- excluir nombres del modelo\n",
        "    'row_id'\n",
        "]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df[\"target\"]\n",
        "\n",
        "mask_train = (~mask_pred) & (y.notna())\n",
        "X_train = X.loc[mask_train].copy()\n",
        "y_train = y.loc[mask_train].astype(int)\n",
        "\n",
        "# X de predicción en el MISMO orden de export\n",
        "X_pred  = X.loc[pred_idx_sorted].copy()\n",
        "\n",
        "# quitar 'Season' si queda y alinear columnas\n",
        "for D in (X_train, X_pred):\n",
        "    if \"Season\" in D.columns:\n",
        "        D.drop(columns=[\"Season\"], inplace=True)\n",
        "X_pred = X_pred.reindex(columns=X_train.columns, fill_value=np.nan)\n",
        "\n",
        "# --- Modelo SMOTE ---\n",
        "pipe_sm = ImbPipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"smote\",   SMOTE(random_state=42)),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"saga\", penalty=\"l2\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe_sm.fit(X_train, y_train)\n",
        "\n",
        "# --- Predicción (ya en orden final) ---\n",
        "proba_pred_sm  = pipe_sm.predict_proba(X_pred)\n",
        "pred_labels_sm = pipe_sm.predict(X_pred)\n",
        "\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes_sm = list(pipe_sm.named_steps[\"logreg\"].classes_)\n",
        "pred_1x2_sm = pd.Series(pred_labels_sm).map(class_map).values\n",
        "\n",
        "proba_df_sm = pd.DataFrame(proba_pred_sm, columns=[class_map[c] for c in classes_sm])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df_sm.columns:\n",
        "        proba_df_sm[lab] = np.nan\n",
        "proba_df_sm = proba_df_sm[[\"H\",\"D\",\"A\"]].reset_index(drop=True)\n",
        "\n",
        "# --- Nombres, cuotas y fechas directamente de df (orden pred_idx_sorted) ---\n",
        "need_cols = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "missing = [c for c in need_cols if c not in df.columns]\n",
        "assert not missing, f\"Faltan columnas en df_final: {missing}\"\n",
        "\n",
        "meta_ord = df.loc[pred_idx_sorted, need_cols].copy().reset_index(drop=True)\n",
        "\n",
        "# probabilidades implícitas y overround\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / meta_ord[[\"B365H\",\"B365D\",\"B365A\"]]\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "# --- Resultado final + export ---\n",
        "out_sm = pd.concat([\n",
        "    meta_ord[[\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]],\n",
        "    pd.Series(pred_1x2_sm, name=\"Pred\"),\n",
        "    proba_df_sm.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1)\n",
        "\n",
        "# Asegura carpeta OUT (misma que baseline)\n",
        "try:\n",
        "    OUT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "    OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "# con sufijo (histórico)\n",
        "out_sm.to_csv( OUT / f\"predictions_{suffix}_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / f\"predictions_{suffix}_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "# “current” (para la app)\n",
        "out_sm.to_csv( OUT / \"predictions_current_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / \"predictions_current_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_sm.head(10))\n",
        "print(\"Exportado SMOTE en:\", OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AUraRaeqPH_"
      },
      "source": [
        "# **EVALUACIÓN HISTÓRICA: Logistic Regression multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Iqi91Ub6gI-T"
      },
      "outputs": [],
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Shn3mE9kGbe"
      },
      "source": [
        "Sin SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPRUPbHqTjP9",
        "outputId": "93ef24d0-d50e-4a5c-a3c4-8935a0bfc211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados:\n",
            "- outputs/eval_grid.json\n",
            "- outputs/metrics_by_season.csv\n"
          ]
        }
      ],
      "source": [
        "# ===== Imports necesarios (por si no están ya arriba) =====\n",
        "\n",
        "# ===== Eval: LogReg SIN SMOTE (excluyendo nombres de equipos y ids) =====\n",
        "def run_logreg_eval_no_smote(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train: Season <= train_until_season\n",
        "    Test : Season >  train_until_season  (y si test_until_season no es None, Season <= test_until_season)\n",
        "    Excluye columnas no predictoras (incluye HomeTeam_norm/AwayTeam_norm si están en df).\n",
        "    \"\"\"\n",
        "\n",
        "    # --- columnas a excluir SIEMPRE de X ---\n",
        "    drop_cols_common = [\n",
        "        'FTR', 'target', 'Date', 'has_xg_data',\n",
        "        'a_squad_size_prev_season', 'away_form_gd_6', 'home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm',   # <- NUEVO: fuera de las features\n",
        "        'row_id',                          # <- si existe\n",
        "    ]\n",
        "    # --- columnas a excluir según modo con/sin cuotas ---\n",
        "    if with_odds:\n",
        "        drop_cols_mode = ['overround', 'pimp2', 'B365D']\n",
        "    else:\n",
        "        drop_cols_mode = [\n",
        "            'fase_temporada_inicio','fase_temporada_mitad',\n",
        "            'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'\n",
        "        ]\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    # --- X e y; filtrado de válidos ---\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        # Si entrenas \"con cuotas\", exige al menos H y A (D la quitamos de X)\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta la columna 'Season' en X para hacer el split temporal.\")\n",
        "\n",
        "    # --- split temporal ---\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] >  train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_train = X_all.loc[train_mask].drop(columns=['Season'])\n",
        "    y_train = y_all.loc[train_mask]\n",
        "\n",
        "    X_test  = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test  = y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "\n",
        "    if len(X_train) == 0 or len(np.unique(y_train)) < 2:\n",
        "        raise ValueError(\"TRAIN vacío o con <2 clases. Revisa filtros/temporadas.\")\n",
        "\n",
        "    # --- escalado + modelo ---\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled  = scaler.transform(X_test) if len(X_test) else None\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        solver='saga', penalty='l2', max_iter=1000, random_state=random_state\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    classes_used = model.classes_\n",
        "\n",
        "    # --- métricas train ---\n",
        "    ytr_pred  = model.predict(X_train_scaled)\n",
        "    ytr_proba = model.predict_proba(X_train_scaled)\n",
        "    ytr_bin   = label_binarize(y_train, classes=classes_used)\n",
        "    brier_tr  = np.mean(np.sum((ytr_proba - ytr_bin)**2, axis=1))\n",
        "    acc_tr    = accuracy_score(y_train, ytr_pred)\n",
        "    ll_tr     = log_loss(y_train, ytr_proba, labels=classes_used)\n",
        "    metrics_train = {\n",
        "        \"accuracy\": float(acc_tr),\n",
        "        \"log_loss\": float(ll_tr),\n",
        "        \"brier\": float(brier_tr),\n",
        "        \"n_train\": int(len(y_train))\n",
        "    }\n",
        "\n",
        "    # --- métricas test ---\n",
        "    metrics_test, yte_pred, yte_proba = None, None, None\n",
        "    if len(X_test):\n",
        "        yte_pred  = model.predict(X_test_scaled)\n",
        "        yte_proba = model.predict_proba(X_test_scaled)\n",
        "        yte_bin   = label_binarize(y_test, classes=classes_used)\n",
        "        brier_te  = np.mean(np.sum((yte_proba - yte_bin)**2, axis=1))\n",
        "        acc_te    = accuracy_score(y_test, yte_pred)\n",
        "        ll_te     = log_loss(y_test, yte_proba, labels=classes_used)\n",
        "        metrics_test = {\n",
        "            \"accuracy\": float(acc_te),\n",
        "            \"log_loss\": float(ll_te),\n",
        "            \"brier\": float(brier_te),\n",
        "            \"n_test\": int(len(y_test)),\n",
        "            \"season_min\": int(X_all.loc[test_mask, 'Season'].min()),\n",
        "            \"season_max\": int(X_all.loc[test_mask, 'Season'].max())\n",
        "        }\n",
        "    else:\n",
        "        print(\"⚠️ TEST vacío tras filtrar (no hay partidos jugados en el rango de test).\")\n",
        "\n",
        "    test_range_txt = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "                      if test_until_season is not None else f\">{train_until_season}\")\n",
        "    print(\"Logistic Regression (sin SMOTE)\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {test_range_txt}) ===\")\n",
        "    print(metrics_test if metrics_test else \"Sin test disponible.\")\n",
        "\n",
        "    return model, scaler, (metrics_train, metrics_test), y_test, yte_pred, yte_proba, idx_test\n",
        "\n",
        "\n",
        "# ===== Bucle que guarda eval_grid.json y metrics_by_season.csv =====\n",
        "ROOT = Path(\".\")\n",
        "OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "\n",
        "rows = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        _, _, (mtr_tr, mtr_te), *_ = run_logreg_eval_no_smote(\n",
        "            df,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=True,\n",
        "            random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "\n",
        "        rows.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SKIP] test={test_season} → {e}\")\n",
        "\n",
        "with open(OUT / \"eval_grid.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows:\n",
        "    flat = []\n",
        "    for r in rows:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "        })\n",
        "    pd.DataFrame(flat).sort_values(\"test_season\").to_csv(\n",
        "        OUT / \"metrics_by_season.csv\", index=False\n",
        "    )\n",
        "\n",
        "print(f\"Guardados:\\n- {OUT/'eval_grid.json'}\\n- {OUT/'metrics_by_season.csv'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5tGcF-y9Ymk",
        "outputId": "48763793-c002-4c64-92ef-581461d22e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n"
          ]
        }
      ],
      "source": [
        "# LOCAL\n",
        "model, scaler, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = \\\n",
        "    run_logreg_eval_no_smote(df, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOHEHwvkEAJ"
      },
      "source": [
        "Con SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTHeArxhUeA5",
        "outputId": "1914f25e-9a0c-45a9-ec1d-1d676aa1166d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados: eval_grid_smote.json y metrics_by_season_smote.csv\n"
          ]
        }
      ],
      "source": [
        "def run_logreg_eval(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Regresión logística con SMOTE + escalado.\n",
        "      - Train: Season <= train_until_season\n",
        "      - Test : Season >  train_until_season (y si test_until_season no es None, Season <= test_until_season)\n",
        "      - Si with_odds=True, exige B365H/B365A no NaN.\n",
        "      - Descarta filas con NaN en features.\n",
        "    Returns:\n",
        "      model, scaler, (metrics_train, metrics_test),\n",
        "      y_test (o None), y_pred_test (o None), proba_test (o None), idx_test (o None)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- EXCLUIR SIEMPRE de X (añadido Home/Away names y row_id) ---\n",
        "    drop_cols_common = [\n",
        "        'FTR', 'target', 'Date', 'has_xg_data',\n",
        "        'a_squad_size_prev_season', 'away_form_gd_6', 'home_form_gd_6',\n",
        "        'HomeTeam_norm', 'AwayTeam_norm',   # <-- NUEVO: fuera del modelo\n",
        "        'row_id',                           # <-- NUEVO: por si existe\n",
        "    ]\n",
        "    if with_odds:\n",
        "        drop_cols_mode = ['overround', 'pimp2', 'B365D']\n",
        "    else:\n",
        "        drop_cols_mode = ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                          'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2']\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    # --- X e y; filtrado de válidos ---\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid_mask = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H', 'B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid_mask &= X_all[c].notna()\n",
        "    valid_mask &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid_mask].copy()\n",
        "    y_all = y_all.loc[valid_mask].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta la columna 'Season' para hacer el split temporal.\")\n",
        "\n",
        "    # --- split temporal ---\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] >  train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_train = X_all.loc[train_mask].drop(columns=['Season'])\n",
        "    y_train = y_all.loc[train_mask]\n",
        "\n",
        "    X_test  = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test  = y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "\n",
        "    if len(X_train) == 0 or len(np.unique(y_train)) < 2:\n",
        "        raise ValueError(\"TRAIN vacío o con menos de 2 clases. Revisa filtros/temporadas.\")\n",
        "\n",
        "    # --- escalado ---\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled  = scaler.transform(X_test) if len(X_test) else None\n",
        "\n",
        "    # --- SMOTE robusto ---\n",
        "    _, counts = np.unique(y_train, return_counts=True)\n",
        "    min_count = int(counts.min())\n",
        "    if min_count <= 1:\n",
        "        X_train_res, y_train_res = X_train_scaled, y_train\n",
        "    else:\n",
        "        k = max(1, min(5, min_count - 1))\n",
        "        try:\n",
        "            smote = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "            X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
        "        except Exception:\n",
        "            X_train_res, y_train_res = X_train_scaled, y_train\n",
        "\n",
        "    # --- modelo ---\n",
        "    model = LogisticRegression(\n",
        "        solver='saga', penalty='l2', max_iter=1000, random_state=random_state\n",
        "    )\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    classes_used = model.classes_\n",
        "\n",
        "    # --- métricas train ---\n",
        "    ytr_pred  = model.predict(X_train_scaled)\n",
        "    ytr_proba = model.predict_proba(X_train_scaled)\n",
        "    ytr_bin   = label_binarize(y_train, classes=classes_used)\n",
        "    brier_tr  = float(np.mean(np.sum((ytr_proba - ytr_bin) ** 2, axis=1)))\n",
        "    acc_tr    = float(accuracy_score(y_train, ytr_pred))\n",
        "    ll_tr     = float(log_loss(y_train, ytr_proba, labels=classes_used))\n",
        "    metrics_train = {\n",
        "        \"accuracy\": acc_tr, \"log_loss\": ll_tr, \"brier\": brier_tr, \"n_train\": int(len(y_train))\n",
        "    }\n",
        "\n",
        "    # --- métricas test ---\n",
        "    metrics_test, yte_pred, yte_proba = None, None, None\n",
        "    if len(X_test):\n",
        "        yte_pred  = model.predict(X_test_scaled)\n",
        "        yte_proba = model.predict_proba(X_test_scaled)\n",
        "        yte_bin   = label_binarize(y_test, classes=classes_used)\n",
        "        brier_te  = float(np.mean(np.sum((yte_proba - yte_bin) ** 2, axis=1)))\n",
        "        acc_te    = float(accuracy_score(y_test, yte_pred))\n",
        "        ll_te     = float(log_loss(y_test, yte_proba, labels=classes_used))\n",
        "        metrics_test = {\n",
        "            \"accuracy\": acc_te, \"log_loss\": ll_te, \"brier\": brier_te,\n",
        "            \"n_test\": int(len(y_test)),\n",
        "            \"season_min\": int(X_all.loc[test_mask, 'Season'].min()),\n",
        "            \"season_max\": int(X_all.loc[test_mask, 'Season'].max())\n",
        "        }\n",
        "    else:\n",
        "        print(\"⚠️ TEST vacío tras filtrar (no hay partidos jugados en el rango de test).\")\n",
        "\n",
        "    # --- reporte ---\n",
        "    test_range_txt = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "                      if test_until_season is not None else f\">{train_until_season}\")\n",
        "    print(\"Logistic Regression con SMOTE\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {test_range_txt}) ===\")\n",
        "    print(metrics_test if metrics_test else \"Sin test disponible.\")\n",
        "\n",
        "    return model, scaler, (metrics_train, metrics_test), y_test, yte_pred, yte_proba, idx_test\n",
        "\n",
        "\n",
        "OUT = ROOT / \"outputs\"   # o ROOT/\"outs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "rows_sm = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "    try:\n",
        "        _, _, (mtr_tr, mtr_te), *_ = run_logreg_eval(\n",
        "            df, train_until_season=train_until, test_until_season=test_season,\n",
        "            with_odds=True, random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "        rows_sm.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SMOTE SKIP] test={test_season} → {e}\")\n",
        "\n",
        "with open(OUT / \"eval_grid_smote.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows_sm, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows_sm:\n",
        "    flat_sm = []\n",
        "    for r in rows_sm:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat_sm.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "        })\n",
        "    pd.DataFrame(flat_sm).sort_values(\"test_season\").to_csv(\n",
        "        OUT / \"metrics_by_season_smote.csv\", index=False\n",
        "    )\n",
        "\n",
        "print(\"Guardados: eval_grid_smote.json y metrics_by_season_smote.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUnUvtBGahqH",
        "outputId": "f1e683a4-a582-4e93-c7e6-b685cdec93e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n"
          ]
        }
      ],
      "source": [
        "# LOCAL\n",
        "model_sm, scaler_sm, (mtr_tr_sm, mtr_te_sm), y_test_sm, y_pred_sm, y_proba_sm, idx_test_sm = \\\n",
        "    run_logreg_eval(df, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WA-02xbP30g"
      },
      "source": [
        "Con este modelo obtengo el mejor **Accuracy** (porcentaje de aciertos totales), pero esta métrica ignora como de seguras son esas esas predicciones.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Número de aciertos}}{\\text{Número total de predicciones}}\n",
        "$$\n",
        "\n",
        "Para ello se utiliza el **Log Loss** (Cross-Entropy Loss), métrica que mide qué tan buenas son las probabilidades que predice mi modelo de clasificación. A esta métrica no solo le importa acertar la clase, sino cuán seguro está el modelo.\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} y_{ij} \\cdot \\log(p_{ij})\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $y_{ij}$ = 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "\n",
        "Tener un Log Loss alto en este caso significaría dar una probabilidad alta a la clase incorrecta, o lo que es lo mismo, dar una probabilidad baja a la clase correcta.\n",
        "\n",
        "Por último añadí también el **Brier Score**, que es una métrica que evalúa cuán cercanas están las probabilidades predichas por tu modelo respecto a la realidad, comparando la distribución de probabilidades contra la clase real (codificada en one-hot). Es como un error cuadrático medio (MSE) para probabilidades.\n",
        "\n",
        "$$\n",
        "\\text{Brier Score} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} (p_{ij} - y_{ij})^2\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $N$ es el número de ejemplos.\n",
        "- $K$ es el número de clases (en este caso 3: victoria local, empate, victoria visitante).\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "- $y_{ij}$ es 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "\n",
        "Un Brier Score de 0 significa que las probabilidades dadas por el modelo son perfectas, mientras que uno del 0.66 en nuestro caso sería un modelo completamente aleatorio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjn9DwWtgyl"
      },
      "source": [
        "## Selección de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agXuwrpyY1A-"
      },
      "source": [
        "La función `forward_selection` implementa un algoritmo clásico de selección de variables hacia adelante (**forward feature selection**) sobre un modelo de regresión logística multiclase con escalado de variables.\n",
        "\n",
        "Va añadiendo sucesivamente la variable que mejor mejora el rendimiento del modelo (según accuracy o log_loss), una por una.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nec5nM-N88pl"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.metrics import accuracy_score, log_loss\n",
        "# import numpy as np\n",
        "\n",
        "# def forward_selection(X, y, max_features=20, scoring='accuracy'):\n",
        "#     selected_features = []\n",
        "#     remaining_features = list(X.columns)\n",
        "#     scores = []\n",
        "\n",
        "#     for i in range(min(max_features, len(remaining_features))):\n",
        "#         best_score = -np.inf if scoring == 'accuracy' else np.inf\n",
        "#         best_feature = None\n",
        "\n",
        "#         for feature in remaining_features:\n",
        "#             current_features = selected_features + [feature]\n",
        "\n",
        "#             model = make_pipeline(\n",
        "#                 StandardScaler(),\n",
        "#                 LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "#             )\n",
        "\n",
        "#             model.fit(X[current_features], y)\n",
        "#             y_pred = model.predict(X[current_features])\n",
        "#             y_proba = model.predict_proba(X[current_features])\n",
        "\n",
        "#             if scoring == 'accuracy':\n",
        "#                 score = accuracy_score(y, y_pred)\n",
        "#                 if score > best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             elif scoring == 'log_loss':\n",
        "#                 score = log_loss(y, y_proba)\n",
        "#                 if score < best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             else:\n",
        "#                 raise ValueError(\"scoring debe ser 'accuracy' o 'log_loss'.\")\n",
        "\n",
        "#         if best_feature is not None:\n",
        "#             selected_features.append(best_feature)\n",
        "#             remaining_features.remove(best_feature)\n",
        "#             scores.append(best_score)\n",
        "\n",
        "#         print(f\"[{i+1}] Añadida: {best_feature} | Score: {best_score:.4f}\")\n",
        "\n",
        "#     return selected_features, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "9w77D7IQ6ORb"
      },
      "outputs": [],
      "source": [
        "# selected, scores = forward_selection(X_train, y_train, max_features=81, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "94wsZYs0akpR"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Suponemos que tienes las listas: selected (variables) y scores (métricas acumuladas)\n",
        "\n",
        "# # Calcular diferencia respecto al valor anterior\n",
        "# deltas = np.diff([0] + scores)\n",
        "# colors = ['blue' if delta >= 0 else 'red' for delta in deltas]\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# bar_width = 0.6  # Reducir ancho de barra para separarlas\n",
        "# indices = np.arange(len(selected))\n",
        "\n",
        "# plt.bar(indices, scores, color=colors, width=bar_width)\n",
        "# plt.xticks(indices, selected, rotation=90)\n",
        "# plt.xlabel('Variables añadidas')\n",
        "# plt.ylabel('Valor de la métrica')\n",
        "# plt.title('Evolución del rendimiento al añadir variables')\n",
        "\n",
        "# plt.ylim(min(scores) - 0.01, max(scores) + 0.01)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r5Zlw7IZTRM"
      },
      "source": [
        "Se implementó un proceso de selección hacia adelante (forward selection) sobre el modelo de regresión logística con variables estandarizadas. Este procedimiento consiste en partir sin predictores y añadir, en cada iteración, la variable que mayor mejora produce en el rendimiento del modelo. Se evaluaron dos métricas complementarias como criterio de selección: el accuracy (para priorizar aciertos de clasificación) y el log loss (para priorizar la calibración de las probabilidades). Esta técnica permitió reducir la dimensionalidad del conjunto original y determinar el orden de relevancia de las variables desde el punto de vista predictivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmmpBR0ity_a"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu7wer0OnyON"
      },
      "source": [
        "## **MATRIZ DE CONFUSIÓN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TBP6i2sWnbY",
        "outputId": "5130bdad-d64d-46ab-9f71-73b432e03062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/confusion_grid_base.json  (19 temporadas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/confusion_grid_smote.json  (19 temporadas)\n"
          ]
        }
      ],
      "source": [
        "# --- IMPORTS NECESARIOS ---\n",
        "\n",
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Excluimos también los nombres y posibles IDs para que NO entren en X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'  # <- añadido\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    # válidas: sin NaN en y ni en X; si with_odds, exige cuotas clave\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Alinea X para que tenga EXACTAMENTE las columnas usadas en el fit.\n",
        "    - Usa feature_names si se proporcionan; si no, intenta fitter.feature_names_in_.\n",
        "    - Elimina columnas extra.\n",
        "    - Lanza error si faltan columnas del fit.\n",
        "    \"\"\"\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # si el scaler/model se entrenó con arrays numpy sin nombres\n",
        "\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Matriz de confusión con rango de test configurable ----------\n",
        "def plot_confusion_for_logreg(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None   # opcional: forzar lista de features del fit\n",
        "):\n",
        "    # 1) reconstruir TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # 4) plot\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = model.classes_\n",
        "    display_labels = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    ConfusionMatrixDisplay.from_predictions(\n",
        "        y_test, y_pred,\n",
        "        labels=classes_used,\n",
        "        display_labels=display_labels,\n",
        "        cmap='Blues', colorbar=False\n",
        "    )\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    plt.title(f'Confusion Matrix (Seasons {rango})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Grid de matrices por temporada (guarda JSON para la app) ----------\n",
        "def build_confusion_grid(df: pd.DataFrame, out_dir: Path, model: str = \"base\", random_state: int = 42):\n",
        "    \"\"\"\n",
        "    Genera matrices de confusión por temporada y las guarda en:\n",
        "      outputs/confusion_grid_<model>.json\n",
        "    - model: \"base\" (sin SMOTE) | \"smote\"\n",
        "    - Split: train ≤ S-1, test = S\n",
        "    - Usa with_odds=True\n",
        "    \"\"\"\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            elif model == \"smote\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"model debe ser 'base' o 'smote'.\")\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # y_test / y_pred pueden venir como Series -> convertir\n",
        "            y_true = np.asarray(y_test)\n",
        "            y_hat  = np.asarray(y_pred)\n",
        "\n",
        "            cm = confusion_matrix(y_true, y_hat, labels=[0, 1, 2]).tolist()  # 0=A,1=D,2=H\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"labels\": [\"A\",\"D\",\"H\"],\n",
        "                \"matrix\": cm,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"])\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[CONF {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_path = out_dir / f\"confusion_grid_{model}.json\"\n",
        "    out_path.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_path}  ({len(rows)} temporadas)\")\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "# Asegúrate de tener OUT definido:\n",
        "# OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "build_confusion_grid(df, OUT, model=\"base\")\n",
        "build_confusion_grid(df, OUT, model=\"smote\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FGsY5ECG9S4E"
      },
      "outputs": [],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# plot_confusion_for_logreg(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBvnqoyz-uws"
      },
      "source": [
        "## **METRICAS DE CLASIFICACIÓN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlFvWkC-ZXGO",
        "outputId": "a5fb7fe5-35e6-4ab1-860e-607be050f433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/classification_grid_base.json  (19 temporadas)\n",
            "Guardado: outputs/classification_by_season_base.csv\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/classification_grid_smote.json  (19 temporadas)\n",
            "Guardado: outputs/classification_by_season_smote.csv\n"
          ]
        }
      ],
      "source": [
        "# -------- split TEST con tope de temporada --------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Excluimos también nombres de equipo (y row_id si existiese) para que NO entren como features\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para hacer el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# -------- alinear columnas a las usadas en el fit --------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        # si se entrenó con arrays, no hay nombres; asumimos que X ya coincide\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# -------- classification_report con rango de test configurable --------\n",
        "def print_classification_report_for_logreg(\n",
        "    df: pd.DataFrame, model, scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    digits: int = 3,\n",
        "    feature_names: list[str] | None = None   # opcional: columnas del fit\n",
        "):\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # Alinear a columnas de entrenamiento\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # Predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Etiquetas (orden estable 0=A,1=D,2=H)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "    classes_used = [c for c in [0,1,2] if c in classes_used]\n",
        "    target_names = [class2label[c] for c in classes_used]\n",
        "\n",
        "    print(\n",
        "        classification_report(\n",
        "            y_test, y_pred,\n",
        "            labels=classes_used,\n",
        "            target_names=target_names,\n",
        "            zero_division=0,\n",
        "            digits=digits\n",
        "        )\n",
        "    )\n",
        "\n",
        "# EJECUTAR EN LOCAL\n",
        "# print_classification_report_for_logreg(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)\n",
        "\n",
        "def build_classification_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",       # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,    # como acordamos para la app\n",
        "    random_state: int = 42\n",
        "):\n",
        "    \"\"\"\n",
        "    Exporta métricas de clasificación por temporada (train ≤ S-1, test = S).\n",
        "    Guarda: outputs/classification_grid_<model>.json\n",
        "            outputs/classification_by_season_<model>.csv (resumen tabular)\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    label_name = {0:\"A\", 1:\"D\", 2:\"H\"}  # tu codificación\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Orden de clases estable basado en el modelo (0,1,2)\n",
        "            classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "            classes_used = [c for c in [0,1,2] if c in classes_used]\n",
        "            target_names = [label_name[c] for c in classes_used]\n",
        "\n",
        "            rep = classification_report(\n",
        "                y_test, y_pred,\n",
        "                labels=classes_used,\n",
        "                target_names=target_names,\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "\n",
        "            per_class = {}\n",
        "            for c in classes_used:\n",
        "                nm = label_name[c]\n",
        "                if nm in rep:\n",
        "                    per_class[nm] = {\n",
        "                        \"precision\": float(rep[nm][\"precision\"]),\n",
        "                        \"recall\":    float(rep[nm][\"recall\"]),\n",
        "                        \"f1\":        float(rep[nm][\"f1-score\"]),\n",
        "                        \"support\":   int(rep[nm][\"support\"]),\n",
        "                    }\n",
        "\n",
        "            overall = {\n",
        "                \"accuracy\":     float(rep.get(\"accuracy\", mtr_te.get(\"accuracy\", float(\"nan\")))),\n",
        "                \"macro_avg\": {\n",
        "                    \"precision\": float(rep[\"macro avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"macro avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"macro avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"macro avg\"][\"support\"]),\n",
        "                },\n",
        "                \"weighted_avg\": {\n",
        "                    \"precision\": float(rep[\"weighted avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"weighted avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"weighted avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"weighted avg\"][\"support\"]),\n",
        "                },\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            }\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,\n",
        "                \"overall\": overall,\n",
        "            })\n",
        "\n",
        "            row_flat = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"accuracy\": overall[\"accuracy\"],\n",
        "                \"macro_f1\": overall[\"macro_avg\"][\"f1\"],\n",
        "                \"n_test\": overall[\"n_test\"],\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    row_flat[f\"precision_{nm}\"] = per_class[nm][\"precision\"]\n",
        "                    row_flat[f\"recall_{nm}\"]    = per_class[nm][\"recall\"]\n",
        "                    row_flat[f\"f1_{nm}\"]        = per_class[nm][\"f1\"]\n",
        "                    row_flat[f\"support_{nm}\"]   = per_class[nm][\"support\"]\n",
        "            flat.append(row_flat)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[CLASS {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (out_dir / f\"classification_grid_{model}.json\").write_text(\n",
        "        json.dumps(rows, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(f\"Guardado: {out_dir / f'classification_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(\n",
        "            out_dir / f\"classification_by_season_{model}.csv\", index=False\n",
        "        )\n",
        "        print(f\"Guardado: {out_dir / f'classification_by_season_{model}.csv'}\")\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Modelo base (sin SMOTE)\n",
        "build_classification_grid(df, OUT, model=\"base\", with_odds=True)\n",
        "\n",
        "# También SMOTE:\n",
        "build_classification_grid(df, OUT, model=\"smote\", with_odds=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8foJ4svkocU2"
      },
      "outputs": [],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# print_classification_report_for_logreg(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_-8dbe3DuYD"
      },
      "source": [
        "## **AUC Y CURVA ROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1T0ZcOtWbztW"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# importa explícito para evitar NameError\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # EXCLUIMOS también los nombres de equipo (y row_id si existe) para que NO entren como features\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # entrenaste con arrays; asumimos que X ya coincide\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta de columnas del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Curvas ROC multiclase con rango de test configurable ----------\n",
        "def plot_multiclass_roc(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None\n",
        "):\n",
        "    import matplotlib.pyplot as plt  # lazy import\n",
        "\n",
        "    # 1) TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) Alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) Probabilidades\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "    # 4) Binarización y etiquetas (usa SIEMPRE el orden real del modelo)\n",
        "    classes_used = list(getattr(model, \"classes_\", [0,1,2]))\n",
        "    y_bin = label_binarize(y_test, classes=classes_used)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    labels_text = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    # 5) Curvas por clase\n",
        "    plt.figure()\n",
        "    auc_per_class, weights = [], []\n",
        "    n = len(y_test)\n",
        "\n",
        "    for k, cls in enumerate(classes_used):\n",
        "        y_true_k = y_bin[:, k]\n",
        "        y_score_k = y_proba[:, k]\n",
        "        pos = int(y_true_k.sum())\n",
        "        neg = n - pos\n",
        "        if pos > 0 and neg > 0:\n",
        "            fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "            auc_k = roc_auc_score(y_true_k, y_score_k)\n",
        "            auc_per_class.append(auc_k)\n",
        "            weights.append(pos)\n",
        "            plt.plot(fpr, tpr, label=f\"{labels_text[k]} (AUC = {auc_k:.2f})\")\n",
        "        else:\n",
        "            print(f\"Nota: '{labels_text[k]}' no tiene suficientes positivos/negativos en TEST; omito su curva.\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    rango = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "             if test_until_season is not None else f\">{train_until_season}\")\n",
        "    plt.title(f\"Curvas ROC por clase (Seasons {rango})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 6) AUC macro y weighted\n",
        "    if auc_per_class:\n",
        "        auc_macro = float(np.mean(auc_per_class))\n",
        "        auc_weighted = float(np.average(auc_per_class, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "        print(f\"\\nAUC macro: {auc_macro:.3f}\")\n",
        "        print(f\"AUC weighted: {auc_weighted:.3f}\")\n",
        "    else:\n",
        "        print(\"\\nNo se pudieron calcular AUCs (todas las clases carecen de positivos/negativos suficientes en TEST).\")\n",
        "\n",
        "# === ROC por temporada (train ≤ S-1, test = S) → outputs/roc_grid_<modelo>.json ===\n",
        "\n",
        "def _downsample_curve(x: np.ndarray, y: np.ndarray, max_points: int = 200):\n",
        "    \"\"\"Reduce puntos de la curva para que el JSON no pese demasiado.\"\"\"\n",
        "    if len(x) <= max_points:\n",
        "        return x.tolist(), y.tolist()\n",
        "    idx = np.linspace(0, len(x) - 1, max_points).round().astype(int)\n",
        "    return x[idx].tolist(), y[idx].tolist()\n",
        "\n",
        "def build_roc_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",        # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    max_points: int = 200       # nº máx. de puntos por curva guardada\n",
        "):\n",
        "    label_name = {0: \"A\", 1: \"D\", 2: \"H\"}  # tu codificación 0/1/2\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Orden REAL de columnas en y_proba:\n",
        "            classes_used = list(getattr(mdl, \"classes_\", [0,1,2]))\n",
        "\n",
        "            # Binariza y calcula curvas por clase si hay positivos y negativos\n",
        "            y_bin = label_binarize(y_test, classes=classes_used)\n",
        "            per_class = {}\n",
        "            aucs, weights = [], []\n",
        "\n",
        "            for k, cls in enumerate(classes_used):\n",
        "                nm = label_name.get(cls, str(cls))\n",
        "                y_true_k = y_bin[:, k]\n",
        "                y_score_k = y_proba[:, k]\n",
        "                pos = int(y_true_k.sum())\n",
        "                neg = int(len(y_true_k) - pos)\n",
        "                if pos > 0 and neg > 0:\n",
        "                    fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "                    auc_k = float(roc_auc_score(y_true_k, y_score_k))\n",
        "                    fpr_l, tpr_l = _downsample_curve(fpr, tpr, max_points=max_points)\n",
        "                    per_class[nm] = {\n",
        "                        \"auc\": auc_k,\n",
        "                        \"support_pos\": pos,\n",
        "                        \"fpr\": fpr_l,\n",
        "                        \"tpr\": tpr_l,\n",
        "                    }\n",
        "                    aucs.append(auc_k)\n",
        "                    weights.append(pos)\n",
        "\n",
        "            if not per_class:\n",
        "                continue\n",
        "\n",
        "            auc_macro = float(np.mean(aucs))\n",
        "            auc_weighted = float(np.average(aucs, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,     # dict con A/D/H presentes\n",
        "                \"overall\": {\n",
        "                    \"auc_macro\": auc_macro,\n",
        "                    \"auc_weighted\": auc_weighted,\n",
        "                    \"n_test\": int(mtr_te[\"n_test\"])\n",
        "                }\n",
        "            })\n",
        "\n",
        "            # fila plana para CSV (útil en tablas)\n",
        "            rowf = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"auc_macro\": auc_macro,\n",
        "                \"auc_weighted\": auc_weighted,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    rowf[f\"auc_{nm}\"] = per_class[nm][\"auc\"]\n",
        "                    rowf[f\"support_pos_{nm}\"] = per_class[nm][\"support_pos\"]\n",
        "            flat.append(rowf)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ROC {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (out_dir / f\"roc_grid_{model}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_dir / f'roc_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(out_dir / f\"roc_by_season_{model}.csv\", index=False)\n",
        "        print(f\"Guardado: {out_dir / f'roc_by_season_{model}.csv'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZDwnt_DBphY",
        "outputId": "31fe7404-5244-423b-faa6-b640ae0a45d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/roc_grid_base.json  (19 temporadas)\n",
            "Guardado: outputs/roc_by_season_base.csv\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/roc_grid_smote.json  (19 temporadas)\n",
            "Guardado: outputs/roc_by_season_smote.csv\n"
          ]
        }
      ],
      "source": [
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # entrenaste con arrays; asumimos que X ya coincide\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta de columnas del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Curvas ROC multiclase con rango de test configurable ----------\n",
        "def plot_multiclass_roc(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None\n",
        "):\n",
        "    import matplotlib.pyplot as plt  # lazy import para evitar NameError\n",
        "\n",
        "    # 1) TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) Alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) Probabilidades\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "    # 4) Binarización y etiquetas\n",
        "    classes_used = model.classes_\n",
        "    y_bin = label_binarize(y_test, classes=classes_used)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    labels_text = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    # 5) Curvas por clase (si hay positivos y negativos)\n",
        "    plt.figure()\n",
        "    auc_per_class, weights = [], []\n",
        "    n = len(y_test)\n",
        "\n",
        "    for k, cls in enumerate(classes_used):\n",
        "        y_true_k = y_bin[:, k]\n",
        "        y_score_k = y_proba[:, k]\n",
        "        pos = y_true_k.sum()\n",
        "        neg = n - pos\n",
        "        if pos > 0 and neg > 0:\n",
        "            fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "            auc_k = roc_auc_score(y_true_k, y_score_k)\n",
        "            auc_per_class.append(auc_k)\n",
        "            weights.append(pos)\n",
        "            plt.plot(fpr, tpr, label=f\"{labels_text[k]} (AUC = {auc_k:.2f})\")\n",
        "        else:\n",
        "            print(f\"Nota: '{labels_text[k]}' no tiene suficientes positivos/negativos en TEST; omito su curva.\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    plt.title(f\"Curvas ROC por clase (Seasons {rango})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 6) AUC macro y weighted (solo con clases válidas)\n",
        "    if auc_per_class:\n",
        "        auc_macro = float(np.mean(auc_per_class))\n",
        "        auc_weighted = float(np.average(auc_per_class, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "        print(f\"\\nAUC macro: {auc_macro:.3f}\")\n",
        "        print(f\"AUC weighted: {auc_weighted:.3f}\")\n",
        "    else:\n",
        "        print(\"\\nNo se pudieron calcular AUCs (todas las clases carecen de positivos/negativos suficientes en TEST).\")\n",
        "\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Sin SMOTE\n",
        "build_roc_grid(df, OUT, model=\"base\", with_odds=True)\n",
        "\n",
        "# Con SMOTE\n",
        "build_roc_grid(df, OUT, model=\"smote\", with_odds=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "izcriACtp027",
        "outputId": "394937ba-27f5-47de-fcec-15cd49688b6a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "AUC macro: 0.697\n",
            "AUC weighted: 0.709\n"
          ]
        }
      ],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "plot_multiclass_roc(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nx6x3AUKKEk"
      },
      "source": [
        "## **BENEFICIOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RYAfU_pvMz"
      },
      "source": [
        "Por último, pero no por ello menos importante vamos a estudiar la última métrica: El **ROI (Return on Investment)**.\n",
        "\n",
        "$$\n",
        "ROI = \\frac{\\text{Beneficio}}{\\text{Inversión}}\n",
        "$$\n",
        "\n",
        "Con el código siguiente lo que estoy haciendo es simular una apuesta de un euro al resultado que predice mi modelo, en todos los partidos que hay en test. Si se acierta sumamos la cuota que ofrece Bet365 pero si falla se resta la unidad apostada. Con esto calculamos el beneficio neto y el ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F8dtqCLmtQp",
        "outputId": "a24ac586-0981-4bc7-aa17-5ad8fc95269a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guardados:\n",
            "- outputs/roi_by_season_base.json\n",
            "- outputs/roi_by_season_base.csv\n",
            "Guardados:\n",
            "- outputs/roi_by_season_smote.json\n",
            "- outputs/roi_by_season_smote.csv\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# ROI por temporada (sin df_old) - Celda única\n",
        "# ============================================\n",
        "\n",
        "# --- Rutas (fallback si no existen variables del proyecto) ---\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "try:\n",
        "    DATA\n",
        "except NameError:\n",
        "    DATA = ROOT / \"data\"\n",
        "\n",
        "FEAT = DATA / \"03_features\"\n",
        "\n",
        "# --- Carga base: df_final ya incluye nombres de equipos ---\n",
        "df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# --- Constantes útiles ---\n",
        "CLASS2TXT = {0: \"A\", 1: \"D\", 2: \"H\"}   # 0=Away, 1=Draw, 2=Home\n",
        "TXT2IDX   = {'A':0, 'D':1, 'H':2}\n",
        "\n",
        "# ---------- Split de TEST con índices ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Importante: excluir variables de nombre de equipos de X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'  # <- evita fuga de info\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Alinear columnas al fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Meta alineada (nombres + cuotas) desde df ----------\n",
        "def attach_names_and_odds(df: pd.DataFrame, idx: pd.Index) -> pd.DataFrame:\n",
        "    need = [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Faltan columnas en df: {missing}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "    meta[\"Date\"] = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    return meta\n",
        "\n",
        "# ---------- Utilidades de reporting ----------\n",
        "def _max_drawdown(equity: pd.Series):\n",
        "    \"\"\"Devuelve drawdown máximo: (mdd_abs, mdd_pct, peak_idx, trough_idx).\"\"\"\n",
        "    if equity.empty:\n",
        "        return 0.0, 0.0, None, None\n",
        "    running_max = equity.cummax()\n",
        "    drawdown = running_max - equity\n",
        "    trough_idx = drawdown.idxmax()\n",
        "    peak_idx = equity.loc[:trough_idx].idxmax() if trough_idx is not None else None\n",
        "    mdd_abs = float(drawdown.max())\n",
        "    peak_val = float(equity.loc[peak_idx]) if peak_idx is not None else 1.0\n",
        "    mdd_pct = float(mdd_abs / peak_val) if peak_val > 0 else 0.0\n",
        "    return mdd_abs, mdd_pct, peak_idx, trough_idx\n",
        "\n",
        "def _edge_bins(edge: pd.Series, bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Discretiza edge (EV de la PREDICCIÓN) en tramos para analizar ROI.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "# ---------- Simulación ROI (con columnas de \"valor\" EV por clase) ----------\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,     # filtro por EV mínimo de la PREDICCIÓN\n",
        "):\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs     = scaler.transform(X_test)\n",
        "    proba  = model.predict_proba(Xs)\n",
        "    y_pred = model.predict(Xs)\n",
        "\n",
        "    # 3) Meta (nombres/fechas/cuotas) desde df\n",
        "    res = attach_names_and_odds(df, idx_test)\n",
        "    res['true_result']      = y_test.loc[res.index].values\n",
        "    res['predicted_result'] = pd.Series(y_pred, index=idx_test).loc[res.index].values\n",
        "\n",
        "    # 4) Probs/odds/edge de la predicción y \"value\" EV por clase\n",
        "    name_map  = {0:'A',1:'D',2:'H'}\n",
        "    classes   = list(model.classes_)  # típicamente [0,1,2]\n",
        "    proba_df  = pd.DataFrame(proba, index=idx_test, columns=[name_map.get(c, str(c)) for c in classes]).loc[res.index]\n",
        "    proba_fix = proba_df.reindex(columns=['A','D','H'])\n",
        "    odds_fix  = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})[['A','D','H']]\n",
        "\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(name_map).loc[res.index]\n",
        "    pred_idx = pred_txt.map(TXT2IDX).to_numpy()\n",
        "\n",
        "    P, O = proba_fix.to_numpy(), odds_fix.to_numpy()\n",
        "\n",
        "    res['Pred']           = pred_txt\n",
        "    res['predicted_prob'] = P[np.arange(len(res)), pred_idx]\n",
        "    res['predicted_odds'] = O[np.arange(len(res)), pred_idx]\n",
        "    res['edge']           = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "    # Value betting (mejor EV entre H/D/A, informativo)\n",
        "    EV = proba_fix * odds_fix - 1.0\n",
        "    best_idx = EV.to_numpy().argmax(axis=1)\n",
        "    labels = np.array(['A','D','H'])\n",
        "    res['value_pick'] = labels[best_idx]\n",
        "    res['value_ev']   = EV.to_numpy()[np.arange(len(EV)), best_idx]\n",
        "    res['value_prob'] = P[np.arange(len(P)), best_idx]\n",
        "    res['value_odds'] = O[np.arange(len(O)), best_idx]\n",
        "\n",
        "    # 5) Filtros\n",
        "    mask_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_odds].copy()\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación (apuesto SIEMPRE a la predicción)\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # Fechas amigables\n",
        "    res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets    = int(len(res))\n",
        "    roi       = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "    return res, roi, total_net\n",
        "\n",
        "# ---------- Rejilla ROI por temporada ----------\n",
        "def build_roi_grid(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "    model_name: str = \"base\",\n",
        "    out_dir: Path | None = None\n",
        "):\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    OUT = (out_dir or (ROOT / \"outputs\"))\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rows = []\n",
        "    flat_for_csv = []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        res, roi, total_net = simulate_bet365_roi(\n",
        "            df, model, scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=with_odds, stake=stake,\n",
        "            feature_names=feature_names, min_edge=min_edge\n",
        "        )\n",
        "        if res is None or len(res) == 0:\n",
        "            continue\n",
        "\n",
        "        tmp = res.copy()\n",
        "        tmp['_Date'] = pd.to_datetime(tmp['Date'], errors='coerce')\n",
        "        tmp = tmp.sort_values('_Date').drop(columns=['_Date'])\n",
        "\n",
        "        equity = tmp['net_profit'].cumsum()\n",
        "        mdd_abs, mdd_pct, *_ = _max_drawdown(equity)\n",
        "\n",
        "        hit_rate = float((tmp['predicted_result'] == tmp['true_result']).mean())\n",
        "        avg_odds = float(tmp['predicted_odds'].mean())\n",
        "        avg_edge = float(tmp['edge'].mean())\n",
        "        avg_value_ev = float(tmp['value_ev'].mean())\n",
        "\n",
        "        by_class = tmp.groupby(tmp['predicted_result']).agg(\n",
        "            profit=('net_profit','sum'), n=('net_profit','size')\n",
        "        )\n",
        "        profit_by_class = {CLASS2TXT.get(int(k), str(k)): float(v) for k, v in by_class['profit'].items()}\n",
        "\n",
        "        bins = _edge_bins(tmp['edge'])\n",
        "        by_bin = tmp.groupby(bins, observed=True).agg(\n",
        "            n=('net_profit','size'),\n",
        "            profit=('net_profit','sum'),\n",
        "            avg_prob=('predicted_prob','mean'),\n",
        "            avg_odds=('predicted_odds','mean'),\n",
        "            avg_edge=('edge','mean')\n",
        "        ).reset_index(names='edge_bin')\n",
        "        by_bin['roi'] = by_bin.apply(lambda r: (r['profit']/(stake*r['n'])) if r['n']>0 else np.nan, axis=1)\n",
        "        roi_by_edge_bins = [\n",
        "            {\n",
        "                \"bin\": str(row['edge_bin']),\n",
        "                \"n\": int(row['n']),\n",
        "                \"roi\": float(row['roi']),\n",
        "                \"profit_total\": float(row['profit']),\n",
        "                \"avg_prob\": float(row['avg_prob']),\n",
        "                \"avg_odds\": float(row['avg_odds']),\n",
        "                \"avg_edge\": float(row['avg_edge']),\n",
        "            }\n",
        "            for _, row in by_bin.iterrows()\n",
        "        ]\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"roi\": float(roi),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"profit_by_class\": profit_by_class,\n",
        "            \"equity\": [float(x) for x in equity.tolist()],\n",
        "            \"max_drawdown_abs\": float(mdd_abs),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"roi_by_edge_bins\": roi_by_edge_bins,\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "        })\n",
        "\n",
        "        flat_for_csv.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_season\": int(test_season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"roi\": float(roi),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "        })\n",
        "\n",
        "    tag = f\"{model_name}\".replace(\" \", \"_\")\n",
        "    (OUT / f\"roi_by_season_{tag}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    if flat_for_csv:\n",
        "        pd.DataFrame(flat_for_csv).sort_values(\"test_season\").to_csv(OUT / f\"roi_by_season_{tag}.csv\", index=False)\n",
        "\n",
        "    print(f\"Guardados:\\n- {OUT/f'roi_by_season_{tag}.json'}\\n- {OUT/f'roi_by_season_{tag}.csv'}\")\n",
        "    return rows\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO (comenta/ajusta)\n",
        "# =========================\n",
        "# Asume que ya has entrenado:\n",
        "#   - model, scaler  (baseline)\n",
        "#   - model_sm, scaler_sm (SMOTE) si quieres\n",
        "#\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# ... (tu entrenamiento aquí, asegurando NO usar HomeTeam_norm/AwayTeam_norm en X)\n",
        "\n",
        "# Ejemplo (descomenta cuando tengas model/scaler):\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model, scaler=scaler,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"base\"\n",
        ")\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model_sm, scaler=scaler_sm,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"smote\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "Ca_qtV0Iqu9z",
        "outputId": "35a2563f-c853-4e68-82df-d1315e37c570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.24\n",
            "-9.84\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "0",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-920aa128-da36-4933-87c1-039968e70fc2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>true_result</th>\n",
              "      <th>predicted_result</th>\n",
              "      <th>Pred</th>\n",
              "      <th>predicted_prob</th>\n",
              "      <th>predicted_odds</th>\n",
              "      <th>edge</th>\n",
              "      <th>value_pick</th>\n",
              "      <th>value_ev</th>\n",
              "      <th>value_prob</th>\n",
              "      <th>value_odds</th>\n",
              "      <th>bet_outcome</th>\n",
              "      <th>net_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7251</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-12</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>elche</td>\n",
              "      <td>1.85</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.002567</td>\n",
              "      <td>H</td>\n",
              "      <td>0.002567</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7252</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>getafe</td>\n",
              "      <td>oviedo</td>\n",
              "      <td>1.95</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.50</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.409182</td>\n",
              "      <td>1.95</td>\n",
              "      <td>-0.202095</td>\n",
              "      <td>A</td>\n",
              "      <td>0.201801</td>\n",
              "      <td>0.267067</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1.95</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7253</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.554822</td>\n",
              "      <td>1.60</td>\n",
              "      <td>-0.112285</td>\n",
              "      <td>D</td>\n",
              "      <td>0.222138</td>\n",
              "      <td>0.282249</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7254</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>alaves</td>\n",
              "      <td>1.60</td>\n",
              "      <td>3.90</td>\n",
              "      <td>5.75</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.550616</td>\n",
              "      <td>1.60</td>\n",
              "      <td>-0.119014</td>\n",
              "      <td>D</td>\n",
              "      <td>0.206930</td>\n",
              "      <td>0.309469</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7255</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.70</td>\n",
              "      <td>4.33</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.469999</td>\n",
              "      <td>1.80</td>\n",
              "      <td>-0.154001</td>\n",
              "      <td>D</td>\n",
              "      <td>0.264452</td>\n",
              "      <td>0.341744</td>\n",
              "      <td>3.70</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7256</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>celta</td>\n",
              "      <td>girona</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.90</td>\n",
              "      <td>4.75</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.561560</td>\n",
              "      <td>1.73</td>\n",
              "      <td>-0.028502</td>\n",
              "      <td>D</td>\n",
              "      <td>0.087143</td>\n",
              "      <td>0.278755</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7257</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>levante</td>\n",
              "      <td>betis</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.364248</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-0.162229</td>\n",
              "      <td>D</td>\n",
              "      <td>0.069974</td>\n",
              "      <td>0.329223</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7258</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>2.55</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.352265</td>\n",
              "      <td>2.55</td>\n",
              "      <td>-0.101724</td>\n",
              "      <td>D</td>\n",
              "      <td>0.111297</td>\n",
              "      <td>0.347280</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7259</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>valencia</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.830355</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.013033</td>\n",
              "      <td>H</td>\n",
              "      <td>0.013033</td>\n",
              "      <td>0.830355</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7260</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-15</td>\n",
              "      <td>espanol</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.368309</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.252250</td>\n",
              "      <td>D</td>\n",
              "      <td>0.252250</td>\n",
              "      <td>0.368309</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-920aa128-da36-4933-87c1-039968e70fc2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-920aa128-da36-4933-87c1-039968e70fc2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-920aa128-da36-4933-87c1-039968e70fc2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1e4b29f-d277-4c29-9fac-cdbd1534e893\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1e4b29f-d277-4c29-9fac-cdbd1534e893')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1e4b29f-d277-4c29-9fac-cdbd1534e893 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      Season        Date HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A  \\\n",
              "7251    2025  2025-09-12       sevilla         elche   1.85   3.40   4.50   \n",
              "7252    2025  2025-09-13        getafe        oviedo   1.95   3.10   4.50   \n",
              "7253    2025  2025-09-13      sociedad   real madrid   5.00   4.33   1.60   \n",
              "7254    2025  2025-09-13    ath bilbao        alaves   1.60   3.90   5.75   \n",
              "7255    2025  2025-09-13    ath madrid    villarreal   1.80   3.70   4.33   \n",
              "7256    2025  2025-09-14         celta        girona   1.73   3.90   4.75   \n",
              "7257    2025  2025-09-14       levante         betis   3.25   3.25   2.30   \n",
              "7258    2025  2025-09-14       osasuna     vallecano   2.55   3.20   2.90   \n",
              "7259    2025  2025-09-14     barcelona      valencia   1.22   7.00  11.00   \n",
              "7260    2025  2025-09-15       espanol      mallorca   2.10   3.40   3.50   \n",
              "\n",
              "      true_result  predicted_result Pred  predicted_prob  predicted_odds  \\\n",
              "7251            1                 2    H        0.541928            1.85   \n",
              "7252            2                 2    H        0.409182            1.95   \n",
              "7253            0                 0    A        0.554822            1.60   \n",
              "7254            0                 2    H        0.550616            1.60   \n",
              "7255            2                 2    H        0.469999            1.80   \n",
              "7256            1                 2    H        0.561560            1.73   \n",
              "7257            1                 0    A        0.364248            2.30   \n",
              "7258            2                 2    H        0.352265            2.55   \n",
              "7259            2                 2    H        0.830355            1.22   \n",
              "7260            2                 1    D        0.368309            3.40   \n",
              "\n",
              "          edge value_pick  value_ev  value_prob  value_odds  bet_outcome  \\\n",
              "7251  0.002567          H  0.002567    0.541928        1.85         0.00   \n",
              "7252 -0.202095          A  0.201801    0.267067        4.50         1.95   \n",
              "7253 -0.112285          D  0.222138    0.282249        4.33         1.60   \n",
              "7254 -0.119014          D  0.206930    0.309469        3.90         0.00   \n",
              "7255 -0.154001          D  0.264452    0.341744        3.70         1.80   \n",
              "7256 -0.028502          D  0.087143    0.278755        3.90         0.00   \n",
              "7257 -0.162229          D  0.069974    0.329223        3.25         0.00   \n",
              "7258 -0.101724          D  0.111297    0.347280        3.20         2.55   \n",
              "7259  0.013033          H  0.013033    0.830355        1.22         1.22   \n",
              "7260  0.252250          D  0.252250    0.368309        3.40         0.00   \n",
              "\n",
              "      net_profit  \n",
              "7251       -1.00  \n",
              "7252        0.95  \n",
              "7253        0.60  \n",
              "7254       -1.00  \n",
              "7255        0.80  \n",
              "7256       -1.00  \n",
              "7257       -1.00  \n",
              "7258        1.55  \n",
              "7259        0.22  \n",
              "7260       -1.00  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "results_df, roi, total_profit = simulate_bet365_roi(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True, stake=1.0)\n",
        "print(roi)\n",
        "print(total_profit)\n",
        "results_df.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBffDLHUX1nw",
        "outputId": "e4c41aa1-a0b3-4728-909e-34fe8b88c67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[base] Season 2007: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[base] Season 2008: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[base] Season 2009: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[base] Season 2010: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[base] Season 2011: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[base] Season 2012: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[base] Season 2013: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[base] Season 2014: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[base] Season 2015: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[base] Season 2016: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[base] Season 2017: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[base] Season 2018: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[base] Season 2019: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[base] Season 2020: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[base] Season 2021: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[base] Season 2022: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[base] Season 2023: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[base] Season 2024: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "[base] Season 2025: guardado match-log (41 filas)\n",
            "Guardados:\n",
            "- outputs/matchlog_season_summary_base.csv\n",
            "- outputs/matchlog_season_summary_base.json\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[smote] Season 2007: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[smote] Season 2008: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[smote] Season 2009: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[smote] Season 2010: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[smote] Season 2011: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[smote] Season 2012: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[smote] Season 2013: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[smote] Season 2014: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[smote] Season 2015: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[smote] Season 2016: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[smote] Season 2017: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[smote] Season 2018: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[smote] Season 2019: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[smote] Season 2020: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[smote] Season 2021: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[smote] Season 2022: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[smote] Season 2023: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[smote] Season 2024: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "[smote] Season 2025: guardado match-log (41 filas)\n",
            "Guardados:\n",
            "- outputs/matchlog_season_summary_smote.csv\n",
            "- outputs/matchlog_season_summary_smote.json\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# MATCH-LOG por temporada (predicción vs valor) + export\n",
        "# =========================\n",
        "\n",
        "# --- Mapas y utilidades ---\n",
        "CLASS2TXT = {0:\"A\", 1:\"D\", 2:\"H\"}   # 0=Away,1=Draw,2=Home\n",
        "TXT2CLASS = {\"A\":0, \"D\":1, \"H\":2}\n",
        "\n",
        "def _edge_bins(edge: pd.Series,\n",
        "               bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Tramos discretos para facilitar filtros por 'valor esperado' en la app.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "def _ensure_probs_adh(y_proba: np.ndarray, classes_model: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve DataFrame de probabilidades con columnas A/D/H,\n",
        "    completando columnas ausentes con NaN si el modelo no las tuvo en train.\n",
        "    \"\"\"\n",
        "    name_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "    cols = [name_map.get(int(c), str(c)) for c in classes_model]\n",
        "    proba_df = pd.DataFrame(y_proba, columns=cols)\n",
        "    for c in [\"A\",\"D\",\"H\"]:\n",
        "        if c not in proba_df.columns:\n",
        "            proba_df[c] = np.nan\n",
        "    return proba_df[[\"A\",\"D\",\"H\"]]\n",
        "\n",
        "def _make_matchlog_from_eval(\n",
        "    df: pd.DataFrame,\n",
        "    y_test: pd.Series,\n",
        "    y_pred: np.ndarray,\n",
        "    y_proba: np.ndarray,\n",
        "    idx_test: pd.Index,\n",
        "    *,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Construye el match-log (una fila por partido del TEST de esa temporada).\n",
        "    Incluye columnas para comparar estrategia de 'Predicción' vs 'Valor'.\n",
        "    \"\"\"\n",
        "    # 1) Meta-información del propio df (alineación por índice)\n",
        "    need = [\"Date\",\"Season\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"df necesita columnas {missing} para construir el match-log.\")\n",
        "    meta = df.loc[idx_test, need].copy()\n",
        "\n",
        "    # 2) Probabilidades A/D/H y odds en mismo orden (A,D,H)\n",
        "    proba_df = _ensure_probs_adh(y_proba, classes_model=np.array([0,1,2][:y_proba.shape[1]]))\n",
        "    proba_df.index = idx_test\n",
        "    odds_df = meta[[\"B365A\",\"B365D\",\"B365H\"]].rename(columns={\"B365A\":\"A\",\"B365D\":\"D\",\"B365H\":\"H\"})\n",
        "\n",
        "    # 3) Predicción del modelo + EV de la predicción\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(CLASS2TXT)\n",
        "    idx_of = {\"A\":0,\"D\":1,\"H\":2}\n",
        "    pred_idx = pred_txt.map(idx_of).to_numpy()\n",
        "\n",
        "    P = proba_df.to_numpy()\n",
        "    O = odds_df[[\"A\",\"D\",\"H\"]].to_numpy()\n",
        "\n",
        "    out = meta.copy()\n",
        "    out[\"true_result\"]      = pd.Series(y_test, index=idx_test).values\n",
        "    out[\"predicted_result\"] = pd.Series(y_pred, index=idx_test).values\n",
        "    out[\"Pred\"]             = pred_txt.values\n",
        "\n",
        "    out[\"predicted_prob\"] = P[np.arange(len(out)), pred_idx]\n",
        "    out[\"predicted_odds\"] = O[np.arange(len(out)), pred_idx]\n",
        "    out[\"edge\"] = out[\"predicted_prob\"] * out[\"predicted_odds\"] - 1.0      # EV de la PREDICCIÓN\n",
        "\n",
        "    # 4) Estrategia de VALOR: máxima EV entre H/D/A (sin mirar la predicción)\n",
        "    ev_df = proba_df * odds_df - 1.0                                      # EV por clase\n",
        "    best_idx = ev_df[[\"A\",\"D\",\"H\"]].to_numpy().argmax(axis=1)\n",
        "    labels  = np.array([\"A\",\"D\",\"H\"])\n",
        "    out[\"value_pick\"] = labels[best_idx]\n",
        "    out[\"value_ev\"]   = ev_df.to_numpy()[np.arange(len(out)), best_idx]\n",
        "    out[\"value_prob\"] = P[np.arange(len(out)), best_idx]\n",
        "    out[\"value_odds\"] = O[np.arange(len(out)), best_idx]\n",
        "\n",
        "    # 5) Requiere cuotas completas y filtros de edge\n",
        "    mask_ok_odds = out[[\"B365H\",\"B365D\",\"B365A\"]].notna().all(axis=1)\n",
        "    out = out.loc[mask_ok_odds].copy()\n",
        "    if min_edge_pred > 0:\n",
        "        out = out.loc[out[\"edge\"] >= min_edge_pred].copy()\n",
        "    if out.empty:\n",
        "        return out\n",
        "\n",
        "    if min_edge_value is None:\n",
        "        min_edge_value = min_edge_pred\n",
        "    # Nota: para comparar estrategias, NO filtramos por value_ev por defecto (se puede activar):\n",
        "    if min_edge_value and (min_edge_value > 0):\n",
        "        out[\"use_value\"] = out[\"value_ev\"] >= min_edge_value\n",
        "    else:\n",
        "        out[\"use_value\"] = True\n",
        "\n",
        "    # 6) Beneficios de cada estrategia (stake fijo)\n",
        "    out[\"bet_return\"] = np.where(\n",
        "        out[\"predicted_result\"] == out[\"true_result\"], out[\"predicted_odds\"] * stake, 0.0\n",
        "    )\n",
        "    out[\"net_profit\"] = out[\"bet_return\"] - stake\n",
        "\n",
        "    value_idx = out[\"value_pick\"].map(idx_of).to_numpy()\n",
        "    value_hit = (value_idx == out[\"true_result\"])\n",
        "    value_ret = np.where(value_hit, out[\"value_odds\"] * stake, 0.0)\n",
        "    out[\"value_bet_return\"] = np.where(out[\"use_value\"], value_ret, 0.0)\n",
        "    out[\"value_net_profit\"] = np.where(out[\"use_value\"], out[\"value_bet_return\"] - stake, 0.0)\n",
        "\n",
        "    # 7) Columnas de apoyo para filtros en la app\n",
        "    out[\"Correct\"]       = np.where(out[\"predicted_result\"] == out[\"true_result\"], \"✓\", \"✗\")\n",
        "    out[\"value_correct\"] = np.where(value_hit, \"✓\", \"✗\")\n",
        "    out[\"edge_bin\"]      = _edge_bins(out[\"edge\"])\n",
        "    out[\"value_bin\"]     = _edge_bins(out[\"value_ev\"])\n",
        "\n",
        "    # 8) Orden temporal + formato fecha amigable\n",
        "    out[\"Date\"] = pd.to_datetime(out[\"Date\"], errors=\"coerce\")\n",
        "    out = out.sort_values([\"Date\", out.index.name or \"Season\"]).reset_index(drop=True)\n",
        "    out[\"Date\"] = out[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_matchlog_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    *,\n",
        "    model: str = \"base\",          # \"base\" | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Para cada temporada S (train ≤ S-1, test = S) entrena/evalúa el modelo escogido,\n",
        "    construye el match-log (partido a partido) con columnas de Predicción y Valor,\n",
        "    y exporta CSV/JSON por temporada + un resumen por temporada con ROI de ambas estrategias.\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    per_season_dir = out_dir / f\"matchlogs_{model}\"\n",
        "    per_season_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    season_summary = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval_no_smote(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "\n",
        "            # Si no hay test válido, sigue\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Construye match-log para esa temporada\n",
        "            ml = _make_matchlog_from_eval(\n",
        "                df, y_test, y_pred, y_proba, idx_test,\n",
        "                stake=stake, min_edge_pred=min_edge_pred, min_edge_value=min_edge_value\n",
        "            )\n",
        "            if ml.empty:\n",
        "                continue\n",
        "\n",
        "            # ROI/beneficio de cada estrategia en esa temporada\n",
        "            n_pred = len(ml)                        # pred: una apuesta por fila tras filtro\n",
        "            roi_pred = float(ml[\"net_profit\"].sum() / (stake * n_pred))\n",
        "            n_val = int(ml[\"use_value\"].sum())      # valor: si filtras por value_ev, puede ser menor\n",
        "            roi_val = float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() / (stake * n_val)) if n_val > 0 else np.nan\n",
        "\n",
        "            # Guardados por temporada\n",
        "            csv_path  = per_season_dir / f\"matchlog_{test_season}.csv\"\n",
        "            json_path = per_season_dir / f\"matchlog_{test_season}.json\"\n",
        "            ml.to_csv(csv_path, index=False)\n",
        "            ml.to_json(json_path, orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "            season_summary.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"n_pred_bets\": int(n_pred),\n",
        "                \"roi_pred\": roi_pred,\n",
        "                \"profit_pred\": float(ml[\"net_profit\"].sum()),\n",
        "                \"n_value_bets\": int(n_val),\n",
        "                \"roi_value\": roi_val,\n",
        "                \"profit_value\": float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() if n_val > 0 else 0.0),\n",
        "                \"min_edge_pred\": float(min_edge_pred),\n",
        "                \"min_edge_value\": float(min_edge_value if (min_edge_value is not None) else min_edge_pred),\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            })\n",
        "            print(f\"[{model}] Season {test_season}: guardado match-log ({len(ml)} filas)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[MATCHLOG {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    # Resumen por temporada (tabla plana + index JSON para la app)\n",
        "    if season_summary:\n",
        "        df_sum = pd.DataFrame(season_summary).sort_values(\"test_season\")\n",
        "        df_sum.to_csv(out_dir / f\"matchlog_season_summary_{model}.csv\", index=False)\n",
        "        (out_dir / f\"matchlog_season_summary_{model}.json\").write_text(\n",
        "            json.dumps(season_summary, ensure_ascii=False, indent=2),\n",
        "            encoding=\"utf-8\"\n",
        "        )\n",
        "        print(f\"Guardados:\\n- {out_dir/f'matchlog_season_summary_{model}.csv'}\\n- {out_dir/f'matchlog_season_summary_{model}.json'}\")\n",
        "    else:\n",
        "        print(\"Sin temporadas válidas para exportar matchlogs.\")\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO\n",
        "# =========================\n",
        "# Asumimos:\n",
        "# - df = df_final (con HomeTeam_norm y AwayTeam_norm)\n",
        "# - OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# BASE (sin SMOTE). Puedes ajustar min_edge_pred para exigir EV mínimo en la estrategia de predicción\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"base\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,   # prueba 0.02 / 0.05 si quieres “apostar solo cuando hay valor en la predicción”\n",
        "    min_edge_value=None   # None = no filtrar la estrategia de valor; pon 0.02/0.05 si quieres filtrarla también\n",
        ")\n",
        "\n",
        "# SMOTE (si ya tienes definidas run_logreg_eval y funciona análogo)\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"smote\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,\n",
        "    min_edge_value=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JposElvmrlP"
      },
      "source": [
        "## **COMPARACIÓN CON EL MODELO DE BET365**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4yDpcqQz-6"
      },
      "source": [
        "El modelo basado en las cuotas de Bet365 consiste en predecir siempre el resultado más probable según la probabilidad implícita."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjgMWmkQ7Dro",
        "outputId": "b079c684-f022-41ab-bc15-1ea7433ff842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2007..2007 | n=380 | ROI: -3.47% | Profit: -13.19\n",
            "[Bet365] Season 2007: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2008..2008 | n=380 | ROI: 7.91% | Profit: 30.05\n",
            "[Bet365] Season 2008: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2009..2009 | n=380 | ROI: 4.28% | Profit: 16.28\n",
            "[Bet365] Season 2009: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2010..2010 | n=380 | ROI: 9.04% | Profit: 34.36\n",
            "[Bet365] Season 2010: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2011..2011 | n=380 | ROI: -7.91% | Profit: -30.06\n",
            "[Bet365] Season 2011: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2012..2012 | n=380 | ROI: -3.74% | Profit: -14.20\n",
            "[Bet365] Season 2012: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2013..2013 | n=380 | ROI: -9.91% | Profit: -37.66\n",
            "[Bet365] Season 2013: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2014..2014 | n=380 | ROI: -6.01% | Profit: -22.84\n",
            "[Bet365] Season 2014: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2015..2015 | n=380 | ROI: -6.26% | Profit: -23.78\n",
            "[Bet365] Season 2015: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2016..2016 | n=380 | ROI: 0.06% | Profit: 0.22\n",
            "[Bet365] Season 2016: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2017..2017 | n=380 | ROI: -2.87% | Profit: -10.90\n",
            "[Bet365] Season 2017: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2018..2018 | n=380 | ROI: -12.71% | Profit: -48.30\n",
            "[Bet365] Season 2018: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2019..2019 | n=380 | ROI: -6.13% | Profit: -23.29\n",
            "[Bet365] Season 2019: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2020..2020 | n=380 | ROI: -1.94% | Profit: -7.36\n",
            "[Bet365] Season 2020: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2021..2021 | n=380 | ROI: -4.51% | Profit: -17.15\n",
            "[Bet365] Season 2021: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2022..2022 | n=380 | ROI: 1.82% | Profit: 6.93\n",
            "[Bet365] Season 2022: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2023..2023 | n=380 | ROI: 2.18% | Profit: 8.28\n",
            "[Bet365] Season 2023: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2024..2024 | n=380 | ROI: -1.80% | Profit: -6.84\n",
            "[Bet365] Season 2024: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2025..2025 | n=41 | ROI: -3.39% | Profit: -1.39\n",
            "[Bet365] Season 2025: OK (41 partidos)\n",
            "Guardados:\n",
            "- outputs/bet365_grid.json\n",
            "- outputs/bet365_metrics_by_season.csv\n",
            "- outputs/bet365_matchlogs/matchlog_<SEASON>.csv/json\n",
            "Guardados comparativos temporada:\n",
            "- outputs/comparison_season_base_vs_bet365.csv\n",
            "- outputs/comparison_season_base_vs_bet365.json\n",
            "Guardados comparativos por partido (2025):\n",
            "- outputs/comparison_matchlog_2025_base_vs_bet365.csv\n",
            "- outputs/comparison_matchlog_2025_base_vs_bet365.json\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Bet365 Baseline + Export + Comparaciones\n",
        "# =========================\n",
        "\n",
        "# --- Split temporal (idéntico a tu flujo) ---\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "\n",
        "# --- Evaluación Bet365 en un rango temporal ---\n",
        "def evaluate_bet365_baseline(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    round_decimals: int = 4,\n",
        "    stake: float = 1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Baseline Bet365:\n",
        "      - TEST: (train_until, test_until]\n",
        "      - Prob implícitas normalizadas\n",
        "      - Métricas: accuracy, log_loss, brier\n",
        "      - ROI apostando al favorito Bet365\n",
        "      - Devuelve (tabla partido a partido, métricas)\n",
        "    \"\"\"\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rng}).\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 2) Cuotas desde df\n",
        "    need_cols = ['B365H','B365D','B365A']\n",
        "    missing = [c for c in need_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"df debe contener columnas de cuotas {missing}\")\n",
        "\n",
        "    odds_df = df.loc[idx, need_cols].copy()\n",
        "    mask_ok = odds_df.notna().all(axis=1)\n",
        "    for c in need_cols:\n",
        "        mask_ok &= (pd.to_numeric(odds_df[c], errors='coerce') > 0)\n",
        "    odds_df = odds_df.loc[mask_ok].astype(float)\n",
        "    y_test  = y_test.loc[mask_ok]\n",
        "    idx     = odds_df.index\n",
        "\n",
        "    if odds_df.empty:\n",
        "        print(\"⚠️ No hay partidos con cuotas B365 completas en el TEST.\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 3) Prob implícitas normalizadas\n",
        "    inv = 1.0 / odds_df[need_cols]\n",
        "    overround = inv.sum(axis=1).replace(0, np.nan)\n",
        "    prob_norm = inv.div(overround, axis=0)\n",
        "\n",
        "    # 4) Proba en orden de clases (0=A,1=D,2=H) y pick\n",
        "    bet365_proba = np.column_stack([\n",
        "        prob_norm['B365A'].to_numpy(),\n",
        "        prob_norm['B365D'].to_numpy(),\n",
        "        prob_norm['B365H'].to_numpy()\n",
        "    ])\n",
        "    bet365_pred = bet365_proba.argmax(axis=1)\n",
        "\n",
        "    # 5) Métricas\n",
        "    classes = [0,1,2]\n",
        "    acc = float(accuracy_score(y_test, bet365_pred))\n",
        "    ll  = float(log_loss(y_test, bet365_proba, labels=classes))\n",
        "    y_bin = label_binarize(y_test, classes=classes)\n",
        "    brier = float(np.mean(np.sum((bet365_proba - y_bin)**2, axis=1)))\n",
        "\n",
        "    # 6) Tabla partido a partido\n",
        "    out = pd.DataFrame(index=idx)\n",
        "    extra = {}\n",
        "    for c in ['Date','Season','HomeTeam_norm','AwayTeam_norm']:\n",
        "        extra[c] = df.loc[idx, c] if c in df.columns else pd.Series(index=idx, dtype='object')\n",
        "\n",
        "    out['Date'] = pd.to_datetime(extra['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "    if 'Season' in df.columns:\n",
        "        out['Season'] = extra['Season'].astype('Int64')\n",
        "    out['HomeTeam_norm'] = extra['HomeTeam_norm'].astype('string')\n",
        "    out['AwayTeam_norm'] = extra['AwayTeam_norm'].astype('string')\n",
        "\n",
        "    out['B365H'] = odds_df['B365H'].round(round_decimals)\n",
        "    out['B365D'] = odds_df['B365D'].round(round_decimals)\n",
        "    out['B365A'] = odds_df['B365A'].round(round_decimals)\n",
        "    out['p_H']   = prob_norm['B365H'].round(round_decimals)\n",
        "    out['p_D']   = prob_norm['B365D'].round(round_decimals)\n",
        "    out['p_A']   = prob_norm['B365A'].round(round_decimals)\n",
        "    out['true_result'] = y_test.values\n",
        "    out['bet365_pred'] = bet365_pred\n",
        "\n",
        "    # 7) ROI del favorito Bet365\n",
        "    pick_idx = bet365_pred\n",
        "    odds_mat = np.column_stack([odds_df['B365A'], odds_df['B365D'], odds_df['B365H']])\n",
        "    picked_odds = odds_mat[np.arange(len(odds_mat)), pick_idx]\n",
        "    out['picked_odds'] = picked_odds\n",
        "    out['bet_return']  = np.where(out['bet365_pred'] == out['true_result'], out['picked_odds'] * stake, 0.0)\n",
        "    out['net_profit']  = out['bet_return'] - stake\n",
        "    out['Cum_net_profit'] = out['net_profit'].cumsum()\n",
        "\n",
        "    # Edge informativo del pick\n",
        "    pA = prob_norm['B365A'].to_numpy()\n",
        "    pD = prob_norm['B365D'].to_numpy()\n",
        "    pH = prob_norm['B365H'].to_numpy()\n",
        "    p_mat = np.column_stack([pA,pD,pH])\n",
        "    out['edge_b365_pick'] = (p_mat[np.arange(len(p_mat)), pick_idx] * picked_odds) - 1.0\n",
        "\n",
        "    n_eval = int(len(out))\n",
        "    total_profit = float(out['net_profit'].sum())\n",
        "    investment_total = float(stake * n_eval)\n",
        "    roi = float(total_profit / investment_total) if investment_total > 0 else np.nan\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"log_loss\": ll,\n",
        "        \"brier\": brier,\n",
        "        \"n_test_with_odds\": n_eval,\n",
        "        \"roi\": roi,\n",
        "        \"profit_total\": total_profit,\n",
        "        \"investment_total\": investment_total,   # << añadido\n",
        "        \"stake\": float(stake)\n",
        "    }\n",
        "\n",
        "    rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    print(\"Baseline Bet365 — Prob. implícitas normalizadas\")\n",
        "    print(f\"Rango TEST: Seasons {rng} | n={n_eval} | ROI: {roi*100:.2f}% | Profit: {total_profit:.2f}\")\n",
        "\n",
        "    return out.reset_index(drop=True), metrics\n",
        "\n",
        "\n",
        "# --- Grid por temporada + export ---\n",
        "def build_bet365_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 4,\n",
        "    save_matchlogs: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Para cada temporada S (train ≤ S-1, test = S):\n",
        "      - matchlog Bet365 (opcional CSV/JSON)\n",
        "      - resumen por temporada (JSON+CSV) con ROI y investment_total\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    per_season_dir = out_dir / \"bet365_matchlogs\"\n",
        "    if save_matchlogs:\n",
        "        per_season_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    rows_json, rows_flat = [], []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:  # sin historial\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tbl, met = evaluate_bet365_baseline(\n",
        "                df,\n",
        "                train_until_season=train_until,\n",
        "                test_until_season=test_season,\n",
        "                with_odds=with_odds,\n",
        "                round_decimals=round_decimals,\n",
        "                stake=stake\n",
        "            )\n",
        "            if tbl.empty:\n",
        "                continue\n",
        "\n",
        "            if save_matchlogs:\n",
        "                (per_season_dir / f\"matchlog_{test_season}.csv\").write_text(\n",
        "                    tbl.to_csv(index=False), encoding=\"utf-8\"\n",
        "                )\n",
        "                (per_season_dir / f\"matchlog_{test_season}.json\").write_text(\n",
        "                    tbl.to_json(orient=\"records\", force_ascii=False, indent=2),\n",
        "                    encoding=\"utf-8\"\n",
        "                )\n",
        "\n",
        "            rows_json.append({\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"metrics\": {\n",
        "                    \"accuracy\": float(met[\"accuracy\"]),\n",
        "                    \"log_loss\": float(met[\"log_loss\"]),\n",
        "                    \"brier\":    float(met[\"brier\"]),\n",
        "                    \"roi\":      float(met[\"roi\"]),\n",
        "                    \"profit_total\": float(met[\"profit_total\"]),\n",
        "                    \"investment_total\": float(met[\"investment_total\"]),  # << añadido\n",
        "                    \"n_test\":   int(met[\"n_test_with_odds\"]),\n",
        "                    \"stake\":    float(met[\"stake\"])\n",
        "                }\n",
        "            })\n",
        "            rows_flat.append({\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"acc\": float(met[\"accuracy\"]),\n",
        "                \"logloss\": float(met[\"log_loss\"]),\n",
        "                \"brier\": float(met[\"brier\"]),\n",
        "                \"roi\": float(met[\"roi\"]),\n",
        "                \"profit_total\": float(met[\"profit_total\"]),\n",
        "                \"investment_total\": float(met[\"investment_total\"]),      # << añadido\n",
        "                \"n_test\": int(met[\"n_test_with_odds\"]),\n",
        "            })\n",
        "\n",
        "            print(f\"[Bet365] Season {test_season}: OK ({len(tbl)} partidos)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[BET365 SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    (out_dir / \"bet365_grid.json\").write_text(json.dumps(rows_json, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    pd.DataFrame(rows_flat).sort_values(\"test_season\").to_csv(out_dir / \"bet365_metrics_by_season.csv\", index=False)\n",
        "\n",
        "    print(\"Guardados:\")\n",
        "    print(f\"- {out_dir/'bet365_grid.json'}\")\n",
        "    print(f\"- {out_dir/'bet365_metrics_by_season.csv'}\")\n",
        "    if save_matchlogs:\n",
        "        print(f\"- {out_dir/'bet365_matchlogs'}/matchlog_<SEASON>.csv/json\")\n",
        "\n",
        "\n",
        "# --- Comparación modelo vs Bet365 por temporada ---\n",
        "def build_season_comparison_model_vs_bet365(\n",
        "    out_dir: Path,\n",
        "    model_tag: str = \"base\"  # coincide con el nombre usado en roi_by_season_<tag>.csv\n",
        "):\n",
        "    \"\"\"\n",
        "    Une outputs/roi_by_season_<model_tag>.csv (tu modelo) con\n",
        "    outputs/bet365_metrics_by_season.csv y calcula deltas.\n",
        "    \"\"\"\n",
        "    df_m = pd.read_csv(out_dir / f\"roi_by_season_{model_tag}.csv\")\n",
        "    df_b = pd.read_csv(out_dir / \"bet365_metrics_by_season.csv\")\n",
        "\n",
        "    # Normaliza nombres por si difieren\n",
        "    df_m = df_m.rename(columns={\"profit_total\":\"profit_model\", \"roi\":\"roi_model\", \"n_bets\":\"n_bets_model\"})\n",
        "    df_b = df_b.rename(columns={\"profit_total\":\"profit_bet365\", \"roi\":\"roi_bet365\", \"n_test\":\"n_bets_bet365\"})\n",
        "\n",
        "    if \"stake\" not in df_m.columns:\n",
        "        df_m[\"stake\"] = 1.0  # fallback si faltara\n",
        "    if \"stake\" not in df_b.columns:\n",
        "        df_b[\"stake\"] = 1.0\n",
        "\n",
        "    df_m[\"investment_total_model\"] = df_m[\"stake\"] * df_m[\"n_bets_model\"]\n",
        "    df_b[\"investment_total_bet365\"] = df_b[\"stake\"] * df_b[\"n_bets_bet365\"]\n",
        "\n",
        "    comp = pd.merge(df_m, df_b, on=[\"test_season\",\"train_until\"], how=\"inner\", suffixes=(\"_m\",\"_b\"))\n",
        "    comp[\"delta_roi\"]    = comp[\"roi_model\"]    - comp[\"roi_bet365\"]\n",
        "    comp[\"delta_profit\"] = comp[\"profit_model\"] - comp[\"profit_bet365\"]\n",
        "\n",
        "    comp_sorted = comp.sort_values(\"test_season\")\n",
        "    comp_sorted.to_csv(out_dir / f\"comparison_season_{model_tag}_vs_bet365.csv\", index=False)\n",
        "    (out_dir / f\"comparison_season_{model_tag}_vs_bet365.json\").write_text(\n",
        "        comp_sorted.to_json(orient=\"records\", force_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(f\"Guardados comparativos temporada:\\n- {out_dir/f'comparison_season_{model_tag}_vs_bet365.csv'}\\n- {out_dir/f'comparison_season_{model_tag}_vs_bet365.json'}\")\n",
        "\n",
        "\n",
        "# --- Comparación por partido (una temporada) modelo vs Bet365 ---\n",
        "def build_match_comparison_for_season(\n",
        "    out_dir: Path,\n",
        "    season: int,\n",
        "    model_tag: str = \"base\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Une matchlogs:\n",
        "      - outputs/matchlogs_<model_tag>/matchlog_<season>.csv\n",
        "      - outputs/bet365_matchlogs/matchlog_<season>.csv\n",
        "    por (Date, HomeTeam_norm, AwayTeam_norm) y calcula deltas por partido.\n",
        "    \"\"\"\n",
        "    ml_model = pd.read_csv(out_dir / f\"matchlogs_{model_tag}\" / f\"matchlog_{season}.csv\")\n",
        "    ml_b365  = pd.read_csv(out_dir / \"bet365_matchlogs\" / f\"matchlog_{season}.csv\")\n",
        "\n",
        "    key = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\"]\n",
        "    both = pd.merge(ml_model, ml_b365, on=key, how=\"inner\", suffixes=(\"_model\",\"_b365\"))\n",
        "\n",
        "    # Columnas mínimas de interés\n",
        "    keep = key + [\n",
        "        \"Season_model\",\"true_result_model\",\"predicted_result\",\"Pred\",\"edge\",\n",
        "        \"predicted_odds\",\"net_profit\",\"Cum_net_profit\",\n",
        "        \"bet365_pred\",\"picked_odds\",\"net_profit_b365\",\"Cum_net_profit_b365\"\n",
        "    ]\n",
        "    # Renombra si no existen exactamente\n",
        "    if \"net_profit_model\" in both.columns:\n",
        "        both[\"net_profit\"] = both[\"net_profit_model\"]\n",
        "    if \"Cum_net_profit_model\" in both.columns:\n",
        "        both[\"Cum_net_profit\"] = both[\"Cum_net_profit_model\"]\n",
        "    if \"net_profit_b365\" not in both.columns and \"net_profit_b365\" not in keep:\n",
        "        if \"net_profit_b365\" in both.columns:\n",
        "            pass\n",
        "\n",
        "    # Deltas por partido\n",
        "    both[\"delta_profit\"] = both[\"net_profit\"] - both[\"net_profit_b365\"]\n",
        "\n",
        "    # Orden temporal\n",
        "    both[\"Date\"] = pd.to_datetime(both[\"Date\"], errors=\"coerce\")\n",
        "    both = both.sort_values([\"Date\"]).reset_index(drop=True)\n",
        "    both[\"Date\"] = both[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    out_csv  = out_dir / f\"comparison_matchlog_{season}_{model_tag}_vs_bet365.csv\"\n",
        "    out_json = out_dir / f\"comparison_matchlog_{season}_{model_tag}_vs_bet365.json\"\n",
        "    both.to_csv(out_csv, index=False)\n",
        "    both.to_json(out_json, orient=\"records\", force_ascii=False, indent=2)\n",
        "    print(f\"Guardados comparativos por partido ({season}):\\n- {out_csv}\\n- {out_json}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO\n",
        "# =========================\n",
        "# OUT = ROOT / \"outputs\"\n",
        "# OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Generar baseline Bet365 por temporada (incluye investment_total y matchlogs)\n",
        "build_bet365_grid(df, out_dir=OUT, seasons=None, with_odds=True, stake=1.0, save_matchlogs=True)\n",
        "\n",
        "# 2) Comparar tu modelo vs Bet365 por temporada (usa tu CSV: roi_by_season_base.csv)\n",
        "build_season_comparison_model_vs_bet365(OUT, model_tag=\"base\")\n",
        "\n",
        "# 3) Comparar por partido en una temporada concreta (usa tus matchlogs y los de Bet365)\n",
        "build_match_comparison_for_season(OUT, season=2025, model_tag=\"base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E9eX18fI5ox",
        "outputId": "7856d766-2002-453d-d907-4f3c5ddba994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2025..2025 | n=41 | ROI: -3.39% | Profit: -1.39\n"
          ]
        }
      ],
      "source": [
        "tabla_bet365, met_bet365 = evaluate_bet365_baseline(df, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9Pd1LJtEb5Lh"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Datos para GRAFICAR en la web: Modelo vs Bet365 (curvas acumuladas)\n",
        "# Compatible con _prep_test_split que devuelve 2 o 3 valores\n",
        "# ============================================\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "CLASS2LABEL = {0: \"Away\", 1: \"Draw\", 2: \"Home\"}\n",
        "\n",
        "def _ensure_probs_adh(y_proba: np.ndarray, classes_model) -> pd.DataFrame:\n",
        "    name_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "    cols = [name_map.get(int(c), str(c)) for c in classes_model]\n",
        "    proba_df = pd.DataFrame(y_proba, columns=cols)\n",
        "    for c in [\"A\",\"D\",\"H\"]:\n",
        "        if c not in proba_df.columns:\n",
        "            proba_df[c] = np.nan\n",
        "    return proba_df[[\"A\",\"D\",\"H\"]]\n",
        "\n",
        "def _prep_test_split_flex(df, train_until_season, with_odds, test_until_season):\n",
        "    \"\"\"Envuelve tu _prep_test_split y devuelve siempre (X_test, y_test, idx_test).\"\"\"\n",
        "    out = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if not isinstance(out, tuple):\n",
        "        raise ValueError(\"Respuesta inesperada de _prep_test_split.\")\n",
        "    if len(out) == 3:\n",
        "        X_test, y_test, idx_test = out\n",
        "    elif len(out) == 2:\n",
        "        X_test, y_test = out\n",
        "        idx_test = X_test.index\n",
        "    else:\n",
        "        raise ValueError(\"Respuesta inesperada de _prep_test_split (ni 2 ni 3 elementos).\")\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "def build_cumprofit_series_one_season(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    *, train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3\n",
        ") -> tuple[pd.DataFrame, dict]:\n",
        "\n",
        "    # 1) TEST (flex)\n",
        "    X_test, y_test, idx = _prep_test_split_flex(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 2) Alinear + predecir modelo\n",
        "    X_test = _align_to_fit_columns(X_test, scaler)\n",
        "    Xs   = scaler.transform(X_test)\n",
        "    yhat = model.predict(Xs)\n",
        "    proba = model.predict_proba(Xs)\n",
        "    classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "\n",
        "    # 3) Meta y cuotas\n",
        "    need = [\"Date\",\"Season\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    miss = [c for c in need if c not in df.columns]\n",
        "    if miss:\n",
        "        raise ValueError(f\"df necesita columnas {miss}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "\n",
        "    mask_ok = meta[[\"B365H\",\"B365D\",\"B365A\"]].notna().all(axis=1)\n",
        "    for c in [\"B365H\",\"B365D\",\"B365A\"]:\n",
        "        mask_ok &= (pd.to_numeric(meta[c], errors=\"coerce\") > 0)\n",
        "    if not mask_ok.any():\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    meta   = meta.loc[mask_ok].copy()\n",
        "    y_test = y_test.loc[mask_ok]\n",
        "    # re-alinear pred y proba a las filas válidas\n",
        "    yhat   = pd.Series(yhat, index=idx).loc[mask_ok].to_numpy()\n",
        "    proba  = proba[mask_ok.values, :]\n",
        "\n",
        "    # 4) Prob implícitas Bet365 normalizadas y predicción Bet365\n",
        "    odds = meta[[\"B365H\",\"B365D\",\"B365A\"]].astype(float)\n",
        "    inv  = 1.0 / odds\n",
        "    over = inv.sum(axis=1).replace(0, np.nan)\n",
        "    pnorm = inv.div(over, axis=0)\n",
        "    bet365_proba_mat = np.column_stack([\n",
        "        pnorm[\"B365A\"].to_numpy(),  # Away -> 0\n",
        "        pnorm[\"B365D\"].to_numpy(),  # Draw -> 1\n",
        "        pnorm[\"B365H\"].to_numpy(),  # Home -> 2\n",
        "    ])\n",
        "    bet365_pred = bet365_proba_mat.argmax(axis=1)\n",
        "\n",
        "    # 5) Retornos por partido y acumulados (stake=1)\n",
        "    odds_matrix = np.column_stack([odds[\"B365A\"], odds[\"B365D\"], odds[\"B365H\"]])  # A,D,H\n",
        "    idx_map = {0:0,1:1,2:2}\n",
        "    idx_model  = pd.Series(yhat).map(idx_map).to_numpy()\n",
        "    idx_b365   = pd.Series(bet365_pred).map(idx_map).to_numpy()\n",
        "\n",
        "    model_ret = np.where(yhat == y_test.values, odds_matrix[np.arange(len(yhat)), idx_model]-1.0, -1.0)\n",
        "    b365_ret  = np.where(bet365_pred == y_test.values, odds_matrix[np.arange(len(yhat)), idx_b365]-1.0, -1.0)\n",
        "\n",
        "    # 6) Orden temporal y acumulados\n",
        "    dates = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    order = np.argsort(dates.fillna(pd.Timestamp(\"1970-01-01\")).values)\n",
        "    dates = dates.iloc[order].dt.strftime(\"%Y-%m-%d\").reset_index(drop=True)\n",
        "\n",
        "    model_ret = pd.Series(model_ret).iloc[order].reset_index(drop=True).round(round_decimals)\n",
        "    b365_ret  = pd.Series(b365_ret ).iloc[order].reset_index(drop=True).round(round_decimals)\n",
        "    model_cum = model_ret.cumsum().round(round_decimals)\n",
        "    b365_cum  = b365_ret.cumsum().round(round_decimals)\n",
        "\n",
        "    home = meta[\"HomeTeam_norm\"].iloc[order].astype(\"string\").reset_index(drop=True)\n",
        "    away = meta[\"AwayTeam_norm\"].iloc[order].astype(\"string\").reset_index(drop=True)\n",
        "    true_txt  = pd.Series(y_test.values).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "    model_txt = pd.Series(yhat).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "    b365_txt  = pd.Series(bet365_pred).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "\n",
        "    series_df = pd.DataFrame({\n",
        "        \"match_num\": np.arange(1, len(model_cum)+1, dtype=int),\n",
        "        \"date\": dates,\n",
        "        \"model_cum\": model_cum,\n",
        "        \"bet365_cum\": b365_cum,\n",
        "        \"model_ret\": model_ret,\n",
        "        \"bet365_ret\": b365_ret,\n",
        "        \"home\": home,\n",
        "        \"away\": away,\n",
        "        \"true_txt\": true_txt,\n",
        "        \"model_txt\": model_txt,\n",
        "        \"bet365_txt\": b365_txt,\n",
        "    })\n",
        "\n",
        "    n = int(len(series_df))\n",
        "    final_model = float(model_cum.iloc[-1]) if n else 0.0\n",
        "    final_b365  = float(b365_cum.iloc[-1]) if n else 0.0\n",
        "    summary = {\n",
        "        \"train_until\": int(train_until_season),\n",
        "        \"test_season\": int(test_until_season if test_until_season is not None else df.loc[idx, \"Season\"].max()),\n",
        "        \"n_matches\": n,\n",
        "        \"profit_model\": final_model,\n",
        "        \"profit_bet365\": final_b365,\n",
        "        \"roi_model\": (final_model / n) if n else np.nan,\n",
        "        \"roi_bet365\": (final_b365 / n) if n else np.nan,\n",
        "    }\n",
        "    return series_df, summary\n",
        "\n",
        "def export_cumprofit_curves_for_streamlit(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    out_dir: Path,\n",
        "    *, seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3\n",
        "):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    curves_dir = out_dir / \"cumprofit_curves\"\n",
        "    curves_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    index_rows = []\n",
        "    for season in seasons:\n",
        "        train_until = season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        series_df, summary = build_cumprofit_series_one_season(\n",
        "            df, model, scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=season,\n",
        "            with_odds=with_odds,\n",
        "            stake=stake,\n",
        "            round_decimals=round_decimals\n",
        "        )\n",
        "        if series_df.empty:\n",
        "            continue\n",
        "\n",
        "        # CSV\n",
        "        csv_path = curves_dir / f\"cumprofit_{season}.csv\"\n",
        "        series_df.to_csv(csv_path, index=False)\n",
        "\n",
        "        # JSON compacto\n",
        "        payload = {\n",
        "            \"train_until\": summary[\"train_until\"],\n",
        "            \"test_season\": summary[\"test_season\"],\n",
        "            \"n_matches\": summary[\"n_matches\"],\n",
        "            \"series\": [\n",
        "                {\n",
        "                    \"i\": int(r.match_num),\n",
        "                    \"d\": str(r.date),\n",
        "                    \"m\": float(r.model_cum),\n",
        "                    \"b\": float(r.bet365_cum),\n",
        "                    \"hm\": str(r.home),\n",
        "                    \"aw\": str(r.away),\n",
        "                    \"t\":  str(r.true_txt),\n",
        "                    \"pm\": str(r.model_txt),\n",
        "                    \"pb\": str(r.bet365_txt),\n",
        "                } for _, r in series_df.iterrows()\n",
        "            ],\n",
        "            \"final\": {\n",
        "                \"model\": float(summary[\"profit_model\"]),\n",
        "                \"bet365\": float(summary[\"profit_bet365\"]),\n",
        "                \"roi_model\": float(summary[\"roi_model\"]),\n",
        "                \"roi_bet365\": float(summary[\"roi_bet365\"]),\n",
        "            }\n",
        "        }\n",
        "        (curves_dir / f\"cumprofit_{season}.json\").write_text(\n",
        "            json.dumps(payload, ensure_ascii=False), encoding=\"utf-8\"\n",
        "        )\n",
        "\n",
        "        index_rows.append({\n",
        "            \"test_season\": int(season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_matches\": int(summary[\"n_matches\"]),\n",
        "            \"profit_model\": float(summary[\"profit_model\"]),\n",
        "            \"profit_bet365\": float(summary[\"profit_bet365\"]),\n",
        "            \"roi_model\": float(summary[\"roi_model\"]),\n",
        "            \"roi_bet365\": float(summary[\"roi_bet365\"]),\n",
        "            \"csv_file\": f\"cumprofit_{season}.csv\",\n",
        "            \"json_file\": f\"cumprofit_{season}.json\",\n",
        "        })\n",
        "        print(f\"[CURVA] Season {season}: {len(series_df)} puntos → guardado CSV/JSON.\")\n",
        "\n",
        "    if index_rows:\n",
        "        idx_df = pd.DataFrame(index_rows).sort_values(\"test_season\")\n",
        "        idx_df.to_csv(out_dir / \"cumprofit_index.csv\", index=False)\n",
        "        (out_dir / \"cumprofit_index.json\").write_text(\n",
        "            json.dumps(index_rows, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
        "        )\n",
        "        print(\"Guardados:\\n-\", out_dir / \"cumprofit_index.csv\",\n",
        "              \"\\n-\", out_dir / \"cumprofit_index.json\",\n",
        "              f\"\\n- {curves_dir}/cumprofit_<SEASON>.csv / .json\")\n",
        "    else:\n",
        "        print(\"No se generaron curvas (no hubo TEST válido con cuotas).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYev8_lXX1Sc",
        "outputId": "b6a0ea22-9ebb-4f1f-98c7-51c001fed5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CURVA] Season 2007: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2008: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2009: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2010: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2011: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2012: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2013: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2014: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2015: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2016: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2017: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2018: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2019: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2020: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2021: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2022: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2023: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2024: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2025: 41 puntos → guardado CSV/JSON.\n",
            "Guardados:\n",
            "- outputs/cumprofit_index.csv \n",
            "- outputs/cumprofit_index.json \n",
            "- outputs/cumprofit_curves/cumprofit_<SEASON>.csv / .json\n"
          ]
        }
      ],
      "source": [
        "# OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "export_cumprofit_curves_for_streamlit(\n",
        "    df=df,\n",
        "    model=model,\n",
        "    scaler=scaler,\n",
        "    out_dir=OUT,\n",
        "    seasons=None,\n",
        "    with_odds=True,\n",
        "    stake=1.0,\n",
        "    round_decimals=3\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ny_spsZP25IM",
        "u-LZWUpHKgiI",
        "_AUraRaeqPH_",
        "LKjn9DwWtgyl",
        "DmmpBR0ity_a",
        "pp0H3HmVus9U",
        "tpTI1gP6z03D",
        "CoH2Hx_s2EqC",
        "F3OYzHaq3CeB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
