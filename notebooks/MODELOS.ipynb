{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Parámetros (se pueden sobreescribir en CI) ---\n",
        "RUN_DATE = \"2025-09-15\"\n",
        "SEASON   = \"2025_26\"\n",
        "MATCHDAY = None\n",
        "MODEL_VERSION = \"xgb-local\"\n",
        "\n",
        "# --- Rutas coherentes local/CI ---\n",
        "from pathlib import Path\n",
        "ROOT   = Path.cwd()\n",
        "DATA   = ROOT / \"data\"\n",
        "RAW    = DATA / \"01_raw\"\n",
        "PROC   = DATA / \"02_processed\"\n",
        "FEAT   = DATA / \"03_features\"\n",
        "MODELS = DATA / \"04_models\"\n",
        "OUT    = ROOT / \"outputs\"\n",
        "\n",
        "for p in [RAW, PROC, FEAT, MODELS, OUT]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Reproducibilidad\n",
        "import random, numpy as np\n",
        "random.seed(42); np.random.seed(42)"
      ],
      "metadata": {
        "id": "EzFV5f4-L4Ox"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, json\n",
        "\n",
        "def load_feat(name: str):\n",
        "    return pd.read_parquet(FEAT / name)\n",
        "\n",
        "def save_model(obj, name: str):\n",
        "    from joblib import dump\n",
        "    MODELS.mkdir(parents=True, exist_ok=True)\n",
        "    dump(obj, MODELS / name)\n",
        "\n",
        "def save_predictions(df: pd.DataFrame, name: str = \"predictions_next.csv\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(OUT / name, index=False)\n",
        "\n",
        "def save_json(obj, name: str = \"metrics_overview.json\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    with open(OUT / name, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "qZs2bMOYL7I7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny_spsZP25IM"
      },
      "source": [
        "# **MODELOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v6i6bPn0tuc4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREDICCIÓN: Logistic Regression multinomial**"
      ],
      "metadata": {
        "id": "u-LZWUpHKgiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oqodyksQuVIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "38c5ce05-966e-4d9d-f63d-3162c1d6728a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leído: /content/data/03_features/df_final.parquet · filas= 7271 · cols= 72\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   B365A  B365D  B365H        Date FTR        h_elo        a_elo  Season  \\\n",
              "0   6.00    3.6   1.57  2006-08-26   H  1857.375122  1726.076904    2006   \n",
              "1   3.75    3.2   2.00  2006-08-27   D  1755.359253  1701.137573    2006   \n",
              "\n",
              "   home_avg_shots_last10  home_avg_shotsontarget_last10  ...  \\\n",
              "0                   11.2                            4.9  ...   \n",
              "1                   10.5                            3.4  ...   \n",
              "\n",
              "   a_squad_size_prev_season  a_pct_foreigners_prev_season  has_xg_data  \\\n",
              "0                      33.0                         24.24            0   \n",
              "1                      31.0                         22.58            0   \n",
              "\n",
              "   target  home_playstyle_defensivo  home_playstyle_equilibrado  \\\n",
              "0     2.0                     False                       False   \n",
              "1     1.0                     False                        True   \n",
              "\n",
              "   home_playstyle_ofensivo  away_playstyle_defensivo  \\\n",
              "0                     True                      True   \n",
              "1                    False                     False   \n",
              "\n",
              "   away_playstyle_equilibrado  away_playstyle_ofensivo  \n",
              "0                       False                    False  \n",
              "1                        True                    False  \n",
              "\n",
              "[2 rows x 72 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82dabe72-9403-4b8b-b419-42b771bc097b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B365A</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365H</th>\n",
              "      <th>Date</th>\n",
              "      <th>FTR</th>\n",
              "      <th>h_elo</th>\n",
              "      <th>a_elo</th>\n",
              "      <th>Season</th>\n",
              "      <th>home_avg_shots_last10</th>\n",
              "      <th>home_avg_shotsontarget_last10</th>\n",
              "      <th>...</th>\n",
              "      <th>a_squad_size_prev_season</th>\n",
              "      <th>a_pct_foreigners_prev_season</th>\n",
              "      <th>has_xg_data</th>\n",
              "      <th>target</th>\n",
              "      <th>home_playstyle_defensivo</th>\n",
              "      <th>home_playstyle_equilibrado</th>\n",
              "      <th>home_playstyle_ofensivo</th>\n",
              "      <th>away_playstyle_defensivo</th>\n",
              "      <th>away_playstyle_equilibrado</th>\n",
              "      <th>away_playstyle_ofensivo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.00</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2006-08-26</td>\n",
              "      <td>H</td>\n",
              "      <td>1857.375122</td>\n",
              "      <td>1726.076904</td>\n",
              "      <td>2006</td>\n",
              "      <td>11.2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>D</td>\n",
              "      <td>1755.359253</td>\n",
              "      <td>1701.137573</td>\n",
              "      <td>2006</td>\n",
              "      <td>10.5</td>\n",
              "      <td>3.4</td>\n",
              "      <td>...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>22.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 72 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82dabe72-9403-4b8b-b419-42b771bc097b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82dabe72-9403-4b8b-b419-42b771bc097b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82dabe72-9403-4b8b-b419-42b771bc097b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3bb59c76-9de7-45e9-83f4-743c46298aec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3bb59c76-9de7-45e9-83f4-743c46298aec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3bb59c76-9de7-45e9-83f4-743c46298aec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)\n",
        "\n",
        "print(\"Leído:\", IN_PATH, \"· filas=\", len(df), \"· cols=\", df.shape[1])\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin SMOTE:"
      ],
      "metadata": {
        "id": "Z9p6IXV2flpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (BASELINE, sin SMOTE) + B365 + export\n",
        "# =========================\n",
        "\n",
        "# --- Parámetros del rango a predecir ---\n",
        "PRED_SEASON = 2025\n",
        "start_date  = pd.to_datetime(\"2025-09-19\").date()\n",
        "end_date    = pd.to_datetime(\"2025-09-21\").date()\n",
        "\n",
        "# --- Normaliza fechas y carga df_old con nombres ---\n",
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "IN_PATH_OLD = None\n",
        "for p in [PROC/\"df_new_features.parquet\", PROC/\"df_clean_vars.parquet\", PROC/\"df_new_features.parquet\"]:\n",
        "    if p.exists(): IN_PATH_OLD = p; break\n",
        "assert IN_PATH_OLD is not None, \"No encuentro un parquet con nombres en PROC/\"\n",
        "\n",
        "df_old = pd.read_parquet(IN_PATH_OLD)\n",
        "df_old[\"Date\"] = pd.to_datetime(df_old[\"Date\"]).dt.date\n",
        "\n",
        "# --- Índices a predecir (con orden estable por fecha+índice) ---\n",
        "mask_pred = (\n",
        "    (df[\"Season\"] == PRED_SEASON) &\n",
        "    (df[\"Date\"] >= start_date) &\n",
        "    (df[\"Date\"] <= end_date)\n",
        ")\n",
        "pred_idx = (\n",
        "    df.loc[mask_pred]\n",
        "      .assign(_idx=lambda x: x.index)\n",
        "      .sort_values([\"Date\",\"_idx\"])[\"_idx\"]\n",
        "      .tolist()\n",
        ")\n",
        "print(f\"[BASE] partidos a predecir: {len(pred_idx)} en {start_date}–{end_date}\")\n",
        "\n",
        "# --- X,y evitando fugas (tu selección original) ---\n",
        "drop_cols = [\n",
        "    'FTR','target','Date','has_xg_data','overround','pimp2','B365D',\n",
        "    'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6'\n",
        "]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df[\"target\"]\n",
        "\n",
        "mask_train = (~mask_pred) & (y.notna())\n",
        "X_train = X.loc[mask_train].copy()\n",
        "y_train = y.loc[mask_train].astype(int)\n",
        "X_pred  = X.loc[pred_idx].copy()\n",
        "\n",
        "# quitar 'Season' si queda y alinear columnas\n",
        "for D in (X_train, X_pred):\n",
        "    if \"Season\" in D.columns: D.drop(columns=[\"Season\"], inplace=True)\n",
        "X_pred = X_pred.reindex(columns=X_train.columns, fill_value=np.nan)\n",
        "\n",
        "# --- Modelo baseline (igual al tuyo) ---\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# --- Predicción ---\n",
        "proba_pred  = pipe.predict_proba(X_pred)\n",
        "pred_labels = pipe.predict(X_pred)\n",
        "\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes    = list(pipe.named_steps[\"logreg\"].classes_)  # [0,1,2]\n",
        "pred_1x2   = pd.Series(pred_labels).map(class_map).values\n",
        "\n",
        "proba_df = pd.DataFrame(proba_pred, columns=[class_map[c] for c in classes])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df.columns: proba_df[lab] = np.nan\n",
        "proba_df = proba_df[[\"H\",\"D\",\"A\"]]\n",
        "\n",
        "# --- Nombres y cuotas B365 ---\n",
        "old_slice = (\n",
        "    df_old[(df_old[\"Season\"] == PRED_SEASON) &\n",
        "           (df_old[\"Date\"] >= start_date) &\n",
        "           (df_old[\"Date\"] <= end_date)]\n",
        "      [[\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\"]]\n",
        "      .sort_values(\"Date\")\n",
        "      .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "dates_pred_ord = df.loc[pred_idx, \"Date\"].sort_values().reset_index(drop=True)\n",
        "order          = np.argsort(df.loc[pred_idx, \"Date\"].values)\n",
        "\n",
        "proba_df_ord   = proba_df.iloc[order].reset_index(drop=True)\n",
        "pred_1x2_ord   = pd.Series(pred_1x2).iloc[order].reset_index(drop=True)\n",
        "\n",
        "# cuotas B365: primero intenta en df, si no, en df_old\n",
        "odds_cols = [c for c in [\"B365H\",\"B365D\",\"B365A\"] if c in df.columns]\n",
        "if odds_cols:\n",
        "    odds_ord = df.loc[pred_idx, odds_cols].iloc[order].reset_index(drop=True)\n",
        "else:\n",
        "    odds_cols = [c for c in [\"B365H\",\"B365D\",\"B365A\"] if c in df_old.columns]\n",
        "    odds_ord = (\n",
        "        df_old[(df_old[\"Season\"] == PRED_SEASON) &\n",
        "               (df_old[\"Date\"] >= start_date) &\n",
        "               (df_old[\"Date\"] <= end_date)]\n",
        "        [odds_cols].sort_values(\"Date\").reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "# probabilidades implícitas y overround (opcional pero útil)\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / odds_ord\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "# --- Resultado final + export ---\n",
        "out_base = pd.concat([\n",
        "    dates_pred_ord.rename(\"Date\"),\n",
        "    old_slice[[\"HomeTeam_norm\",\"AwayTeam_norm\"]],\n",
        "    odds_ord,\n",
        "    pred_1x2_ord.rename(\"Pred\"),\n",
        "    proba_df_ord.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "# con sufijo (histórico)\n",
        "out_base.to_csv( OUT / f\"predictions_{suffix}_base.csv\", index=False)\n",
        "out_base.to_json(OUT / f\"predictions_{suffix}_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "# “current” (para la app)\n",
        "out_base.to_csv( OUT / \"predictions_current_base.csv\", index=False)\n",
        "out_base.to_json(OUT / \"predictions_current_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_base.head(10))\n",
        "print(\"Exportado BASE en:\", OUT)"
      ],
      "metadata": {
        "id": "EWMXywk8eKGr",
        "outputId": "6ec2e162-8cdd-489b-c276-a0e62e5fd256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[BASE] partidos a predecir: 10 en 2025-09-19–2025-09-21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Date HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred    Prob_H  \\\n",
              "0  2025-09-19         betis      sociedad   2.05   3.10   4.00    H  0.408542   \n",
              "1  2025-09-20        girona       levante   1.90   3.50   3.90    H  0.406479   \n",
              "2  2025-09-20   real madrid       espanol   1.22   7.00  11.00    H  0.811867   \n",
              "3  2025-09-20        alaves       sevilla   2.40   3.10   3.00    D  0.308216   \n",
              "4  2025-09-20    villarreal       osasuna   1.53   4.10   5.75    H  0.607126   \n",
              "5  2025-09-20      valencia    ath bilbao   3.20   3.00   2.45    D  0.233103   \n",
              "6  2025-09-21         elche        oviedo   2.05   3.00   4.10    H  0.373651   \n",
              "7  2025-09-21     vallecano         celta   2.30   3.30   3.10    H  0.400853   \n",
              "8  2025-09-21      mallorca    ath madrid   5.00   3.50   1.75    A  0.203928   \n",
              "9  2025-09-21     barcelona        getafe   1.25   6.25   9.50    H  0.818260   \n",
              "\n",
              "     Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.323314  0.268144  0.460026  0.304211  0.235763   1.060386  \n",
              "1  0.350893  0.242628  0.492602  0.267412  0.239986   1.068440  \n",
              "2  0.136805  0.051328  0.778092  0.135610  0.086297   1.053438  \n",
              "3  0.392619  0.299165  0.388471  0.300752  0.310777   1.072581  \n",
              "4  0.262557  0.130317  0.610032  0.227646  0.162322   1.071410  \n",
              "5  0.434462  0.332435  0.296491  0.316257  0.387253   1.053997  \n",
              "6  0.349079  0.277270  0.458015  0.312977  0.229008   1.065041  \n",
              "7  0.322284  0.276864  0.410020  0.285772  0.304208   1.060394  \n",
              "8  0.309176  0.486896  0.189189  0.270270  0.540541   1.057143  \n",
              "9  0.129387  0.052354  0.750988  0.150198  0.098814   1.065263  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6cbc5df-c79c-40be-a9e4-86eeaa0e5b66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>betis</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>0.323314</td>\n",
              "      <td>0.268144</td>\n",
              "      <td>0.460026</td>\n",
              "      <td>0.304211</td>\n",
              "      <td>0.235763</td>\n",
              "      <td>1.060386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>girona</td>\n",
              "      <td>levante</td>\n",
              "      <td>1.90</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.90</td>\n",
              "      <td>H</td>\n",
              "      <td>0.406479</td>\n",
              "      <td>0.350893</td>\n",
              "      <td>0.242628</td>\n",
              "      <td>0.492602</td>\n",
              "      <td>0.267412</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>1.068440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.811867</td>\n",
              "      <td>0.136805</td>\n",
              "      <td>0.051328</td>\n",
              "      <td>0.778092</td>\n",
              "      <td>0.135610</td>\n",
              "      <td>0.086297</td>\n",
              "      <td>1.053438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>alaves</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.308216</td>\n",
              "      <td>0.392619</td>\n",
              "      <td>0.299165</td>\n",
              "      <td>0.388471</td>\n",
              "      <td>0.300752</td>\n",
              "      <td>0.310777</td>\n",
              "      <td>1.072581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.10</td>\n",
              "      <td>5.75</td>\n",
              "      <td>H</td>\n",
              "      <td>0.607126</td>\n",
              "      <td>0.262557</td>\n",
              "      <td>0.130317</td>\n",
              "      <td>0.610032</td>\n",
              "      <td>0.227646</td>\n",
              "      <td>0.162322</td>\n",
              "      <td>1.071410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>valencia</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>D</td>\n",
              "      <td>0.233103</td>\n",
              "      <td>0.434462</td>\n",
              "      <td>0.332435</td>\n",
              "      <td>0.296491</td>\n",
              "      <td>0.316257</td>\n",
              "      <td>0.387253</td>\n",
              "      <td>1.053997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>elche</td>\n",
              "      <td>oviedo</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.10</td>\n",
              "      <td>H</td>\n",
              "      <td>0.373651</td>\n",
              "      <td>0.349079</td>\n",
              "      <td>0.277270</td>\n",
              "      <td>0.458015</td>\n",
              "      <td>0.312977</td>\n",
              "      <td>0.229008</td>\n",
              "      <td>1.065041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.10</td>\n",
              "      <td>H</td>\n",
              "      <td>0.400853</td>\n",
              "      <td>0.322284</td>\n",
              "      <td>0.276864</td>\n",
              "      <td>0.410020</td>\n",
              "      <td>0.285772</td>\n",
              "      <td>0.304208</td>\n",
              "      <td>1.060394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.75</td>\n",
              "      <td>A</td>\n",
              "      <td>0.203928</td>\n",
              "      <td>0.309176</td>\n",
              "      <td>0.486896</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>1.057143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>getafe</td>\n",
              "      <td>1.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.818260</td>\n",
              "      <td>0.129387</td>\n",
              "      <td>0.052354</td>\n",
              "      <td>0.750988</td>\n",
              "      <td>0.150198</td>\n",
              "      <td>0.098814</td>\n",
              "      <td>1.065263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6cbc5df-c79c-40be-a9e4-86eeaa0e5b66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6cbc5df-c79c-40be-a9e4-86eeaa0e5b66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6cbc5df-c79c-40be-a9e4-86eeaa0e5b66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-77dbf2b6-b9ed-4977-8bf9-df8b9f09247d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77dbf2b6-b9ed-4977-8bf9-df8b9f09247d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-77dbf2b6-b9ed-4977-8bf9-df8b9f09247d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Exportado BASE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-19\",\n        \"max\": \"2025-09-21\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2025-09-19\",\n          \"2025-09-20\",\n          \"2025-09-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"mallorca\",\n          \"girona\",\n          \"valencia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ath madrid\",\n          \"levante\",\n          \"ath bilbao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118322155930233,\n        \"min\": 1.22,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          1.9,\n          3.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4406884928163108,\n        \"min\": 3.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.1,\n          3.5,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0604511286918323,\n        \"min\": 1.75,\n        \"max\": 11.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.75,\n          3.9,\n          2.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"H\",\n          \"D\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21865478734963248,\n        \"min\": 0.20392756281958432,\n        \"max\": 0.8182598556244115,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.20392756281958432,\n          0.406478752052089,\n          0.23310303282761966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0999521160526657,\n        \"min\": 0.12938660504749738,\n        \"max\": 0.4344616553637417,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.3091760384872759,\n          0.3508930240460812,\n          0.4344616553637417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1330655131474865,\n        \"min\": 0.0513281975903017,\n        \"max\": 0.48689639869313983,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.48689639869313983,\n          0.24262822390182973,\n          0.3324353118086386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18608518362988613,\n        \"min\": 0.1891891891891892,\n        \"max\": 0.7780921584478578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1891891891891892,\n          0.4926019487549621,\n          0.2964905203711174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06574690146674969,\n        \"min\": 0.13561034761519808,\n        \"max\": 0.3162565550625252,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.27027027027027023,\n          0.2674124864669794,\n          0.3162565550625252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1362471014572106,\n        \"min\": 0.08629749393694423,\n        \"max\": 0.5405405405405405,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5405405405405405,\n          0.23998556477805852,\n          0.3872529245663574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0068431771743474945,\n        \"min\": 1.0534383649137746,\n        \"max\": 1.0725806451612903,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0571428571428572,\n          1.0684403315982263,\n          1.0539965986394557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exportado BASE en: /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con SMOTE:"
      ],
      "metadata": {
        "id": "ExCI5w60foc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (SMOTE) + B365 + export\n",
        "# =========================\n",
        "\n",
        "# Reutilizamos: df, df_old, pred_idx, order, dates_pred_ord, old_slice,\n",
        "#               X_train, y_train, X_pred, odds_ord (si lo quieres recalcular, usa el mismo bloque de arriba)\n",
        "\n",
        "pipe_sm = ImbPipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"smote\",   SMOTE(random_state=42)),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"saga\", penalty=\"l2\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe_sm.fit(X_train, y_train)\n",
        "\n",
        "proba_pred_sm  = pipe_sm.predict_proba(X_pred)\n",
        "pred_labels_sm = pipe_sm.predict(X_pred)\n",
        "\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes_sm = list(pipe_sm.named_steps[\"logreg\"].classes_)\n",
        "pred_1x2_sm = pd.Series(pred_labels_sm).map(class_map).values\n",
        "\n",
        "proba_df_sm = pd.DataFrame(proba_pred_sm, columns=[class_map[c] for c in classes_sm])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df_sm.columns: proba_df_sm[lab] = np.nan\n",
        "proba_df_sm = proba_df_sm[[\"H\",\"D\",\"A\"]]\n",
        "\n",
        "proba_df_sm_ord = proba_df_sm.iloc[order].reset_index(drop=True)\n",
        "pred_1x2_sm_ord = pd.Series(pred_1x2_sm).iloc[order].reset_index(drop=True)\n",
        "\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / odds_ord\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "out_sm = pd.concat([\n",
        "    dates_pred_ord.rename(\"Date\"),\n",
        "    old_slice[[\"HomeTeam_norm\",\"AwayTeam_norm\"]],\n",
        "    odds_ord,\n",
        "    pred_1x2_sm_ord.rename(\"Pred\"),\n",
        "    proba_df_sm_ord.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1).sort_values(\"Date\").reset_index(drop=True)\n",
        "\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "out_sm.to_csv( OUT / f\"predictions_{suffix}_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / f\"predictions_{suffix}_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "out_sm.to_csv( OUT / \"predictions_current_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / \"predictions_current_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_sm.head(10))\n",
        "print(\"Exportado SMOTE en:\", OUT)"
      ],
      "metadata": {
        "id": "-DEKvxP_ejWk",
        "outputId": "ef3c5bd0-2585-4713-cc19-f044a42ae6ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Date HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred    Prob_H  \\\n",
              "0  2025-09-19         betis      sociedad   2.05   3.10   4.00    D  0.247164   \n",
              "1  2025-09-20        girona       levante   1.90   3.50   3.90    D  0.275431   \n",
              "2  2025-09-20   real madrid       espanol   1.22   7.00  11.00    H  0.723960   \n",
              "3  2025-09-20        alaves       sevilla   2.40   3.10   3.00    D  0.179639   \n",
              "4  2025-09-20    villarreal       osasuna   1.53   4.10   5.75    H  0.481312   \n",
              "5  2025-09-20      valencia    ath bilbao   3.20   3.00   2.45    D  0.138001   \n",
              "6  2025-09-21         elche        oviedo   2.05   3.00   4.10    D  0.254901   \n",
              "7  2025-09-21     vallecano         celta   2.30   3.30   3.10    D  0.243360   \n",
              "8  2025-09-21      mallorca    ath madrid   5.00   3.50   1.75    A  0.123738   \n",
              "9  2025-09-21     barcelona        getafe   1.25   6.25   9.50    H  0.716049   \n",
              "\n",
              "     Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.468492  0.284345  0.460026  0.304211  0.235763   1.060386  \n",
              "1  0.449404  0.275165  0.492602  0.267412  0.239986   1.068440  \n",
              "2  0.211729  0.064311  0.778092  0.135610  0.086297   1.053438  \n",
              "3  0.550759  0.269602  0.388471  0.300752  0.310777   1.072581  \n",
              "4  0.348460  0.170228  0.610032  0.227646  0.162322   1.071410  \n",
              "5  0.528202  0.333797  0.296491  0.316257  0.387253   1.053997  \n",
              "6  0.422445  0.322654  0.458015  0.312977  0.229008   1.065041  \n",
              "7  0.459598  0.297042  0.410020  0.285772  0.304208   1.060394  \n",
              "8  0.400692  0.475571  0.189189  0.270270  0.540541   1.057143  \n",
              "9  0.218309  0.065642  0.750988  0.150198  0.098814   1.065263  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7140a629-7f84-449a-8351-6c50c9ae4d28\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>betis</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.247164</td>\n",
              "      <td>0.468492</td>\n",
              "      <td>0.284345</td>\n",
              "      <td>0.460026</td>\n",
              "      <td>0.304211</td>\n",
              "      <td>0.235763</td>\n",
              "      <td>1.060386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>girona</td>\n",
              "      <td>levante</td>\n",
              "      <td>1.90</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.90</td>\n",
              "      <td>D</td>\n",
              "      <td>0.275431</td>\n",
              "      <td>0.449404</td>\n",
              "      <td>0.275165</td>\n",
              "      <td>0.492602</td>\n",
              "      <td>0.267412</td>\n",
              "      <td>0.239986</td>\n",
              "      <td>1.068440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.723960</td>\n",
              "      <td>0.211729</td>\n",
              "      <td>0.064311</td>\n",
              "      <td>0.778092</td>\n",
              "      <td>0.135610</td>\n",
              "      <td>0.086297</td>\n",
              "      <td>1.053438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>alaves</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.179639</td>\n",
              "      <td>0.550759</td>\n",
              "      <td>0.269602</td>\n",
              "      <td>0.388471</td>\n",
              "      <td>0.300752</td>\n",
              "      <td>0.310777</td>\n",
              "      <td>1.072581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.10</td>\n",
              "      <td>5.75</td>\n",
              "      <td>H</td>\n",
              "      <td>0.481312</td>\n",
              "      <td>0.348460</td>\n",
              "      <td>0.170228</td>\n",
              "      <td>0.610032</td>\n",
              "      <td>0.227646</td>\n",
              "      <td>0.162322</td>\n",
              "      <td>1.071410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>valencia</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.45</td>\n",
              "      <td>D</td>\n",
              "      <td>0.138001</td>\n",
              "      <td>0.528202</td>\n",
              "      <td>0.333797</td>\n",
              "      <td>0.296491</td>\n",
              "      <td>0.316257</td>\n",
              "      <td>0.387253</td>\n",
              "      <td>1.053997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>elche</td>\n",
              "      <td>oviedo</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.254901</td>\n",
              "      <td>0.422445</td>\n",
              "      <td>0.322654</td>\n",
              "      <td>0.458015</td>\n",
              "      <td>0.312977</td>\n",
              "      <td>0.229008</td>\n",
              "      <td>1.065041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.243360</td>\n",
              "      <td>0.459598</td>\n",
              "      <td>0.297042</td>\n",
              "      <td>0.410020</td>\n",
              "      <td>0.285772</td>\n",
              "      <td>0.304208</td>\n",
              "      <td>1.060394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.75</td>\n",
              "      <td>A</td>\n",
              "      <td>0.123738</td>\n",
              "      <td>0.400692</td>\n",
              "      <td>0.475571</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>0.540541</td>\n",
              "      <td>1.057143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>getafe</td>\n",
              "      <td>1.25</td>\n",
              "      <td>6.25</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>0.218309</td>\n",
              "      <td>0.065642</td>\n",
              "      <td>0.750988</td>\n",
              "      <td>0.150198</td>\n",
              "      <td>0.098814</td>\n",
              "      <td>1.065263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7140a629-7f84-449a-8351-6c50c9ae4d28')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7140a629-7f84-449a-8351-6c50c9ae4d28 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7140a629-7f84-449a-8351-6c50c9ae4d28');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-64fb8e6b-8d53-4f94-8dd0-15c87e98fe6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64fb8e6b-8d53-4f94-8dd0-15c87e98fe6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-64fb8e6b-8d53-4f94-8dd0-15c87e98fe6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Exportado SMOTE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-19\",\n        \"max\": \"2025-09-21\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2025-09-19\",\n          \"2025-09-20\",\n          \"2025-09-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"mallorca\",\n          \"girona\",\n          \"valencia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"ath madrid\",\n          \"levante\",\n          \"ath bilbao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.118322155930233,\n        \"min\": 1.22,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          1.9,\n          3.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4406884928163108,\n        \"min\": 3.0,\n        \"max\": 7.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          3.1,\n          3.5,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0604511286918323,\n        \"min\": 1.75,\n        \"max\": 11.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.75,\n          3.9,\n          2.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\",\n          \"H\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22396364440953034,\n        \"min\": 0.12373772626332337,\n        \"max\": 0.7239602733272985,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.12373772626332337,\n          0.2754307517377617,\n          0.13800143759945918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11601158650948261,\n        \"min\": 0.21172916243315967,\n        \"max\": 0.5507587425518293,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.4006916206079566,\n          0.4494038023478946,\n          0.5282017981855056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12564685257410635,\n        \"min\": 0.06431056423954178,\n        \"max\": 0.47557065312872,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.47557065312872,\n          0.2751654459143438,\n          0.3337967642150351\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18608518362988613,\n        \"min\": 0.1891891891891892,\n        \"max\": 0.7780921584478578,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1891891891891892,\n          0.4926019487549621,\n          0.2964905203711174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06574690146674969,\n        \"min\": 0.13561034761519808,\n        \"max\": 0.3162565550625252,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.27027027027027023,\n          0.2674124864669794,\n          0.3162565550625252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1362471014572106,\n        \"min\": 0.08629749393694423,\n        \"max\": 0.5405405405405405,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5405405405405405,\n          0.23998556477805852,\n          0.3872529245663574\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0068431771743474945,\n        \"min\": 1.0534383649137746,\n        \"max\": 1.0725806451612903,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.0571428571428572,\n          1.0684403315982263,\n          1.0539965986394557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exportado SMOTE en: /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AUraRaeqPH_"
      },
      "source": [
        "# **EVALUACIÓN HISTÓRICA: Logistic Regression multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)"
      ],
      "metadata": {
        "id": "Iqi91Ub6gI-T"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin SMOTE:"
      ],
      "metadata": {
        "id": "4Shn3mE9kGbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_logreg_eval_no_smote(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Entrena y evalúa una regresión logística SIN SMOTE.\n",
        "\n",
        "    - Train: Season <= train_until_season\n",
        "    - Test : Season >  train_until_season  (y si test_until_season no es None, Season <= test_until_season)\n",
        "    - Excluye partidos futuros (target NaN).\n",
        "    - Si with_odds=True, exige cuotas no NaN en train/test.\n",
        "    - Descarta filas con NaN en algún feature de X (rápido y seguro).\n",
        "\n",
        "    Returns:\n",
        "      model, scaler, (metrics_train, metrics_test),\n",
        "      y_test (o None), y_pred_test (o None), proba_test (o None), idx_test (o None)\n",
        "    \"\"\"\n",
        "\n",
        "    drop_cols_common = [\n",
        "        'FTR', 'target', 'Date', 'has_xg_data',\n",
        "        'a_squad_size_prev_season', 'away_form_gd_6', 'home_form_gd_6'\n",
        "    ]\n",
        "    if with_odds:\n",
        "        drop_cols_mode = ['overround', 'pimp2', 'B365D']\n",
        "    else:\n",
        "        drop_cols_mode = ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                          'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2']\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    y_all = df['target']  # usamos 'target' tal cual tienes\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta la columna 'Season' en X para hacer el split temporal.\")\n",
        "\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] >  train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_train = X_all.loc[train_mask].drop(columns=['Season'])\n",
        "    y_train = y_all.loc[train_mask]\n",
        "\n",
        "    X_test  = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test  = y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "\n",
        "    if len(X_train)==0 or len(np.unique(y_train))<2:\n",
        "        raise ValueError(\"TRAIN vacío o con <2 clases. Revisa filtros/temporadas.\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled  = scaler.transform(X_test) if len(X_test) else None\n",
        "\n",
        "    model = LogisticRegression(\n",
        "        solver='saga', penalty='l2', max_iter=1000,\n",
        "        random_state=random_state\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    classes_used = model.classes_\n",
        "\n",
        "    # --- métricas train ---\n",
        "    ytr_pred  = model.predict(X_train_scaled)\n",
        "    ytr_proba = model.predict_proba(X_train_scaled)\n",
        "    ytr_bin   = label_binarize(y_train, classes=classes_used)\n",
        "    brier_tr  = np.mean(np.sum((ytr_proba - ytr_bin)**2, axis=1))\n",
        "    acc_tr    = accuracy_score(y_train, ytr_pred)\n",
        "    ll_tr     = log_loss(y_train, ytr_proba, labels=classes_used)\n",
        "    metrics_train = {\"accuracy\": float(acc_tr), \"log_loss\": float(ll_tr), \"brier\": float(brier_tr), \"n_train\": int(len(y_train))}\n",
        "\n",
        "    # --- métricas test ---\n",
        "    metrics_test, yte_pred, yte_proba = None, None, None\n",
        "    if len(X_test):\n",
        "        yte_pred  = model.predict(X_test_scaled)\n",
        "        yte_proba = model.predict_proba(X_test_scaled)\n",
        "        yte_bin   = label_binarize(y_test, classes=classes_used)\n",
        "        brier_te  = np.mean(np.sum((yte_proba - yte_bin)**2, axis=1))\n",
        "        acc_te    = accuracy_score(y_test, yte_pred)\n",
        "        ll_te     = log_loss(y_test, yte_proba, labels=classes_used)\n",
        "        metrics_test = {\n",
        "            \"accuracy\": float(acc_te), \"log_loss\": float(ll_te), \"brier\": float(brier_te),\n",
        "            \"n_test\": int(len(y_test)),\n",
        "            \"season_min\": int(X_all.loc[test_mask, 'Season'].min()),\n",
        "            \"season_max\": int(X_all.loc[test_mask, 'Season'].max())\n",
        "        }\n",
        "    else:\n",
        "        print(\"⚠️ TEST vacío tras filtrar (no hay partidos jugados en el rango de test).\")\n",
        "\n",
        "    test_range_txt = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "                      if test_until_season is not None else f\">{train_until_season}\")\n",
        "    print(\"Logistic Regression (sin SMOTE)\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {test_range_txt}) ===\")\n",
        "    print(metrics_test if metrics_test else \"Sin test disponible.\")\n",
        "\n",
        "    return model, scaler, (metrics_train, metrics_test), y_test, yte_pred, yte_proba, idx_test"
      ],
      "metadata": {
        "id": "3-op-v-KpVTS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "\n",
        "rows = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        _, _, (mtr_tr, mtr_te), *_ = run_logreg_eval_no_smote(\n",
        "            df,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=True,\n",
        "            random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "\n",
        "        rows.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SKIP] test={test_season} → {e}\")\n",
        "\n",
        "with open(OUT / \"eval_grid.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows:\n",
        "    flat = []\n",
        "    for r in rows:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "        })\n",
        "    pd.DataFrame(flat).sort_values(\"test_season\").to_csv(OUT / \"metrics_by_season.csv\", index=False)\n",
        "\n",
        "print(f\"Guardados:\\n- {OUT/'eval_grid.json'}\\n- {OUT/'metrics_by_season.csv'}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tgicLUn_uLta",
        "outputId": "d499c4db-b4ac-472a-ba41-ab81f3b77f0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados:\n",
            "- /content/outputs/eval_grid.json\n",
            "- /content/outputs/metrics_by_season.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOCAL\n",
        "model, scaler, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = \\\n",
        "    run_logreg_eval_no_smote(df, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ],
      "metadata": {
        "id": "N5tGcF-y9Ymk",
        "outputId": "7ba6d3eb-a14d-431e-a479-3fa40dd32b6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con SMOTE:"
      ],
      "metadata": {
        "id": "VFOHEHwvkEAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_logreg_eval(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Regresión logística con SMOTE + escalado.\n",
        "      - Train: Season <= train_until_season\n",
        "      - Test : Season >  train_until_season (y si test_until_season no es None, Season <= test_until_season)\n",
        "      - Si with_odds=True, exige B365H/B365A no NaN.\n",
        "      - Descarta filas con NaN en features.\n",
        "    Returns:\n",
        "      model, scaler, (metrics_train, metrics_test),\n",
        "      y_test (o None), y_pred_test (o None), proba_test (o None), idx_test (o None)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- columnas a excluir según modo ---\n",
        "    drop_cols_common = [\n",
        "        'FTR', 'target', 'Date', 'has_xg_data',\n",
        "        'a_squad_size_prev_season', 'away_form_gd_6', 'home_form_gd_6'\n",
        "    ]\n",
        "    if with_odds:\n",
        "        drop_cols_mode = ['overround', 'pimp2', 'B365D']\n",
        "    else:\n",
        "        drop_cols_mode = ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                          'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2']\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    # --- X e y; filtrado de válidos ---\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid_mask = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H', 'B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid_mask &= X_all[c].notna()\n",
        "    valid_mask &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid_mask].copy()\n",
        "    y_all = y_all.loc[valid_mask].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta la columna 'Season' para hacer el split temporal.\")\n",
        "\n",
        "    # --- split temporal ---\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] >  train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_train = X_all.loc[train_mask].drop(columns=['Season'])\n",
        "    y_train = y_all.loc[train_mask]\n",
        "\n",
        "    X_test  = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test  = y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "\n",
        "    if len(X_train) == 0 or len(np.unique(y_train)) < 2:\n",
        "        raise ValueError(\"TRAIN vacío o con menos de 2 clases. Revisa filtros/temporadas.\")\n",
        "\n",
        "    # --- escalado ---\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled  = scaler.transform(X_test) if len(X_test) else None\n",
        "\n",
        "    # --- SMOTE robusto (ajusta k_neighbors según la minoritaria) ---\n",
        "    # evita errores cuando la clase minoritaria tiene pocos ejemplos\n",
        "    _, counts = np.unique(y_train, return_counts=True)\n",
        "    min_count = int(counts.min())\n",
        "    if min_count <= 1:\n",
        "        # No se puede aplicar SMOTE de forma segura: entrenamos sin resample\n",
        "        X_train_res, y_train_res = X_train_scaled, y_train\n",
        "    else:\n",
        "        k = max(1, min(5, min_count - 1))\n",
        "        try:\n",
        "            smote = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "            X_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n",
        "        except Exception:\n",
        "            # Fallback si aún así falla\n",
        "            X_train_res, y_train_res = X_train_scaled, y_train\n",
        "\n",
        "    # --- modelo ---\n",
        "    model = LogisticRegression(\n",
        "        solver='saga', penalty='l2', max_iter=1000, random_state=random_state\n",
        "    )\n",
        "    model.fit(X_train_res, y_train_res)\n",
        "    classes_used = model.classes_\n",
        "\n",
        "    # --- métricas train (predice sobre train original escalado) ---\n",
        "    ytr_pred  = model.predict(X_train_scaled)\n",
        "    ytr_proba = model.predict_proba(X_train_scaled)\n",
        "    ytr_bin   = label_binarize(y_train, classes=classes_used)\n",
        "    brier_tr  = float(np.mean(np.sum((ytr_proba - ytr_bin) ** 2, axis=1)))\n",
        "    acc_tr    = float(accuracy_score(y_train, ytr_pred))\n",
        "    ll_tr     = float(log_loss(y_train, ytr_proba, labels=classes_used))\n",
        "    metrics_train = {\n",
        "        \"accuracy\": acc_tr, \"log_loss\": ll_tr, \"brier\": brier_tr, \"n_train\": int(len(y_train))\n",
        "    }\n",
        "\n",
        "    # --- métricas test ---\n",
        "    metrics_test, yte_pred, yte_proba = None, None, None\n",
        "    if len(X_test):\n",
        "        yte_pred  = model.predict(X_test_scaled)\n",
        "        yte_proba = model.predict_proba(X_test_scaled)\n",
        "        yte_bin   = label_binarize(y_test, classes=classes_used)\n",
        "        brier_te  = float(np.mean(np.sum((yte_proba - yte_bin) ** 2, axis=1)))\n",
        "        acc_te    = float(accuracy_score(y_test, yte_pred))\n",
        "        ll_te     = float(log_loss(y_test, yte_proba, labels=classes_used))\n",
        "        metrics_test = {\n",
        "            \"accuracy\": acc_te, \"log_loss\": ll_te, \"brier\": brier_te,\n",
        "            \"n_test\": int(len(y_test)),\n",
        "            \"season_min\": int(X_all.loc[test_mask, 'Season'].min()),\n",
        "            \"season_max\": int(X_all.loc[test_mask, 'Season'].max())\n",
        "        }\n",
        "    else:\n",
        "        print(\"⚠️ TEST vacío tras filtrar (no hay partidos jugados en el rango de test).\")\n",
        "\n",
        "    # --- reporte ---\n",
        "    test_range_txt = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "                      if test_until_season is not None else f\">{train_until_season}\")\n",
        "    print(\"Logistic Regression con SMOTE\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {test_range_txt}) ===\")\n",
        "    print(metrics_test if metrics_test else \"Sin test disponible.\")\n",
        "\n",
        "    return model, scaler, (metrics_train, metrics_test), y_test, yte_pred, yte_proba, idx_test"
      ],
      "metadata": {
        "id": "9i6L9bnHylmE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Grid SMOTE: train ≤ S-1, test = S (solo con cuotas) =====\n",
        "\n",
        "OUT = ROOT / \"outputs\"   # o ROOT/\"outs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "rows_sm = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "    try:\n",
        "        _, _, (mtr_tr, mtr_te), *_ = run_logreg_eval(\n",
        "            df, train_until_season=train_until, test_until_season=test_season,\n",
        "            with_odds=True, random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "        rows_sm.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SMOTE SKIP] test={test_season} → {e}\")\n",
        "\n",
        "# JSON + CSV (SMOTE)\n",
        "with open(OUT / \"eval_grid_smote.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows_sm, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows_sm:\n",
        "    flat_sm = []\n",
        "    for r in rows_sm:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat_sm.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "        })\n",
        "    pd.DataFrame(flat_sm).sort_values(\"test_season\").to_csv(OUT / \"metrics_by_season_smote.csv\", index=False)\n",
        "\n",
        "print(\"Guardados: eval_grid_smote.json y metrics_by_season_smote.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNLnqvVcjJXd",
        "outputId": "70817121-0f7b-430a-bb26-fd144d25a0b9",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados: eval_grid_smote.json y metrics_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOCAL\n",
        "model_sm, scaler_sm, (mtr_tr_sm, mtr_te_sm), y_test_sm, y_pred_sm, y_proba_sm, idx_test_sm = \\\n",
        "    run_logreg_eval(df, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ],
      "metadata": {
        "id": "mUnUvtBGahqH",
        "outputId": "96990a1d-1e1c-4c5a-f2c9-27496760d817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WA-02xbP30g"
      },
      "source": [
        "Con este modelo obtengo el mejor **Accuracy** (porcentaje de aciertos totales), pero esta métrica ignora como de seguras son esas esas predicciones.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Número de aciertos}}{\\text{Número total de predicciones}}\n",
        "$$\n",
        "\n",
        "Para ello se utiliza el **Log Loss** (Cross-Entropy Loss), métrica que mide qué tan buenas son las probabilidades que predice mi modelo de clasificación. A esta métrica no solo le importa acertar la clase, sino cuán seguro está el modelo.\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} y_{ij} \\cdot \\log(p_{ij})\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $y_{ij}$ = 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "\n",
        "Tener un Log Loss alto en este caso significaría dar una probabilidad alta a la clase incorrecta, o lo que es lo mismo, dar una probabilidad baja a la clase correcta.\n",
        "\n",
        "Por último añadí también el **Brier Score**, que es una métrica que evalúa cuán cercanas están las probabilidades predichas por tu modelo respecto a la realidad, comparando la distribución de probabilidades contra la clase real (codificada en one-hot). Es como un error cuadrático medio (MSE) para probabilidades.\n",
        "\n",
        "$$\n",
        "\\text{Brier Score} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} (p_{ij} - y_{ij})^2\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $N$ es el número de ejemplos.\n",
        "- $K$ es el número de clases (en este caso 3: victoria local, empate, victoria visitante).\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "- $y_{ij}$ es 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "\n",
        "Un Brier Score de 0 significa que las probabilidades dadas por el modelo son perfectas, mientras que uno del 0.66 en nuestro caso sería un modelo completamente aleatorio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjn9DwWtgyl"
      },
      "source": [
        "## Selección de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agXuwrpyY1A-"
      },
      "source": [
        "La función `forward_selection` implementa un algoritmo clásico de selección de variables hacia adelante (**forward feature selection**) sobre un modelo de regresión logística multiclase con escalado de variables.\n",
        "\n",
        "Va añadiendo sucesivamente la variable que mejor mejora el rendimiento del modelo (según accuracy o log_loss), una por una.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nec5nM-N88pl"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.metrics import accuracy_score, log_loss\n",
        "# import numpy as np\n",
        "\n",
        "# def forward_selection(X, y, max_features=20, scoring='accuracy'):\n",
        "#     selected_features = []\n",
        "#     remaining_features = list(X.columns)\n",
        "#     scores = []\n",
        "\n",
        "#     for i in range(min(max_features, len(remaining_features))):\n",
        "#         best_score = -np.inf if scoring == 'accuracy' else np.inf\n",
        "#         best_feature = None\n",
        "\n",
        "#         for feature in remaining_features:\n",
        "#             current_features = selected_features + [feature]\n",
        "\n",
        "#             model = make_pipeline(\n",
        "#                 StandardScaler(),\n",
        "#                 LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "#             )\n",
        "\n",
        "#             model.fit(X[current_features], y)\n",
        "#             y_pred = model.predict(X[current_features])\n",
        "#             y_proba = model.predict_proba(X[current_features])\n",
        "\n",
        "#             if scoring == 'accuracy':\n",
        "#                 score = accuracy_score(y, y_pred)\n",
        "#                 if score > best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             elif scoring == 'log_loss':\n",
        "#                 score = log_loss(y, y_proba)\n",
        "#                 if score < best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             else:\n",
        "#                 raise ValueError(\"scoring debe ser 'accuracy' o 'log_loss'.\")\n",
        "\n",
        "#         if best_feature is not None:\n",
        "#             selected_features.append(best_feature)\n",
        "#             remaining_features.remove(best_feature)\n",
        "#             scores.append(best_score)\n",
        "\n",
        "#         print(f\"[{i+1}] Añadida: {best_feature} | Score: {best_score:.4f}\")\n",
        "\n",
        "#     return selected_features, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9w77D7IQ6ORb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# selected, scores = forward_selection(X_train, y_train, max_features=81, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "94wsZYs0akpR"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Suponemos que tienes las listas: selected (variables) y scores (métricas acumuladas)\n",
        "\n",
        "# # Calcular diferencia respecto al valor anterior\n",
        "# deltas = np.diff([0] + scores)\n",
        "# colors = ['blue' if delta >= 0 else 'red' for delta in deltas]\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# bar_width = 0.6  # Reducir ancho de barra para separarlas\n",
        "# indices = np.arange(len(selected))\n",
        "\n",
        "# plt.bar(indices, scores, color=colors, width=bar_width)\n",
        "# plt.xticks(indices, selected, rotation=90)\n",
        "# plt.xlabel('Variables añadidas')\n",
        "# plt.ylabel('Valor de la métrica')\n",
        "# plt.title('Evolución del rendimiento al añadir variables')\n",
        "\n",
        "# plt.ylim(min(scores) - 0.01, max(scores) + 0.01)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r5Zlw7IZTRM"
      },
      "source": [
        "Se implementó un proceso de selección hacia adelante (forward selection) sobre el modelo de regresión logística con variables estandarizadas. Este procedimiento consiste en partir sin predictores y añadir, en cada iteración, la variable que mayor mejora produce en el rendimiento del modelo. Se evaluaron dos métricas complementarias como criterio de selección: el accuracy (para priorizar aciertos de clasificación) y el log loss (para priorizar la calibración de las probabilidades). Esta técnica permitió reducir la dimensionalidad del conjunto original y determinar el orden de relevancia de las variables desde el punto de vista predictivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmmpBR0ity_a"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **MATRIZ DE CONFUSIÓN**"
      ],
      "metadata": {
        "id": "zu7wer0OnyON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    # válidas: sin NaN en y ni en X; si with_odds, exige cuotas clave\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Alinea X para que tenga EXACTAMENTE las columnas usadas en el fit.\n",
        "    - Usa feature_names si se proporcionan; si no, intenta fitter.feature_names_in_.\n",
        "    - Elimina columnas extra.\n",
        "    - Lanza error si faltan columnas del fit.\n",
        "    \"\"\"\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        # Si el scaler/model se entrenó con arrays numpy, no hay nombres guardados.\n",
        "        # En ese caso asumimos que X ya coincide.\n",
        "        return X\n",
        "\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Matriz de confusión con rango de test configurable ----------\n",
        "def plot_confusion_for_logreg(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None   # opcional: forzar lista de features del fit\n",
        "):\n",
        "\n",
        "    # 1) reconstruir TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) alinear columnas a las del fit (usamos scaler; también valdría el modelo)\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # 4) plot\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = model.classes_\n",
        "    display_labels = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    ConfusionMatrixDisplay.from_predictions(\n",
        "        y_test, y_pred,\n",
        "        labels=classes_used,\n",
        "        display_labels=display_labels,\n",
        "        cmap='Blues', colorbar=False\n",
        "    )\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    plt.title(f'Confusion Matrix (Seasons {rango})')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aCp9bPdP-2fi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# plot_confusion_for_logreg(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ],
      "metadata": {
        "id": "FGsY5ECG9S4E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_confusion_grid(df: pd.DataFrame, out_dir: Path, model: str = \"base\", random_state: int = 42):\n",
        "    \"\"\"\n",
        "    Genera matrices de confusión por temporada y las guarda en:\n",
        "      outputs/confusion_grid_<model>.json\n",
        "    - model: \"base\" (sin SMOTE) | \"smote\"\n",
        "    - Split: train ≤ S-1, test = S\n",
        "    - Usa with_odds=True\n",
        "    \"\"\"\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            elif model == \"smote\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"model debe ser 'base' o 'smote'.\")\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2]).tolist()  # 0=A,1=D,2=H\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"labels\": [\"A\",\"D\",\"H\"],\n",
        "                \"matrix\": cm,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"])\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[CONF {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_path = out_dir / f\"confusion_grid_{model}.json\"\n",
        "    out_path.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_path}  ({len(rows)} temporadas)\")"
      ],
      "metadata": {
        "id": "8wiCWFmm3bCP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "build_confusion_grid(df, OUT, model=\"base\")\n",
        "\n",
        "build_confusion_grid(df, OUT, model=\"smote\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V6k0YQEV3mh2",
        "outputId": "23417d8b-44cd-4592-c12a-6e7de8f0d7d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/confusion_grid_base.json  (19 temporadas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/confusion_grid_smote.json  (19 temporadas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **METRICAS DE CLASIFICACIÓN**"
      ],
      "metadata": {
        "id": "PBvnqoyz-uws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- split TEST con tope de temporada --------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para hacer el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# -------- alinear columnas a las usadas en el fit --------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        # si se entrenó con arrays, no hay nombres; asumimos que X ya coincide\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# -------- classification_report con rango de test configurable --------\n",
        "def print_classification_report_for_logreg(\n",
        "    df: pd.DataFrame, model, scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    digits: int = 3,\n",
        "    feature_names: list[str] | None = None   # opcional: columnas del fit\n",
        "):\n",
        "    \"\"\"\n",
        "    Reconstruye TEST (Season in (train_until_season, test_until_season]) si se indica,\n",
        "    alinea columnas al fit y muestra classification_report. Robusto a clases ausentes.\n",
        "    \"\"\"\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # Alinear a columnas de entrenamiento\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # Predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Etiquetas\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = model.classes_\n",
        "    target_names = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    # Reporte\n",
        "    print(\n",
        "        classification_report(\n",
        "            y_test, y_pred,\n",
        "            labels=classes_used,\n",
        "            target_names=target_names,\n",
        "            zero_division=0,\n",
        "            digits=digits\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "TQDJL9b4Ar0r"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# print_classification_report_for_logreg(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ],
      "metadata": {
        "id": "8foJ4svkocU2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classification_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",       # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,    # como acordamos para la app\n",
        "    random_state: int = 42\n",
        "):\n",
        "    \"\"\"\n",
        "    Exporta métricas de clasificación por temporada (train ≤ S-1, test = S).\n",
        "    Guarda: outputs/classification_grid_<model>.json\n",
        "            outputs/classification_by_season_<model>.csv (resumen tabular)\n",
        "    \"\"\"\n",
        "    # Import local para evitar \"me faltó ejecutar la celda de imports\"\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    label_name = {0:\"A\", 1:\"D\", 2:\"H\"}  # tu codificación\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Alinear nombres de clase a tu esquema\n",
        "            # classification_report necesita que target_names corresponda al orden de \"labels\"\n",
        "            # Usamos las clases del modelo si están disponibles; si no, asumimos [0,1,2]\n",
        "            try:\n",
        "                classes_used = list(sorted(set(y_test.unique()).union(set(y_pred))))\n",
        "            except Exception:\n",
        "                classes_used = [0,1,2]\n",
        "            # Limita y ordena a 0,1,2 por coherencia\n",
        "            classes_used = [c for c in [0,1,2] if c in classes_used]\n",
        "            target_names = [label_name[c] for c in classes_used]\n",
        "\n",
        "            rep = classification_report(\n",
        "                y_test, y_pred,\n",
        "                labels=classes_used,\n",
        "                target_names=target_names,\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "\n",
        "            # Estructura limpia para JSON\n",
        "            per_class = {}\n",
        "            for c in classes_used:\n",
        "                nm = label_name[c]\n",
        "                if nm in rep:\n",
        "                    per_class[nm] = {\n",
        "                        \"precision\": float(rep[nm][\"precision\"]),\n",
        "                        \"recall\":    float(rep[nm][\"recall\"]),\n",
        "                        \"f1\":        float(rep[nm][\"f1-score\"]),\n",
        "                        \"support\":   int(rep[nm][\"support\"]),\n",
        "                    }\n",
        "\n",
        "            overall = {\n",
        "                \"accuracy\":     float(rep.get(\"accuracy\", mtr_te.get(\"accuracy\", float(\"nan\")))),\n",
        "                \"macro_avg\": {\n",
        "                    \"precision\": float(rep[\"macro avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"macro avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"macro avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"macro avg\"][\"support\"]),\n",
        "                },\n",
        "                \"weighted_avg\": {\n",
        "                    \"precision\": float(rep[\"weighted avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"weighted avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"weighted avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"weighted avg\"][\"support\"]),\n",
        "                },\n",
        "                # por conveniencia añadimos lo de mtr_te si lo quieres usar en la app\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            }\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,\n",
        "                \"overall\": overall,\n",
        "            })\n",
        "\n",
        "            # Fila “plana” para CSV\n",
        "            row_flat = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"accuracy\": overall[\"accuracy\"],\n",
        "                \"macro_f1\": overall[\"macro_avg\"][\"f1\"],\n",
        "                \"n_test\": overall[\"n_test\"],\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    row_flat[f\"precision_{nm}\"] = per_class[nm][\"precision\"]\n",
        "                    row_flat[f\"recall_{nm}\"]    = per_class[nm][\"recall\"]\n",
        "                    row_flat[f\"f1_{nm}\"]        = per_class[nm][\"f1\"]\n",
        "                    row_flat[f\"support_{nm}\"]   = per_class[nm][\"support\"]\n",
        "            flat.append(row_flat)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[CLASS {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    # JSON completo para la app\n",
        "    (out_dir / f\"classification_grid_{model}.json\").write_text(\n",
        "        json.dumps(rows, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(f\"Guardado: {out_dir / f'classification_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    # CSV resumido (útil para tablas rápidas)\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(\n",
        "            out_dir / f\"classification_by_season_{model}.csv\", index=False\n",
        "        )\n",
        "        print(f\"Guardado: {out_dir / f'classification_by_season_{model}.csv'}\")"
      ],
      "metadata": {
        "id": "EAn60wwpEl0T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Modelo base (sin SMOTE)\n",
        "build_classification_grid(df, OUT, model=\"base\", with_odds=True)\n",
        "\n",
        "# También SMOTE:\n",
        "build_classification_grid(df, OUT, model=\"smote\", with_odds=True)\n"
      ],
      "metadata": {
        "id": "xtZ_DGjMEln9",
        "outputId": "4f22e247-14bc-411e-f1d3-28f60970ae9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/classification_grid_base.json  (19 temporadas)\n",
            "Guardado: /content/outputs/classification_by_season_base.csv\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/classification_grid_smote.json  (19 temporadas)\n",
            "Guardado: /content/outputs/classification_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **AUC Y CURVA ROC**"
      ],
      "metadata": {
        "id": "U_-8dbe3DuYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # entrenaste con arrays; asumimos que X ya coincide\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta de columnas del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Curvas ROC multiclase con rango de test configurable ----------\n",
        "def plot_multiclass_roc(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None\n",
        "):\n",
        "    import matplotlib.pyplot as plt  # lazy import para evitar NameError\n",
        "\n",
        "    # 1) TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) Alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) Probabilidades\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "    # 4) Binarización y etiquetas\n",
        "    classes_used = model.classes_\n",
        "    y_bin = label_binarize(y_test, classes=classes_used)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    labels_text = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    # 5) Curvas por clase (si hay positivos y negativos)\n",
        "    plt.figure()\n",
        "    auc_per_class, weights = [], []\n",
        "    n = len(y_test)\n",
        "\n",
        "    for k, cls in enumerate(classes_used):\n",
        "        y_true_k = y_bin[:, k]\n",
        "        y_score_k = y_proba[:, k]\n",
        "        pos = y_true_k.sum()\n",
        "        neg = n - pos\n",
        "        if pos > 0 and neg > 0:\n",
        "            fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "            auc_k = roc_auc_score(y_true_k, y_score_k)\n",
        "            auc_per_class.append(auc_k)\n",
        "            weights.append(pos)\n",
        "            plt.plot(fpr, tpr, label=f\"{labels_text[k]} (AUC = {auc_k:.2f})\")\n",
        "        else:\n",
        "            print(f\"Nota: '{labels_text[k]}' no tiene suficientes positivos/negativos en TEST; omito su curva.\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    plt.title(f\"Curvas ROC por clase (Seasons {rango})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 6) AUC macro y weighted (solo con clases válidas)\n",
        "    if auc_per_class:\n",
        "        auc_macro = float(np.mean(auc_per_class))\n",
        "        auc_weighted = float(np.average(auc_per_class, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "        print(f\"\\nAUC macro: {auc_macro:.3f}\")\n",
        "        print(f\"AUC weighted: {auc_weighted:.3f}\")\n",
        "    else:\n",
        "        print(\"\\nNo se pudieron calcular AUCs (todas las clases carecen de positivos/negativos suficientes en TEST).\")"
      ],
      "metadata": {
        "id": "iZDwnt_DBphY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# plot_multiclass_roc(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ],
      "metadata": {
        "id": "izcriACtp027"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === ROC por temporada (train ≤ S-1, test = S) → outputs/roc_grid_<modelo>.json ===\n",
        "\n",
        "def _downsample_curve(x: np.ndarray, y: np.ndarray, max_points: int = 200):\n",
        "    \"\"\"Reduce puntos de la curva para que el JSON no pese demasiado.\"\"\"\n",
        "    if len(x) <= max_points:\n",
        "        return x.tolist(), y.tolist()\n",
        "    idx = np.linspace(0, len(x) - 1, max_points).round().astype(int)\n",
        "    return x[idx].tolist(), y[idx].tolist()\n",
        "\n",
        "def build_roc_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",        # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    max_points: int = 200       # nº máx. de puntos por curva guardada\n",
        "):\n",
        "\n",
        "    label_name = {0: \"A\", 1: \"D\", 2: \"H\"}  # tu codificación\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, _ = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                # Asegúrate de que tu run_logreg_eval devuelve y_test, y_pred, y_proba\n",
        "                _, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, _ = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Clases tal y como las usó el modelo (orden de columnas en y_proba)\n",
        "            classes_used = getattr(_, \"classes_\", None)  # el primer \"_\" es model; pero no lo necesitamos aquí\n",
        "            # Si no tenemos el modelo a mano, inferimos a partir de columnas de y_proba\n",
        "            # asumimos orden 0,1,2 por coherencia:\n",
        "            classes_used = [0,1,2][:y_proba.shape[1]]\n",
        "\n",
        "            # Binariza y calcula curvas por clase si hay positivos y negativos\n",
        "            y_bin = label_binarize(y_test, classes=classes_used)\n",
        "            per_class = {}\n",
        "            aucs, weights = [], []\n",
        "\n",
        "            for k, cls in enumerate(classes_used):\n",
        "                nm = label_name[cls]\n",
        "                y_true_k = y_bin[:, k]\n",
        "                y_score_k = y_proba[:, k]\n",
        "                pos = int(y_true_k.sum())\n",
        "                neg = int(len(y_true_k) - pos)\n",
        "                if pos > 0 and neg > 0:\n",
        "                    fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "                    auc_k = float(roc_auc_score(y_true_k, y_score_k))\n",
        "                    fpr_l, tpr_l = _downsample_curve(fpr, tpr, max_points=max_points)\n",
        "                    per_class[nm] = {\n",
        "                        \"auc\": auc_k,\n",
        "                        \"support_pos\": pos,\n",
        "                        \"fpr\": fpr_l,\n",
        "                        \"tpr\": tpr_l,\n",
        "                    }\n",
        "                    aucs.append(auc_k)\n",
        "                    weights.append(pos)\n",
        "                # si no hay suficientes casos, simplemente no incluimos esa clase\n",
        "\n",
        "            if not per_class:\n",
        "                continue\n",
        "\n",
        "            auc_macro = float(np.mean(aucs))\n",
        "            auc_weighted = float(np.average(aucs, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,     # dict con A/D/H presentes\n",
        "                \"overall\": {\n",
        "                    \"auc_macro\": auc_macro,\n",
        "                    \"auc_weighted\": auc_weighted,\n",
        "                    \"n_test\": int(mtr_te[\"n_test\"])\n",
        "                }\n",
        "            })\n",
        "\n",
        "            # fila plana para CSV (útil en tablas)\n",
        "            rowf = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"auc_macro\": auc_macro,\n",
        "                \"auc_weighted\": auc_weighted,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    rowf[f\"auc_{nm}\"] = per_class[nm][\"auc\"]\n",
        "                    rowf[f\"support_pos_{nm}\"] = per_class[nm][\"support_pos\"]\n",
        "            flat.append(rowf)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ROC {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (out_dir / f\"roc_grid_{model}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_dir / f'roc_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(out_dir / f\"roc_by_season_{model}.csv\", index=False)\n",
        "        print(f\"Guardado: {out_dir / f'roc_by_season_{model}.csv'}\")"
      ],
      "metadata": {
        "id": "ZRFOTvK4IR-S"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Sin SMOTE\n",
        "build_roc_grid(df, OUT, model=\"base\", with_odds=True)\n",
        "\n",
        "# Con SMOTE\n",
        "build_roc_grid(df, OUT, model=\"smote\", with_odds=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ODtyFt7UIvER",
        "outputId": "8533263c-1557-4913-eec7-ed716e525175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/roc_grid_base.json  (19 temporadas)\n",
            "Guardado: /content/outputs/roc_by_season_base.csv\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: /content/outputs/roc_grid_smote.json  (19 temporadas)\n",
            "Guardado: /content/outputs/roc_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BENEFICIOS**"
      ],
      "metadata": {
        "id": "2Nx6x3AUKKEk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RYAfU_pvMz"
      },
      "source": [
        "Por último, pero no por ello menos importante vamos a estudiar la última métrica: El **ROI (Return on Investment)**.\n",
        "\n",
        "$$\n",
        "ROI = \\frac{\\text{Beneficio}}{\\text{Inversión}}\n",
        "$$\n",
        "\n",
        "Con el código siguiente lo que estoy haciendo es simular una apuesta de un euro al resultado que predice mi modelo, en todos los partidos que hay en test. Si se acierta sumamos la cuota que ofrece Bet365 pero si falla se resta la unidad apostada. Con esto calculamos el beneficio neto y el ROI."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HcDm7CLMiug8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FEAT = DATA / \"03_features\"\n",
        "PROC = DATA / \"02_processed\"\n",
        "df      = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "df_old  = pd.read_parquet(PROC / \"df_new_features.parquet\").reset_index(drop=True)\n",
        "\n",
        "\n",
        "# ---------- Split de TEST con índices ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "\n",
        "# ---------- Alinear columnas al fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "\n",
        "# ---------- Simulación ROI (bien indentada + min_edge) ----------\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "):\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs = scaler.transform(X_test)\n",
        "    proba = model.predict_proba(Xs)\n",
        "    y_pred = model.predict(Xs)\n",
        "\n",
        "    # 3) Meta-información: SIEMPRE primero de df con idx_test\n",
        "    need = ['Date','Season','HomeTeam_norm','AwayTeam_norm','B365H','B365D','B365A']\n",
        "    have_df = [c for c in need if c in df.columns]\n",
        "    res = df.loc[idx_test, have_df].copy()\n",
        "\n",
        "    # Relleno fino desde meta_df (misma alineación por índice; ya reseteados antes)\n",
        "    if meta_df is not None:\n",
        "        have_meta = [c for c in need if c in meta_df.columns]\n",
        "        aux = meta_df.loc[idx_test, have_meta]\n",
        "        for c in need:\n",
        "            if c not in res.columns:\n",
        "                res[c] = aux[c] if c in aux.columns else np.nan\n",
        "            else:\n",
        "                if c in aux.columns:\n",
        "                    res[c] = res[c].where(res[c].notna(), aux[c])\n",
        "\n",
        "    # Exige tener nombres y odds completos\n",
        "    must_have = ['HomeTeam_norm','AwayTeam_norm','B365H','B365D','B365A']\n",
        "    for c in must_have:\n",
        "        if c not in res.columns:\n",
        "            raise ValueError(f\"Falta columna clave: {c}\")\n",
        "    mask_ok_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_ok_odds].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 4) Añadir verdad/predicción\n",
        "    res['true_result'] = y_test.loc[res.index].values\n",
        "    res['predicted_result'] = pd.Series(y_pred, index=idx_test).loc[res.index].values\n",
        "\n",
        "    # 5) Probabilidad / odds / edge de la clase predicha\n",
        "    classes = list(model.classes_)\n",
        "    proba_df = pd.DataFrame(proba, index=idx_test, columns=classes).loc[res.index]\n",
        "    proba_df = proba_df[[c for c in [0,1,2] if c in proba_df.columns]]\n",
        "\n",
        "    pred_idx = res['predicted_result'].map({0:0, 1:1, 2:2}).to_numpy()\n",
        "    res['predicted_prob'] = proba_df.to_numpy()[np.arange(len(res)), pred_idx]\n",
        "\n",
        "    odds_mat = res[['B365A','B365D','B365H']].to_numpy()\n",
        "    res['predicted_odds'] = odds_mat[np.arange(len(res)), pred_idx]\n",
        "    res['edge'] = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "        if res.empty:\n",
        "            return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # Formato fecha al final\n",
        "    res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets = int(len(res))\n",
        "    roi = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "\n",
        "    return res, roi, total_net"
      ],
      "metadata": {
        "id": "y2EahNkyCZ1e"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "results_df, roi, total_profit = simulate_bet365_roi(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True, stake=1.0, meta_df=df_old)\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ca_qtV0Iqu9z",
        "outputId": "675d45e6-932d-4362-d1b6-3fe6b4ac52c7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date  Season  B365H  B365D  B365A HomeTeam_norm AwayTeam_norm  \\\n",
              "7220  2025-08-15    2025   2.25   3.25   3.30    ath bilbao        getafe   \n",
              "7221  2025-08-15    2025   1.40   4.75   8.00         betis        girona   \n",
              "7222  2025-08-16    2025   2.15   3.00   3.80         celta        alaves   \n",
              "7223  2025-08-16    2025   2.60   2.90   3.10    las palmas       sevilla   \n",
              "7224  2025-08-16    2025   7.00   5.00   1.40       osasuna       leganes   \n",
              "7225  2025-08-17    2025   1.73   3.50   5.25      valencia     barcelona   \n",
              "7226  2025-08-17    2025   1.57   3.90   6.00      sociedad     vallecano   \n",
              "7227  2025-08-17    2025   6.00   3.90   1.57      mallorca   real madrid   \n",
              "7228  2025-08-18    2025   3.40   3.30   2.20    valladolid       espanol   \n",
              "7229  2025-08-19    2025   1.22   6.25  13.00    villarreal    ath madrid   \n",
              "7230  2025-08-22    2025   1.91   3.40   4.20         celta      valencia   \n",
              "7231  2025-08-23    2025  11.00   6.00   1.25       sevilla    villarreal   \n",
              "7232  2025-08-23    2025   3.00   3.10   2.55       osasuna      mallorca   \n",
              "7233  2025-08-23    2025   1.25   5.25  15.00     barcelona    ath bilbao   \n",
              "7234  2025-08-24    2025   1.80   3.40   5.00       espanol      sociedad   \n",
              "7235  2025-08-24    2025   2.40   3.20   3.10        getafe     vallecano   \n",
              "7236  2025-08-24    2025   9.50   5.50   1.30   real madrid    valladolid   \n",
              "7237  2025-08-24    2025   1.53   4.33   6.00       leganes    las palmas   \n",
              "7238  2025-08-25    2025   1.70   3.50   5.50        alaves         betis   \n",
              "7239  2025-08-25    2025   2.25   3.00   3.60    ath madrid        girona   \n",
              "7240  2025-08-27    2025   2.20   3.40   3.25    villarreal         celta   \n",
              "7241  2025-08-29    2025   2.15   3.25   3.50      mallorca       sevilla   \n",
              "7242  2025-08-29    2025   2.30   2.90   3.60     vallecano     barcelona   \n",
              "7243  2025-08-30    2025   4.75   3.50   1.80    ath bilbao      valencia   \n",
              "7244  2025-08-30    2025   3.50   3.10   2.25    valladolid       leganes   \n",
              "7245  2025-08-30    2025   2.40   3.30   3.00    ath madrid       espanol   \n",
              "7246  2025-08-30    2025   1.18   7.00  15.00      sociedad        alaves   \n",
              "7247  2025-08-31    2025   2.38   3.20   3.10        girona       osasuna   \n",
              "7248  2025-08-31    2025   2.75   3.50   2.50    las palmas   real madrid   \n",
              "7249  2025-08-31    2025   3.00   3.10   2.55    ath bilbao    ath madrid   \n",
              "7250  2025-08-31    2025   6.25   5.50   1.40       leganes      mallorca   \n",
              "7251  2025-09-12    2025   1.85   3.40   4.50     barcelona    valladolid   \n",
              "7252  2025-09-13    2025   1.95   3.10   4.50      valencia    villarreal   \n",
              "7253  2025-09-13    2025   5.00   4.33   1.60       espanol     vallecano   \n",
              "7254  2025-09-13    2025   1.60   3.90   5.75        alaves    las palmas   \n",
              "7255  2025-09-13    2025   1.80   3.70   4.33       osasuna         celta   \n",
              "7256  2025-09-14    2025   1.73   3.90   4.75       sevilla        girona   \n",
              "7257  2025-09-14    2025   3.25   3.25   2.30        getafe      sociedad   \n",
              "7258  2025-09-14    2025   2.55   3.20   2.90   real madrid         betis   \n",
              "7259  2025-09-14    2025   1.22   7.00  11.00         betis       leganes   \n",
              "7260  2025-09-15    2025   2.10   3.40   3.50      mallorca    villarreal   \n",
              "\n",
              "      true_result  predicted_result  predicted_prob  predicted_odds      edge  \\\n",
              "7220            0                 1        0.400167            3.25  0.300541   \n",
              "7221            2                 2        0.649056            1.40 -0.091321   \n",
              "7222            2                 0        0.356404            3.80  0.354335   \n",
              "7223            1                 1        0.443889            2.90  0.287277   \n",
              "7224            0                 0        0.740902            1.40  0.037263   \n",
              "7225            0                 2        0.482455            1.73 -0.165353   \n",
              "7226            2                 2        0.495957            1.57 -0.221348   \n",
              "7227            2                 0        0.663439            1.57  0.041599   \n",
              "7228            1                 0        0.469962            2.20  0.033917   \n",
              "7229            2                 2        0.759537            1.22 -0.073365   \n",
              "7230            2                 2        0.489292            1.91 -0.065452   \n",
              "7231            0                 0        0.832223            1.25  0.040279   \n",
              "7232            1                 0        0.421945            2.55  0.075960   \n",
              "7233            1                 2        0.823859            1.25  0.029823   \n",
              "7234            1                 2        0.487931            1.80 -0.121724   \n",
              "7235            2                 1        0.382552            3.20  0.224166   \n",
              "7236            0                 0        0.848929            1.30  0.103608   \n",
              "7237            2                 2        0.629680            1.53 -0.036589   \n",
              "7238            2                 2        0.537262            1.70 -0.086655   \n",
              "7239            0                 2        0.387158            2.25 -0.128895   \n",
              "7240            1                 2        0.462533            2.20  0.017574   \n",
              "7241            2                 0        0.377101            3.50  0.319855   \n",
              "7242            2                 2        0.381102            2.30 -0.123466   \n",
              "7243            1                 0        0.617796            1.80  0.112033   \n",
              "7244            2                 0        0.456672            2.25  0.027512   \n",
              "7245            0                 1        0.378390            3.30  0.248688   \n",
              "7246            2                 2        0.788391            1.18 -0.069699   \n",
              "7247            2                 2        0.358539            2.38 -0.146677   \n",
              "7248            1                 0        0.397441            2.50 -0.006398   \n",
              "7249            0                 1        0.368287            3.10  0.141691   \n",
              "7250            1                 0        0.731633            1.40  0.024286   \n",
              "7251            1                 2        0.541928            1.85  0.002567   \n",
              "7252            2                 2        0.409182            1.95 -0.202095   \n",
              "7253            0                 0        0.554822            1.60 -0.112285   \n",
              "7254            0                 2        0.550616            1.60 -0.119014   \n",
              "7255            2                 2        0.469999            1.80 -0.154001   \n",
              "7256            1                 2        0.561560            1.73 -0.028502   \n",
              "7257            1                 0        0.364248            2.30 -0.162229   \n",
              "7258            2                 2        0.352265            2.55 -0.101724   \n",
              "7259            2                 2        0.830355            1.22  0.013033   \n",
              "7260            2                 1        0.368309            3.40  0.252250   \n",
              "\n",
              "      bet_outcome  net_profit  \n",
              "7220         0.00       -1.00  \n",
              "7221         1.40        0.40  \n",
              "7222         0.00       -1.00  \n",
              "7223         2.90        1.90  \n",
              "7224         1.40        0.40  \n",
              "7225         0.00       -1.00  \n",
              "7226         1.57        0.57  \n",
              "7227         0.00       -1.00  \n",
              "7228         0.00       -1.00  \n",
              "7229         1.22        0.22  \n",
              "7230         1.91        0.91  \n",
              "7231         1.25        0.25  \n",
              "7232         0.00       -1.00  \n",
              "7233         0.00       -1.00  \n",
              "7234         0.00       -1.00  \n",
              "7235         0.00       -1.00  \n",
              "7236         1.30        0.30  \n",
              "7237         1.53        0.53  \n",
              "7238         1.70        0.70  \n",
              "7239         0.00       -1.00  \n",
              "7240         0.00       -1.00  \n",
              "7241         0.00       -1.00  \n",
              "7242         2.30        1.30  \n",
              "7243         0.00       -1.00  \n",
              "7244         0.00       -1.00  \n",
              "7245         0.00       -1.00  \n",
              "7246         1.18        0.18  \n",
              "7247         2.38        1.38  \n",
              "7248         0.00       -1.00  \n",
              "7249         0.00       -1.00  \n",
              "7250         0.00       -1.00  \n",
              "7251         0.00       -1.00  \n",
              "7252         1.95        0.95  \n",
              "7253         1.60        0.60  \n",
              "7254         0.00       -1.00  \n",
              "7255         1.80        0.80  \n",
              "7256         0.00       -1.00  \n",
              "7257         0.00       -1.00  \n",
              "7258         2.55        1.55  \n",
              "7259         1.22        0.22  \n",
              "7260         0.00       -1.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-608cd90a-cd31-4ffc-98b7-7e3dbd5fcd9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Season</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>true_result</th>\n",
              "      <th>predicted_result</th>\n",
              "      <th>predicted_prob</th>\n",
              "      <th>predicted_odds</th>\n",
              "      <th>edge</th>\n",
              "      <th>bet_outcome</th>\n",
              "      <th>net_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7220</th>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.30</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.400167</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.300541</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7221</th>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.40</td>\n",
              "      <td>4.75</td>\n",
              "      <td>8.00</td>\n",
              "      <td>betis</td>\n",
              "      <td>girona</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.649056</td>\n",
              "      <td>1.40</td>\n",
              "      <td>-0.091321</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.80</td>\n",
              "      <td>celta</td>\n",
              "      <td>alaves</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.356404</td>\n",
              "      <td>3.80</td>\n",
              "      <td>0.354335</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.10</td>\n",
              "      <td>las palmas</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.443889</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.287277</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>2025</td>\n",
              "      <td>7.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>leganes</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.740902</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.037263</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7225</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.25</td>\n",
              "      <td>valencia</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.482455</td>\n",
              "      <td>1.73</td>\n",
              "      <td>-0.165353</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7226</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.57</td>\n",
              "      <td>3.90</td>\n",
              "      <td>6.00</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.495957</td>\n",
              "      <td>1.57</td>\n",
              "      <td>-0.221348</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7227</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>2025</td>\n",
              "      <td>6.00</td>\n",
              "      <td>3.90</td>\n",
              "      <td>1.57</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.663439</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.041599</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7228</th>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.20</td>\n",
              "      <td>valladolid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469962</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.033917</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7229</th>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.22</td>\n",
              "      <td>6.25</td>\n",
              "      <td>13.00</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.759537</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.073365</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7230</th>\n",
              "      <td>2025-08-22</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.20</td>\n",
              "      <td>celta</td>\n",
              "      <td>valencia</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.489292</td>\n",
              "      <td>1.91</td>\n",
              "      <td>-0.065452</td>\n",
              "      <td>1.91</td>\n",
              "      <td>0.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7231</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>2025</td>\n",
              "      <td>11.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.25</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.832223</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.040279</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7232</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.55</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.421945</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.075960</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7233</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.25</td>\n",
              "      <td>5.25</td>\n",
              "      <td>15.00</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.823859</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.029823</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7234</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.40</td>\n",
              "      <td>5.00</td>\n",
              "      <td>espanol</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.487931</td>\n",
              "      <td>1.80</td>\n",
              "      <td>-0.121724</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7235</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.10</td>\n",
              "      <td>getafe</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.382552</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.224166</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>2025</td>\n",
              "      <td>9.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1.30</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>valladolid</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.848929</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.103608</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7237</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.33</td>\n",
              "      <td>6.00</td>\n",
              "      <td>leganes</td>\n",
              "      <td>las palmas</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.629680</td>\n",
              "      <td>1.53</td>\n",
              "      <td>-0.036589</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7238</th>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>alaves</td>\n",
              "      <td>betis</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.537262</td>\n",
              "      <td>1.70</td>\n",
              "      <td>-0.086655</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>girona</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.387158</td>\n",
              "      <td>2.25</td>\n",
              "      <td>-0.128895</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7240</th>\n",
              "      <td>2025-08-27</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.25</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>celta</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.462533</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.017574</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7241</th>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.377101</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.319855</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7242</th>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.60</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.381102</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-0.123466</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7243</th>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>2025</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.80</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>valencia</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.617796</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.112033</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7244</th>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.25</td>\n",
              "      <td>valladolid</td>\n",
              "      <td>leganes</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.456672</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.027512</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7245</th>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.00</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.378390</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.248688</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7246</th>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.18</td>\n",
              "      <td>7.00</td>\n",
              "      <td>15.00</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>alaves</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.788391</td>\n",
              "      <td>1.18</td>\n",
              "      <td>-0.069699</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7247</th>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.38</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.10</td>\n",
              "      <td>girona</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.358539</td>\n",
              "      <td>2.38</td>\n",
              "      <td>-0.146677</td>\n",
              "      <td>2.38</td>\n",
              "      <td>1.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7248</th>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.50</td>\n",
              "      <td>las palmas</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.397441</td>\n",
              "      <td>2.50</td>\n",
              "      <td>-0.006398</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7249</th>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.55</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.368287</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.141691</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7250</th>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>2025</td>\n",
              "      <td>6.25</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1.40</td>\n",
              "      <td>leganes</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.731633</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.024286</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7251</th>\n",
              "      <td>2025-09-12</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.85</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.50</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>valladolid</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.541928</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.002567</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7252</th>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.95</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.50</td>\n",
              "      <td>valencia</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.409182</td>\n",
              "      <td>1.95</td>\n",
              "      <td>-0.202095</td>\n",
              "      <td>1.95</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7253</th>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>2025</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.60</td>\n",
              "      <td>espanol</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.554822</td>\n",
              "      <td>1.60</td>\n",
              "      <td>-0.112285</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7254</th>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.60</td>\n",
              "      <td>3.90</td>\n",
              "      <td>5.75</td>\n",
              "      <td>alaves</td>\n",
              "      <td>las palmas</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.550616</td>\n",
              "      <td>1.60</td>\n",
              "      <td>-0.119014</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7255</th>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.70</td>\n",
              "      <td>4.33</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>celta</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.469999</td>\n",
              "      <td>1.80</td>\n",
              "      <td>-0.154001</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7256</th>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.90</td>\n",
              "      <td>4.75</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>girona</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.561560</td>\n",
              "      <td>1.73</td>\n",
              "      <td>-0.028502</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7257</th>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>2025</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.30</td>\n",
              "      <td>getafe</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.364248</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-0.162229</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7258</th>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.55</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.90</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>betis</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.352265</td>\n",
              "      <td>2.55</td>\n",
              "      <td>-0.101724</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7259</th>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>2025</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>betis</td>\n",
              "      <td>leganes</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.830355</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.013033</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7260</th>\n",
              "      <td>2025-09-15</td>\n",
              "      <td>2025</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.50</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.368309</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.252250</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-608cd90a-cd31-4ffc-98b7-7e3dbd5fcd9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-608cd90a-cd31-4ffc-98b7-7e3dbd5fcd9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-608cd90a-cd31-4ffc-98b7-7e3dbd5fcd9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43ade857-0120-40de-b5a4-7025b61a4ea9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43ade857-0120-40de-b5a4-7025b61a4ea9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43ade857-0120-40de-b5a4-7025b61a4ea9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_026d8fad-a6f0-4182-a7ab-0042cd4722e0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_026d8fad-a6f0-4182-a7ab-0042cd4722e0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS2TXT = {0:\"A\", 1:\"D\", 2:\"H\"}  # 0=Away, 1=Draw, 2=Home\n",
        "\n",
        "def _max_drawdown(equity: pd.Series):\n",
        "    \"\"\"Devuelve drawdown máximo: (mdd_abs, mdd_pct, peak_idx, trough_idx).\"\"\"\n",
        "    if equity.empty:\n",
        "        return 0.0, 0.0, None, None\n",
        "    running_max = equity.cummax()\n",
        "    drawdown = running_max - equity\n",
        "    trough_idx = drawdown.idxmax()\n",
        "    peak_idx = equity.loc[:trough_idx].idxmax() if trough_idx is not None else None\n",
        "    mdd_abs = float(drawdown.max())\n",
        "    peak_val = float(equity.loc[peak_idx]) if peak_idx is not None else 1.0\n",
        "    mdd_pct = float(mdd_abs / peak_val) if peak_val > 0 else 0.0\n",
        "    return mdd_abs, mdd_pct, peak_idx, trough_idx\n",
        "\n",
        "def _edge_bins(edge: pd.Series, bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Discretiza edge (EV) en tramos para analizar ROI por 'valor esperado'.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "# --- usa tus _prep_test_split y _align_to_fit_columns ya definidos en el notebook ---\n",
        "\n",
        "\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,     # filtro por EV mínimo (para la estrategia de predicción)\n",
        "):\n",
        "    \"\"\"\n",
        "    Devuelve (results_df, roi, total_profit) sobre el TEST indicado.\n",
        "    Mantiene tu 'edge' original (EV de la PREDICCIÓN) y añade columnas de 'valor':\n",
        "      - value_pick, value_ev, value_prob, value_odds  (mejor EV entre H/D/A)\n",
        "    \"\"\"\n",
        "    # 1) TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs = scaler.transform(X_test)\n",
        "    proba = model.predict_proba(Xs)\n",
        "    y_pred = model.predict(Xs)\n",
        "\n",
        "    # 3) Meta-información (Date/Home/Away/B365*)\n",
        "    want = ['Date','HomeTeam_norm','AwayTeam_norm','Season','B365H','B365D','B365A']\n",
        "    def pull(source):\n",
        "        cols = [c for c in want if (source is not None and c in source.columns)]\n",
        "        return source.reindex(X_test.index)[cols] if cols else pd.DataFrame(index=X_test.index)\n",
        "\n",
        "    meta = pull(df)\n",
        "    meta_old = pull(meta_df)\n",
        "    for c in want:\n",
        "        if c not in meta.columns:\n",
        "            meta[c] = np.nan\n",
        "        if c in meta_old.columns:\n",
        "            meta[c] = meta[c].where(meta[c].notna(), meta_old[c])\n",
        "\n",
        "    # 4) Construcción de results_df\n",
        "    res = meta.copy()\n",
        "    res['true_result'] = y_test.values\n",
        "    res['predicted_result'] = y_pred\n",
        "\n",
        "    # --- Probabilidades en DataFrame con columnas 'A','D','H' (mapeo desde model.classes_) ---\n",
        "    classes = list(model.classes_)                 # típicamente [0,1,2] => A,D,H\n",
        "    name_map = {0:'A', 1:'D', 2:'H'}\n",
        "    col_names = [name_map.get(c, str(c)) for c in classes]\n",
        "    proba_df = pd.DataFrame(proba, index=X_test.index, columns=col_names)\n",
        "    # fijamos orden canónico\n",
        "    proba_fixed = proba_df.reindex(columns=['A','D','H'])\n",
        "\n",
        "    # --- Cuotas en el mismo orden canónico ---\n",
        "    odds_df = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})\n",
        "    odds_fixed = odds_df[['A','D','H']]\n",
        "\n",
        "    # --- Predicción del modelo (texto) y EV de la predicción (tu 'edge' original) ---\n",
        "    pred_txt = pd.Series(y_pred, index=X_test.index).map(name_map)\n",
        "    idx_of = {'A':0, 'D':1, 'H':2}\n",
        "    pred_idx = pred_txt.map(idx_of).to_numpy()\n",
        "\n",
        "    proba_mat = proba_fixed.to_numpy()\n",
        "    odds_mat  = odds_fixed.to_numpy()\n",
        "\n",
        "    res['Pred'] = pred_txt\n",
        "    res['predicted_prob'] = proba_mat[np.arange(len(res)), pred_idx]\n",
        "    res['predicted_odds'] = odds_mat[np.arange(len(res)), pred_idx]\n",
        "    res['edge'] = res['predicted_prob'] * res['predicted_odds'] - 1.0  # <-- edge EV de la predicción (como antes)\n",
        "\n",
        "    # --- NUEVO: EV por clase y mejor selección por EV (value betting) ---\n",
        "    ev_df = proba_fixed * odds_fixed - 1.0                  # EV para H/D/A\n",
        "    best_idx = ev_df.to_numpy().argmax(axis=1)\n",
        "    labels = np.array(['A','D','H'])\n",
        "    res['value_pick'] = labels[best_idx]\n",
        "    res['value_ev']   = ev_df.to_numpy()[np.arange(len(ev_df)), best_idx]\n",
        "    res['value_prob'] = proba_mat[np.arange(len(proba_mat)), best_idx]\n",
        "    res['value_odds'] = odds_mat[np.arange(len(odds_mat)), best_idx]\n",
        "\n",
        "    # 5) Exigir cuotas completas y filtrar por min_edge (aplicado al edge de PREDICCIÓN)\n",
        "    mask_ok_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_ok_odds].copy()\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación \"apuesto a la predicción\"\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # (opcional) también podrías simular la estrategia de valor:\n",
        "    # value_idx = res['value_pick'].map(idx_of).to_numpy()\n",
        "    # value_hit = (value_idx == res['true_result'])\n",
        "    # value_odds = odds_mat[np.arange(len(res)), value_idx]\n",
        "    # res['value_net_profit'] = np.where(value_hit, value_odds * stake, 0.0) - stake\n",
        "\n",
        "    # limpieza visual\n",
        "    if 'Date' in res.columns:\n",
        "        res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets = int(len(res))\n",
        "    roi = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "\n",
        "    return res, roi, total_net\n",
        "\n",
        "\n",
        "def build_roi_grid(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    seasons: list[int] | None = None,   # si None, usa todas\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "    model_name: str = \"base\",\n",
        "    out_dir: Path | None = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Recorre temporadas y guarda JSON/CSV con ROI por temporada basándose en la\n",
        "    estrategia \"apuesto a la predicción\". Mantiene 'edge' y añade métricas.\n",
        "    \"\"\"\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    OUT = (out_dir or (ROOT / \"outputs\"))\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rows = []\n",
        "    flat_for_csv = []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        res, roi, total_net = simulate_bet365_roi(\n",
        "            df, model, scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=with_odds, stake=stake,\n",
        "            meta_df=meta_df, feature_names=feature_names,\n",
        "            min_edge=min_edge\n",
        "        )\n",
        "        if res is None or len(res) == 0:\n",
        "            continue\n",
        "\n",
        "        # ordenar por fecha para equity\n",
        "        tmp = res.copy()\n",
        "        if 'Date' in tmp.columns:\n",
        "            tmp['_Date'] = pd.to_datetime(tmp['Date'], errors='coerce')\n",
        "        else:\n",
        "            tmp['_Date'] = pd.NaT\n",
        "        tmp = tmp.sort_values(['_Date']).drop(columns=['_Date'])\n",
        "\n",
        "        equity = tmp['net_profit'].cumsum()\n",
        "        mdd_abs, mdd_pct, _, _ = _max_drawdown(equity)\n",
        "\n",
        "        # métricas adicionales\n",
        "        hit_rate = float((tmp['predicted_result'] == tmp['true_result']).mean())\n",
        "        avg_odds = float(tmp['predicted_odds'].mean())\n",
        "        avg_edge = float(tmp['edge'].mean())\n",
        "        # nuevo: medias del \"valor\"\n",
        "        avg_value_ev   = float(tmp['value_ev'].mean())\n",
        "        avg_value_prob = float(tmp['value_prob'].mean())\n",
        "        avg_value_odds = float(tmp['value_odds'].mean())\n",
        "\n",
        "        # beneficio por clase predicha\n",
        "        by_class = tmp.groupby(tmp['predicted_result']).agg(\n",
        "            profit=('net_profit','sum'), n=('net_profit','size')\n",
        "        )\n",
        "        profit_by_class = {CLASS2TXT.get(int(k), str(k)): float(v) for k, v in by_class['profit'].items()}\n",
        "\n",
        "        # ROI por tramos de edge (predicción)\n",
        "        bins = _edge_bins(tmp['edge'])\n",
        "        by_bin = tmp.groupby(bins, observed=True).agg(\n",
        "            n=('net_profit','size'),\n",
        "            profit=('net_profit','sum'),\n",
        "            avg_prob=('predicted_prob','mean'),\n",
        "            avg_odds=('predicted_odds','mean'),\n",
        "            avg_edge=('edge','mean')\n",
        "        ).reset_index(names='edge_bin')\n",
        "        by_bin['roi'] = by_bin.apply(\n",
        "            lambda r: (r['profit'] / (stake * r['n'])) if r['n'] > 0 else np.nan, axis=1\n",
        "        )\n",
        "        roi_by_edge_bins = [\n",
        "            {\n",
        "                \"bin\": str(row['edge_bin']),\n",
        "                \"n\": int(row['n']),\n",
        "                \"roi\": float(row['roi']),\n",
        "                \"profit_total\": float(row['profit']),\n",
        "                \"avg_prob\": float(row['avg_prob']),\n",
        "                \"avg_odds\": float(row['avg_odds']),\n",
        "                \"avg_edge\": float(row['avg_edge']),\n",
        "            }\n",
        "            for _, row in by_bin.iterrows()\n",
        "        ]\n",
        "\n",
        "        row = {\n",
        "            \"model\": model_name,\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"roi\": float(roi),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),       # <-- nuevo\n",
        "            \"avg_value_prob\": float(avg_value_prob),   # <-- nuevo\n",
        "            \"avg_value_odds\": float(avg_value_odds),   # <-- nuevo\n",
        "            \"profit_by_class\": profit_by_class,\n",
        "            \"equity\": [float(x) for x in equity.tolist()],\n",
        "            \"max_drawdown_abs\": float(mdd_abs),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"roi_by_edge_bins\": roi_by_edge_bins,\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "        # resumido para CSV\n",
        "        flat_for_csv.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_season\": int(test_season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"roi\": float(roi),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),     # <-- nuevo\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "        })\n",
        "\n",
        "    # guardar\n",
        "    tag = f\"{model_name}\".replace(\" \", \"_\")\n",
        "    with open( (out_dir or (ROOT / \"outputs\")) / f\"roi_by_season_{tag}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    if flat_for_csv:\n",
        "        pd.DataFrame(flat_for_csv).sort_values(\"test_season\").to_csv(\n",
        "            (out_dir or (ROOT / \"outputs\")) / f\"roi_by_season_{tag}.csv\", index=False\n",
        "        )\n",
        "\n",
        "    print(f\"Guardados:\\n- {(out_dir or (ROOT/'outputs'))/f'roi_by_season_{tag}.json'}\\n- {(out_dir or (ROOT/'outputs'))/f'roi_by_season_{tag}.csv'}\")\n",
        "    return rows"
      ],
      "metadata": {
        "id": "FkL257T6X1Wr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === BASE ===\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model, scaler=scaler,\n",
        "    seasons=None,               # todas\n",
        "    with_odds=True,\n",
        "    stake=1.0,\n",
        "    meta_df=df_old,             # para nombres/fechas/cuotas si hace falta\n",
        "    min_edge=0.00,              # prueba 0.02 / 0.05 si quieres filtrar valor esperado\n",
        "    model_name=\"base\"\n",
        ")\n",
        "\n",
        "# === SMOTE (si tienes model_sm, scaler_sm) ===\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model_sm, scaler=scaler_sm,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    meta_df=df_old, min_edge=0.00,\n",
        "    model_name=\"smote\"\n",
        ")"
      ],
      "metadata": {
        "id": "mj1c8-t_X1Rd",
        "outputId": "f29f0133-a59b-4f1a-efff-24513bac4335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardados:\n",
            "- /content/outputs/roi_by_season_base.json\n",
            "- /content/outputs/roi_by_season_base.csv\n",
            "Guardados:\n",
            "- /content/outputs/roi_by_season_smote.json\n",
            "- /content/outputs/roi_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBffDLHUX1nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4M89pS1XysGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Mapas útiles (mantén los tuyos si ya existen) ===\n",
        "CLASS2LABEL = {0: 'Away', 1: 'Draw', 2: 'Home'}\n",
        "LABEL2CLASS = {'A':0, 'D':1, 'H':2}  # por si lo necesitas\n",
        "\n",
        "def _add_value_strategy_if_missing(results_df: pd.DataFrame, stake: float = 1.0) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Si el results_df viene de simulate_bet365_roi (versión con 'value_pick', 'value_ev', ...),\n",
        "    calcula columnas de la estrategia de valor (value_*). Si ya existen, no hace nada.\n",
        "    \"\"\"\n",
        "    df = results_df.copy()\n",
        "    need_cols = {'value_pick','value_prob','value_odds'}\n",
        "    if not need_cols.issubset(df.columns):\n",
        "        # No hay columnas de valor (quizá llamaste a una versión antigua de simulate_bet365_roi)\n",
        "        return df\n",
        "\n",
        "    # Índice/clase de la selección de valor\n",
        "    idx_map = {'A':0, 'D':1, 'H':2}\n",
        "    value_idx = df['value_pick'].map(idx_map).to_numpy()\n",
        "\n",
        "    # Éxito de la apuesta de valor\n",
        "    df['value_correct'] = (value_idx == df['true_result']).map({True:'✓', False:'✗'})\n",
        "\n",
        "    # Beneficio de la apuesta de valor\n",
        "    df['value_bet_return'] = np.where(df['value_correct'] == '✓', df['value_odds'] * stake, 0.0)\n",
        "    df['value_net_profit'] = df['value_bet_return'] - stake\n",
        "    return df\n",
        "\n",
        "def build_bets_summary(results_df: pd.DataFrame,\n",
        "                       sort_by_date: bool = True,\n",
        "                       round_decimals: int = 2,\n",
        "                       save_path: str | None = None,\n",
        "                       include_value: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    A partir del results_df (simulate_bet365_roi), construye una tabla resumen\n",
        "    de la estrategia de PREDICCIÓN y, opcionalmente, también la de VALOR.\n",
        "\n",
        "    Salida (columnas):\n",
        "      Fecha/Partido + Predicción:\n",
        "        - Predicted, True, Correct\n",
        "        - Pred_prob, Pred_odds, Pred_edge\n",
        "        - Bet_return, Net_profit, Cum_net_profit\n",
        "      Valor (si include_value=True y hay columnas value_*):\n",
        "        - Value_pick, Value_prob, Value_odds, Value_ev\n",
        "        - Value_return, Value_profit, Value_cum_profit\n",
        "    \"\"\"\n",
        "    if results_df is None or results_df.empty:\n",
        "        raise ValueError(\"results_df vacío o None.\")\n",
        "\n",
        "    df = results_df.copy()\n",
        "\n",
        "    # Asegura columnas de estrategia de valor si existen los insumos (no rompe nada si ya estaban)\n",
        "    if include_value:\n",
        "        df = _add_value_strategy_if_missing(df, stake=1.0)\n",
        "\n",
        "    # Fecha y orden\n",
        "    if 'Date' in df.columns:\n",
        "        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "    else:\n",
        "        df['Date'] = pd.NaT\n",
        "\n",
        "    if sort_by_date and df['Date'].notna().any():\n",
        "        df = df.sort_values(['Date']).reset_index(drop=True)\n",
        "\n",
        "    # Partido + etiquetas\n",
        "    home = df.get('HomeTeam_norm', pd.Series(index=df.index, dtype='object')).fillna('—')\n",
        "    away = df.get('AwayTeam_norm', pd.Series(index=df.index, dtype='object')).fillna('—')\n",
        "    df['Match'] = home.astype(str) + \" vs \" + away.astype(str)\n",
        "\n",
        "    df['Predicted'] = df['predicted_result'].map(CLASS2LABEL).fillna('—')\n",
        "    df['True']      = df['true_result'].map(CLASS2LABEL).fillna('—')\n",
        "    df['Correct']   = np.where(df['predicted_result'] == df['true_result'], '✓', '✗')\n",
        "\n",
        "    # Prob, odds y edge de la predicción (si existen)\n",
        "    if 'predicted_prob' in df.columns:\n",
        "        df['Pred_prob'] = pd.to_numeric(df['predicted_prob'], errors='coerce')\n",
        "    else:\n",
        "        df['Pred_prob'] = np.nan\n",
        "\n",
        "    if 'predicted_odds' in df.columns:\n",
        "        df['Pred_odds'] = pd.to_numeric(df['predicted_odds'], errors='coerce')\n",
        "    else:\n",
        "        df['Pred_odds'] = np.nan\n",
        "\n",
        "    if 'edge' in df.columns:\n",
        "        df['Pred_edge'] = pd.to_numeric(df['edge'], errors='coerce')\n",
        "    else:\n",
        "        df['Pred_edge'] = np.nan\n",
        "\n",
        "    # Beneficios de predicción\n",
        "    df['Bet_return'] = pd.to_numeric(df.get('bet_outcome'), errors='coerce')\n",
        "    df['Net_profit'] = pd.to_numeric(df.get('net_profit'),  errors='coerce')\n",
        "    df['Cum_net_profit'] = df['Net_profit'].cumsum()\n",
        "\n",
        "    # Estrategia de valor (si procede)\n",
        "    if include_value and {'value_pick','value_prob','value_odds','value_ev'}.issubset(df.columns):\n",
        "        df['Value_pick']   = df['value_pick']\n",
        "        df['Value_prob']   = pd.to_numeric(df['value_prob'], errors='coerce')\n",
        "        df['Value_odds']   = pd.to_numeric(df['value_odds'], errors='coerce')\n",
        "        df['Value_ev']     = pd.to_numeric(df['value_ev'],   errors='coerce')\n",
        "        # correct/bet_return/net_profit de valor si los creamos arriba\n",
        "        if 'value_net_profit' not in df.columns:\n",
        "            # por si no se añadió anteriormente\n",
        "            df = _add_value_strategy_if_missing(df, stake=1.0)\n",
        "        df['Value_return']    = pd.to_numeric(df.get('value_bet_return'), errors='coerce')\n",
        "        df['Value_profit']    = pd.to_numeric(df.get('value_net_profit'), errors='coerce')\n",
        "        df['Value_cum_profit']= df['Value_profit'].cumsum()\n",
        "    else:\n",
        "        # columnas vacías si no hay estrategia de valor\n",
        "        df['Value_pick'] = df['Value_prob'] = df['Value_odds'] = df['Value_ev'] = np.nan\n",
        "        df['Value_return'] = df['Value_profit'] = df['Value_cum_profit'] = np.nan\n",
        "\n",
        "    # Redondeos “bonitos” para presentación\n",
        "    pct = lambda s: (s*100.0).round(1)  # prob y edge en %\n",
        "    df['Pred_prob_pct'] = pct(df['Pred_prob'])\n",
        "    df['Pred_edge_pct'] = pct(df['Pred_edge'])\n",
        "    df['Value_prob_pct'] = pct(df['Value_prob'])\n",
        "    df['Value_ev_pct']   = pct(df['Value_ev'])\n",
        "\n",
        "    # Selección y renombrado final\n",
        "    out_cols = [\n",
        "        'Date','Match','Predicted','True','Correct',\n",
        "        'Pred_prob_pct','Pred_odds','Pred_edge_pct',\n",
        "        'Bet_return','Net_profit','Cum_net_profit',\n",
        "        'Value_pick','Value_prob_pct','Value_odds','Value_ev_pct',\n",
        "        'Value_return','Value_profit','Value_cum_profit'\n",
        "    ]\n",
        "    summary = df[out_cols].copy()\n",
        "\n",
        "    # Formato fecha\n",
        "    summary['Date'] = summary['Date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    # Redondeos finales donde procede\n",
        "    num_cols_round_2 = ['Pred_odds','Bet_return','Net_profit','Cum_net_profit',\n",
        "                        'Value_odds','Value_return','Value_profit','Value_cum_profit']\n",
        "    for c in num_cols_round_2:\n",
        "        summary[c] = pd.to_numeric(summary[c], errors='coerce').round(round_decimals)\n",
        "\n",
        "    # Guardado opcional\n",
        "    if save_path:\n",
        "        summary.to_csv(save_path, index=False)\n",
        "        print(f\"Tabla resumen guardada en: {save_path}\")\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def simulate_and_summarize(df: pd.DataFrame, model, scaler,\n",
        "                           train_until_season: int = 2023,\n",
        "                           test_until_season: int | None = None,\n",
        "                           with_odds: bool = True,\n",
        "                           stake: float = 1.0,\n",
        "                           meta_df: pd.DataFrame | None = None,\n",
        "                           feature_names: list[str] | None = None,\n",
        "                           min_edge: float = 0.00,\n",
        "                           save_path: str | None = None,\n",
        "                           include_value: bool = True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Ejecuta la simulación (estrategia de PREDICCIÓN con filtro 'min_edge') y\n",
        "    devuelve un resumen que incluye también la estrategia de VALOR si está disponible.\n",
        "    \"\"\"\n",
        "    results_df, roi, total_profit = simulate_bet365_roi(\n",
        "        df, model, scaler,\n",
        "        train_until_season=train_until_season,\n",
        "        test_until_season=test_until_season,\n",
        "        with_odds=with_odds,\n",
        "        stake=stake,\n",
        "        meta_df=meta_df,\n",
        "        feature_names=feature_names,\n",
        "        min_edge=min_edge,\n",
        "    )\n",
        "    if results_df is None or results_df.empty:\n",
        "        print(\"Sin partidos válidos en TEST para ese rango/edge.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    summary = build_bets_summary(results_df, save_path=save_path, include_value=include_value)\n",
        "\n",
        "    # Métricas globales (predicción)\n",
        "    n_bets = len(summary)\n",
        "    total_pred = summary['Net_profit'].sum()\n",
        "    roi_pred = (total_pred / n_bets) if n_bets > 0 else np.nan\n",
        "\n",
        "    msg = f\"\\nResumen PRED: {n_bets} apuestas | Beneficio total: {total_pred:.2f} | ROI: {roi_pred*100:.2f}% (stake=1)\"\n",
        "    # Métricas globales (valor), si existen\n",
        "    if include_value and summary['Value_profit'].notna().any():\n",
        "        n_val = int(summary['Value_profit'].notna().sum())\n",
        "        total_val = float(summary['Value_profit'].sum())\n",
        "        roi_val = (total_val / n_val) if n_val > 0 else np.nan\n",
        "        msg += f\"\\nResumen VALOR: {n_val} apuestas | Beneficio total: {total_val:.2f} | ROI: {roi_val*100:.2f}% (stake=1)\"\n",
        "\n",
        "    print(msg)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "fdZMitWzysCv"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = simulate_and_summarize(\n",
        "    df, model, scaler,\n",
        "    train_until_season=2024, test_until_season=2025,\n",
        "    with_odds=True, stake=1.0,\n",
        "    meta_df=df_old, feature_names=None,\n",
        "    min_edge=0.00,                 # si quieres filtrar por EV mínimo de la predicción\n",
        "    save_path=\"resumen_apuestas.csv\",\n",
        "    include_value=True             # <- para añadir columnas de la estrategia “de valor”\n",
        ")\n",
        "display(summary.head(20))"
      ],
      "metadata": {
        "id": "DT3S8WPkzNh8",
        "outputId": "b08ce713-4b8f-4296-8099-dc8a50a874fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tabla resumen guardada en: resumen_apuestas.csv\n",
            "\n",
            "Resumen PRED: 41 apuestas | Beneficio total: -9.84 | ROI: -24.00% (stake=1)\n",
            "Resumen VALOR: 41 apuestas | Beneficio total: -13.53 | ROI: -33.00% (stake=1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          Date                      Match Predicted  True Correct  \\\n",
              "0   2025-08-15       ath bilbao vs getafe      Draw  Away       ✗   \n",
              "1   2025-08-15            betis vs girona      Home  Home       ✓   \n",
              "2   2025-08-16            celta vs alaves      Away  Home       ✗   \n",
              "3   2025-08-16      las palmas vs sevilla      Draw  Draw       ✓   \n",
              "4   2025-08-16         osasuna vs leganes      Away  Away       ✓   \n",
              "5   2025-08-17      valencia vs barcelona      Home  Away       ✗   \n",
              "6   2025-08-17      sociedad vs vallecano      Home  Home       ✓   \n",
              "7   2025-08-17    mallorca vs real madrid      Away  Home       ✗   \n",
              "8   2025-08-18      valladolid vs espanol      Away  Draw       ✗   \n",
              "9   2025-08-19   villarreal vs ath madrid      Home  Home       ✓   \n",
              "10  2025-08-22          celta vs valencia      Home  Home       ✓   \n",
              "11  2025-08-23      sevilla vs villarreal      Away  Away       ✓   \n",
              "12  2025-08-23        osasuna vs mallorca      Away  Draw       ✗   \n",
              "13  2025-08-23    barcelona vs ath bilbao      Home  Draw       ✗   \n",
              "14  2025-08-24        espanol vs sociedad      Home  Draw       ✗   \n",
              "15  2025-08-24        getafe vs vallecano      Draw  Home       ✗   \n",
              "16  2025-08-24  real madrid vs valladolid      Away  Away       ✓   \n",
              "17  2025-08-24      leganes vs las palmas      Home  Home       ✓   \n",
              "18  2025-08-25            alaves vs betis      Home  Home       ✓   \n",
              "19  2025-08-25       ath madrid vs girona      Home  Away       ✗   \n",
              "\n",
              "    Pred_prob_pct  Pred_odds  Pred_edge_pct  Bet_return  Net_profit  \\\n",
              "0            40.0       3.25           30.1        0.00       -1.00   \n",
              "1            64.9       1.40           -9.1        1.40        0.40   \n",
              "2            35.6       3.80           35.4        0.00       -1.00   \n",
              "3            44.4       2.90           28.7        2.90        1.90   \n",
              "4            74.1       1.40            3.7        1.40        0.40   \n",
              "5            48.2       1.73          -16.5        0.00       -1.00   \n",
              "6            49.6       1.57          -22.1        1.57        0.57   \n",
              "7            66.3       1.57            4.2        0.00       -1.00   \n",
              "8            47.0       2.20            3.4        0.00       -1.00   \n",
              "9            76.0       1.22           -7.3        1.22        0.22   \n",
              "10           48.9       1.91           -6.5        1.91        0.91   \n",
              "11           83.2       1.25            4.0        1.25        0.25   \n",
              "12           42.2       2.55            7.6        0.00       -1.00   \n",
              "13           82.4       1.25            3.0        0.00       -1.00   \n",
              "14           48.8       1.80          -12.2        0.00       -1.00   \n",
              "15           38.3       3.20           22.4        0.00       -1.00   \n",
              "16           84.9       1.30           10.4        1.30        0.30   \n",
              "17           63.0       1.53           -3.7        1.53        0.53   \n",
              "18           53.7       1.70           -8.7        1.70        0.70   \n",
              "19           38.7       2.25          -12.9        0.00       -1.00   \n",
              "\n",
              "    Cum_net_profit Value_pick  Value_prob_pct  Value_odds  Value_ev_pct  \\\n",
              "0            -1.00          D            40.0        3.25          30.1   \n",
              "1            -0.60          A            21.3        8.00          70.1   \n",
              "2            -1.60          A            35.6        3.80          35.4   \n",
              "3             0.30          D            44.4        2.90          28.7   \n",
              "4             0.70          A            74.1        1.40           3.7   \n",
              "5            -0.30          A            22.5        5.25          18.1   \n",
              "6             0.27          D            36.4        3.90          42.1   \n",
              "7            -0.73          A            66.3        1.57           4.2   \n",
              "8            -1.73          A            47.0        2.20           3.4   \n",
              "9            -1.51          D            20.6        6.25          28.6   \n",
              "10           -0.60          D            29.9        3.40           1.7   \n",
              "11           -0.35          A            83.2        1.25           4.0   \n",
              "12           -1.35          A            42.2        2.55           7.6   \n",
              "13           -2.35          H            82.4        1.25           3.0   \n",
              "14           -3.35          D            38.7        3.40          31.6   \n",
              "15           -4.35          D            38.3        3.20          22.4   \n",
              "16           -4.05          A            84.9        1.30          10.4   \n",
              "17           -3.52          D            24.2        4.33           5.0   \n",
              "18           -2.82          D            30.2        3.50           5.6   \n",
              "19           -3.82          A            29.4        3.60           5.8   \n",
              "\n",
              "    Value_return  Value_profit  Value_cum_profit  \n",
              "0           0.00         -1.00             -1.00  \n",
              "1           0.00         -1.00             -2.00  \n",
              "2           0.00         -1.00             -3.00  \n",
              "3           2.90          1.90             -1.10  \n",
              "4           1.40          0.40             -0.70  \n",
              "5           5.25          4.25              3.55  \n",
              "6           0.00         -1.00              2.55  \n",
              "7           0.00         -1.00              1.55  \n",
              "8           0.00         -1.00              0.55  \n",
              "9           0.00         -1.00             -0.45  \n",
              "10          0.00         -1.00             -1.45  \n",
              "11          1.25          0.25             -1.20  \n",
              "12          0.00         -1.00             -2.20  \n",
              "13          0.00         -1.00             -3.20  \n",
              "14          3.40          2.40             -0.80  \n",
              "15          0.00         -1.00             -1.80  \n",
              "16          1.30          0.30             -1.50  \n",
              "17          0.00         -1.00             -2.50  \n",
              "18          0.00         -1.00             -3.50  \n",
              "19          3.60          2.60             -0.90  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f61736dd-a082-4421-87fb-4db25dfd337c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Match</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>True</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Pred_prob_pct</th>\n",
              "      <th>Pred_odds</th>\n",
              "      <th>Pred_edge_pct</th>\n",
              "      <th>Bet_return</th>\n",
              "      <th>Net_profit</th>\n",
              "      <th>Cum_net_profit</th>\n",
              "      <th>Value_pick</th>\n",
              "      <th>Value_prob_pct</th>\n",
              "      <th>Value_odds</th>\n",
              "      <th>Value_ev_pct</th>\n",
              "      <th>Value_return</th>\n",
              "      <th>Value_profit</th>\n",
              "      <th>Value_cum_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>ath bilbao vs getafe</td>\n",
              "      <td>Draw</td>\n",
              "      <td>Away</td>\n",
              "      <td>✗</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.25</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>D</td>\n",
              "      <td>40.0</td>\n",
              "      <td>3.25</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>betis vs girona</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>64.9</td>\n",
              "      <td>1.40</td>\n",
              "      <td>-9.1</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>A</td>\n",
              "      <td>21.3</td>\n",
              "      <td>8.00</td>\n",
              "      <td>70.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>celta vs alaves</td>\n",
              "      <td>Away</td>\n",
              "      <td>Home</td>\n",
              "      <td>✗</td>\n",
              "      <td>35.6</td>\n",
              "      <td>3.80</td>\n",
              "      <td>35.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.60</td>\n",
              "      <td>A</td>\n",
              "      <td>35.6</td>\n",
              "      <td>3.80</td>\n",
              "      <td>35.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>las palmas vs sevilla</td>\n",
              "      <td>Draw</td>\n",
              "      <td>Draw</td>\n",
              "      <td>✓</td>\n",
              "      <td>44.4</td>\n",
              "      <td>2.90</td>\n",
              "      <td>28.7</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.90</td>\n",
              "      <td>0.30</td>\n",
              "      <td>D</td>\n",
              "      <td>44.4</td>\n",
              "      <td>2.90</td>\n",
              "      <td>28.7</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.90</td>\n",
              "      <td>-1.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>osasuna vs leganes</td>\n",
              "      <td>Away</td>\n",
              "      <td>Away</td>\n",
              "      <td>✓</td>\n",
              "      <td>74.1</td>\n",
              "      <td>1.40</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.70</td>\n",
              "      <td>A</td>\n",
              "      <td>74.1</td>\n",
              "      <td>1.40</td>\n",
              "      <td>3.7</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "      <td>-0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>valencia vs barcelona</td>\n",
              "      <td>Home</td>\n",
              "      <td>Away</td>\n",
              "      <td>✗</td>\n",
              "      <td>48.2</td>\n",
              "      <td>1.73</td>\n",
              "      <td>-16.5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.30</td>\n",
              "      <td>A</td>\n",
              "      <td>22.5</td>\n",
              "      <td>5.25</td>\n",
              "      <td>18.1</td>\n",
              "      <td>5.25</td>\n",
              "      <td>4.25</td>\n",
              "      <td>3.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>sociedad vs vallecano</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>49.6</td>\n",
              "      <td>1.57</td>\n",
              "      <td>-22.1</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.27</td>\n",
              "      <td>D</td>\n",
              "      <td>36.4</td>\n",
              "      <td>3.90</td>\n",
              "      <td>42.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>2.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>mallorca vs real madrid</td>\n",
              "      <td>Away</td>\n",
              "      <td>Home</td>\n",
              "      <td>✗</td>\n",
              "      <td>66.3</td>\n",
              "      <td>1.57</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>A</td>\n",
              "      <td>66.3</td>\n",
              "      <td>1.57</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>1.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>valladolid vs espanol</td>\n",
              "      <td>Away</td>\n",
              "      <td>Draw</td>\n",
              "      <td>✗</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.73</td>\n",
              "      <td>A</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>villarreal vs ath madrid</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-7.3</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "      <td>-1.51</td>\n",
              "      <td>D</td>\n",
              "      <td>20.6</td>\n",
              "      <td>6.25</td>\n",
              "      <td>28.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-08-22</td>\n",
              "      <td>celta vs valencia</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>48.9</td>\n",
              "      <td>1.91</td>\n",
              "      <td>-6.5</td>\n",
              "      <td>1.91</td>\n",
              "      <td>0.91</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>D</td>\n",
              "      <td>29.9</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>sevilla vs villarreal</td>\n",
              "      <td>Away</td>\n",
              "      <td>Away</td>\n",
              "      <td>✓</td>\n",
              "      <td>83.2</td>\n",
              "      <td>1.25</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.35</td>\n",
              "      <td>A</td>\n",
              "      <td>83.2</td>\n",
              "      <td>1.25</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-1.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>osasuna vs mallorca</td>\n",
              "      <td>Away</td>\n",
              "      <td>Draw</td>\n",
              "      <td>✗</td>\n",
              "      <td>42.2</td>\n",
              "      <td>2.55</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.35</td>\n",
              "      <td>A</td>\n",
              "      <td>42.2</td>\n",
              "      <td>2.55</td>\n",
              "      <td>7.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-2.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>barcelona vs ath bilbao</td>\n",
              "      <td>Home</td>\n",
              "      <td>Draw</td>\n",
              "      <td>✗</td>\n",
              "      <td>82.4</td>\n",
              "      <td>1.25</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-2.35</td>\n",
              "      <td>H</td>\n",
              "      <td>82.4</td>\n",
              "      <td>1.25</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-3.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>espanol vs sociedad</td>\n",
              "      <td>Home</td>\n",
              "      <td>Draw</td>\n",
              "      <td>✗</td>\n",
              "      <td>48.8</td>\n",
              "      <td>1.80</td>\n",
              "      <td>-12.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-3.35</td>\n",
              "      <td>D</td>\n",
              "      <td>38.7</td>\n",
              "      <td>3.40</td>\n",
              "      <td>31.6</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.40</td>\n",
              "      <td>-0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>getafe vs vallecano</td>\n",
              "      <td>Draw</td>\n",
              "      <td>Home</td>\n",
              "      <td>✗</td>\n",
              "      <td>38.3</td>\n",
              "      <td>3.20</td>\n",
              "      <td>22.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-4.35</td>\n",
              "      <td>D</td>\n",
              "      <td>38.3</td>\n",
              "      <td>3.20</td>\n",
              "      <td>22.4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-1.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>real madrid vs valladolid</td>\n",
              "      <td>Away</td>\n",
              "      <td>Away</td>\n",
              "      <td>✓</td>\n",
              "      <td>84.9</td>\n",
              "      <td>1.30</td>\n",
              "      <td>10.4</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-4.05</td>\n",
              "      <td>A</td>\n",
              "      <td>84.9</td>\n",
              "      <td>1.30</td>\n",
              "      <td>10.4</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.30</td>\n",
              "      <td>-1.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>leganes vs las palmas</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>63.0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>-3.7</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.53</td>\n",
              "      <td>-3.52</td>\n",
              "      <td>D</td>\n",
              "      <td>24.2</td>\n",
              "      <td>4.33</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>alaves vs betis</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home</td>\n",
              "      <td>✓</td>\n",
              "      <td>53.7</td>\n",
              "      <td>1.70</td>\n",
              "      <td>-8.7</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>-2.82</td>\n",
              "      <td>D</td>\n",
              "      <td>30.2</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-3.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>ath madrid vs girona</td>\n",
              "      <td>Home</td>\n",
              "      <td>Away</td>\n",
              "      <td>✗</td>\n",
              "      <td>38.7</td>\n",
              "      <td>2.25</td>\n",
              "      <td>-12.9</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "      <td>-3.82</td>\n",
              "      <td>A</td>\n",
              "      <td>29.4</td>\n",
              "      <td>3.60</td>\n",
              "      <td>5.8</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.60</td>\n",
              "      <td>-0.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f61736dd-a082-4421-87fb-4db25dfd337c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f61736dd-a082-4421-87fb-4db25dfd337c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f61736dd-a082-4421-87fb-4db25dfd337c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c37571ef-b862-4aac-b0be-a840040c7b4a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c37571ef-b862-4aac-b0be-a840040c7b4a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c37571ef-b862-4aac-b0be-a840040c7b4a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(summary\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"2025-08-24\",\n          \"2025-08-16\",\n          \"2025-08-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Match\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"ath bilbao vs getafe\",\n          \"leganes vs las palmas\",\n          \"getafe vs vallecano\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Draw\",\n          \"Home\",\n          \"Away\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"True\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Away\",\n          \"Home\",\n          \"Draw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correct\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\u2713\",\n          \"\\u2717\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_prob_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.429751575787908,\n        \"min\": 35.6,\n        \"max\": 84.9,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          40.0,\n          63.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_odds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7677780655207185,\n        \"min\": 1.22,\n        \"max\": 3.8,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          3.25,\n          1.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred_edge_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.086623243192495,\n        \"min\": -22.1,\n        \"max\": 35.4,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          30.1,\n          -3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bet_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8981026784575535,\n        \"min\": 0.0,\n        \"max\": 2.9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.53,\n          1.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Net_profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8981026784575534,\n        \"min\": -1.0,\n        \"max\": 1.9,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.53,\n          0.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cum_net_profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5579696639165381,\n        \"min\": -4.35,\n        \"max\": 0.7,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          -1.0,\n          -0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_pick\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_prob_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.54240860305673,\n        \"min\": 20.6,\n        \"max\": 84.9,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          40.0,\n          24.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_odds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.737576957780727,\n        \"min\": 1.25,\n        \"max\": 8.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          3.25,\n          8.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_ev_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.929331305228075,\n        \"min\": 1.7,\n        \"max\": 70.1,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          30.1,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5805478730324396,\n        \"min\": 0.0,\n        \"max\": 5.25,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.9,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5805478730324396,\n        \"min\": -1.0,\n        \"max\": 4.25,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.9,\n          2.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value_cum_profit\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8286391258615187,\n        \"min\": -3.5,\n        \"max\": 3.55,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          -1.0,\n          -2.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JposElvmrlP"
      },
      "source": [
        "**COMPARACIÓN CON EL MODELO DE BET365**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4yDpcqQz-6"
      },
      "source": [
        "El modelo basado en las cuotas de Bet365 consiste en predecir siempre el resultado más probable según la probabilidad implícita."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_bet365_baseline(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    round_decimals: int = 4,\n",
        "):\n",
        "    \"\"\"\n",
        "    Baseline Bet365 sobre el TEST:\n",
        "      - Reconstruye TEST con el mismo split temporal usado en tus funciones.\n",
        "      - Toma B365H/B365D/B365A de df y, si faltan, de meta_df (alineado por índice de X_test).\n",
        "      - Normaliza probabilidades implícitas y calcula métricas: accuracy, log_loss, Brier.\n",
        "      - Devuelve (tabla, métricas).\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1) TEST (usa tu helper) ---\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rng}).\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    idx = X_test.index\n",
        "\n",
        "    # --- 2) Traer cuotas B365 (df y/o meta_df) ---\n",
        "    cols = ['B365H', 'B365D', 'B365A']\n",
        "\n",
        "    def _pull(source: pd.DataFrame | None, cols: list[str]) -> pd.DataFrame:\n",
        "        if source is None:\n",
        "            return pd.DataFrame(index=idx)\n",
        "        have = [c for c in cols if c in source.columns]\n",
        "        if not have:\n",
        "            return pd.DataFrame(index=idx)\n",
        "        return source.reindex(idx)[have]\n",
        "\n",
        "    odds_df = _pull(df, cols)\n",
        "    odds_old = _pull(meta_df, cols)\n",
        "\n",
        "    for c in cols:\n",
        "        if c not in odds_df.columns:\n",
        "            odds_df[c] = np.nan\n",
        "    for c in cols:\n",
        "        if c in odds_old.columns:\n",
        "            odds_df[c] = odds_df[c].where(odds_df[c].notna(), odds_old[c])\n",
        "\n",
        "    # Filtrar filas con cuotas completas y > 0\n",
        "    mask_ok = odds_df[cols].notna().all(axis=1)\n",
        "    for c in cols:\n",
        "        mask_ok &= (pd.to_numeric(odds_df[c], errors='coerce') > 0)\n",
        "    odds_df = odds_df.loc[mask_ok].astype(float)\n",
        "    y_test  = y_test.loc[mask_ok]\n",
        "\n",
        "    if odds_df.empty:\n",
        "        print(\"⚠️ No hay partidos con cuotas B365 completas en el TEST.\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # --- 3) Probabilidades implícitas normalizadas ---\n",
        "    inv = 1.0 / odds_df[cols]\n",
        "    overround = inv.sum(axis=1).replace(0, np.nan)\n",
        "    prob_norm = inv.div(overround, axis=0)  # columnas: B365H, B365D, B365A\n",
        "\n",
        "    # Orden proba en clase (0=Away,1=Draw,2=Home) → [A, D, H]\n",
        "    bet365_proba = np.column_stack([\n",
        "        prob_norm['B365A'].to_numpy(),  # clase 0\n",
        "        prob_norm['B365D'].to_numpy(),  # clase 1\n",
        "        prob_norm['B365H'].to_numpy()   # clase 2\n",
        "    ])\n",
        "    bet365_pred = bet365_proba.argmax(axis=1)\n",
        "\n",
        "    # --- 4) Métricas ---\n",
        "    classes = [0, 1, 2]\n",
        "    acc = float(accuracy_score(y_test, bet365_pred))\n",
        "    ll  = float(log_loss(y_test, bet365_proba, labels=classes))\n",
        "    y_bin = label_binarize(y_test, classes=classes)\n",
        "    brier = float(np.mean(np.sum((bet365_proba - y_bin) ** 2, axis=1)))\n",
        "\n",
        "    # --- 5) Tabla resumen por partido ---\n",
        "    out = pd.DataFrame(index=odds_df.index)\n",
        "    out['B365H'] = odds_df['B365H'].round(round_decimals)\n",
        "    out['B365D'] = odds_df['B365D'].round(round_decimals)\n",
        "    out['B365A'] = odds_df['B365A'].round(round_decimals)\n",
        "    out['p_H']   = prob_norm['B365H'].round(round_decimals)\n",
        "    out['p_D']   = prob_norm['B365D'].round(round_decimals)\n",
        "    out['p_A']   = prob_norm['B365A'].round(round_decimals)\n",
        "    out['true_result'] = y_test.values\n",
        "    out['bet365_pred'] = bet365_pred\n",
        "\n",
        "    # Si tienes nombres/fecha en df o meta_df, añádelos (opcional)\n",
        "    extra_cols = []\n",
        "    for c in ['Date','HomeTeam_norm','AwayTeam_norm']:\n",
        "        if c in df.columns:\n",
        "            extra_cols.append(df.reindex(out.index)[c])\n",
        "        elif meta_df is not None and c in meta_df.columns:\n",
        "            extra_cols.append(meta_df.reindex(out.index)[c])\n",
        "        else:\n",
        "            extra_cols.append(pd.Series(index=out.index, dtype='object'))\n",
        "    out.insert(0, 'Date', pd.to_datetime(extra_cols[0], errors='coerce').dt.strftime('%Y-%m-%d'))\n",
        "    out.insert(1, 'HomeTeam_norm', extra_cols[1].astype('string'))\n",
        "    out.insert(2, 'AwayTeam_norm', extra_cols[2].astype('string'))\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"log_loss\": ll,\n",
        "        \"brier\": brier,\n",
        "        \"n_test_with_odds\": int(len(out))\n",
        "    }\n",
        "\n",
        "    print(\"Baseline Bet365 (probabilidades implícitas normalizadas)\")\n",
        "    rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    print(f\"Rango TEST: Seasons {rng}\")\n",
        "    print(f\"Partidos evaluados (con cuotas completas): {metrics['n_test_with_odds']}\")\n",
        "    print(f\"Accuracy: {acc:.3f}\")\n",
        "    print(f\"Log Loss: {ll:.3f}\")\n",
        "    print(f\"Brier:    {brier:.3f}\")\n",
        "\n",
        "    return out, metrics"
      ],
      "metadata": {
        "id": "UKiBDoUOI2va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabla_bet365, met_bet365 = evaluate_bet365_baseline(df, train_until_season=2024, test_until_season=2025, with_odds=True, meta_df=df_old)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E9eX18fI5ox",
        "outputId": "ea4779e9-db92-4102-94f4-912c7c2cc908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Bet365 (probabilidades implícitas normalizadas)\n",
            "Rango TEST: Seasons 2025..2025\n",
            "Partidos evaluados (con cuotas completas): 21\n",
            "Accuracy: 0.524\n",
            "Log Loss: 0.933\n",
            "Brier:    0.551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- usa el helper \"nuevo\" con test_until_season ---\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:  # si tu df tiene cuotas en test y quieres exigirlas aquí\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test\n",
        "\n",
        "def build_bet365_results_table(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,          # pon False si las cuotas están sólo en meta_df\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3\n",
        "):\n",
        "    \"\"\"\n",
        "    Construye la tabla 'results_bet365' para el TEST (Season ∈ (train, test]):\n",
        "\n",
        "    - Reconstruye TEST con el mismo split que usas.\n",
        "    - Toma B365H/D/A de df; si faltan, intenta meta_df (alineado por índice).\n",
        "    - Calcula probabilidades implícitas normalizadas, predicción Bet365, métricas y ROI.\n",
        "    - Devuelve (results_bet365, metrics).\n",
        "    \"\"\"\n",
        "    # 1) TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rng}).\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    idx = X_test.index\n",
        "\n",
        "    # 2) Traer cuotas B365\n",
        "    cols = ['B365H','B365D','B365A']\n",
        "    def _pull(source: pd.DataFrame | None, cols: list[str]) -> pd.DataFrame:\n",
        "        if source is None: return pd.DataFrame(index=idx)\n",
        "        have = [c for c in cols if c in source.columns]\n",
        "        if not have: return pd.DataFrame(index=idx)\n",
        "        return source.reindex(idx)[have]\n",
        "\n",
        "    odds_df  = _pull(df, cols)\n",
        "    odds_old = _pull(meta_df, cols)\n",
        "\n",
        "    for c in cols:\n",
        "        if c not in odds_df.columns: odds_df[c] = np.nan\n",
        "    for c in cols:\n",
        "        if c in odds_old.columns:\n",
        "            odds_df[c] = odds_df[c].where(odds_df[c].notna(), odds_old[c])\n",
        "\n",
        "    # Filtrar filas con cuotas completas y >0\n",
        "    mask_ok = odds_df[cols].notna().all(axis=1)\n",
        "    for c in cols:\n",
        "        mask_ok &= (pd.to_numeric(odds_df[c], errors='coerce') > 0)\n",
        "    odds_df = odds_df.loc[mask_ok].astype(float)\n",
        "    y_test  = y_test.loc[mask_ok]\n",
        "    X_test  = X_test.loc[mask_ok]\n",
        "\n",
        "    if odds_df.empty:\n",
        "        print(\"⚠️ No hay partidos con cuotas B365 completas en el TEST.\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 3) Probabilidades implícitas normalizadas\n",
        "    inv = 1.0 / odds_df[cols]\n",
        "    overround = inv.sum(axis=1).replace(0, np.nan)\n",
        "    prob_norm = inv.div(overround, axis=0)  # columnas: B365H, B365D, B365A\n",
        "\n",
        "    # Clase mapping: 0=Away, 1=Draw, 2=Home => [A,D,H]\n",
        "    bet365_proba = np.column_stack([\n",
        "        prob_norm['B365A'].to_numpy(),  # clase 0\n",
        "        prob_norm['B365D'].to_numpy(),  # clase 1\n",
        "        prob_norm['B365H'].to_numpy()   # clase 2\n",
        "    ])\n",
        "    bet365_pred = bet365_proba.argmax(axis=1)\n",
        "\n",
        "    # 4) Tabla results_bet365\n",
        "    results_bet365 = pd.DataFrame(index=odds_df.index)\n",
        "    # meta para legibilidad\n",
        "    for c in ['Date','HomeTeam_norm','AwayTeam_norm']:\n",
        "        if c in df.columns:\n",
        "            results_bet365[c] = df.reindex(results_bet365.index)[c]\n",
        "        elif meta_df is not None and c in meta_df.columns:\n",
        "            results_bet365[c] = meta_df.reindex(results_bet365.index)[c]\n",
        "\n",
        "    # formatear fecha\n",
        "    if 'Date' in results_bet365.columns:\n",
        "        results_bet365['Date'] = pd.to_datetime(results_bet365['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    # cuotas y probabilidades\n",
        "    results_bet365[['B365H','B365D','B365A']] = odds_df[cols].round(round_decimals)\n",
        "    results_bet365[['p_H','p_D','p_A']] = prob_norm[['B365H','B365D','B365A']].round(round_decimals)\n",
        "\n",
        "    # verdad y predicción\n",
        "    results_bet365['true_result'] = y_test.values\n",
        "    results_bet365['predicted_result'] = bet365_pred\n",
        "\n",
        "    # cuota asociada a la predicción (vectorizado)\n",
        "    odds_matrix = results_bet365[['B365A','B365D','B365H']].to_numpy()  # columnas en orden A,D,H\n",
        "    idx_map = results_bet365['predicted_result'].map({0:0, 1:1, 2:2}).to_numpy()\n",
        "    results_bet365['predicted_odds'] = odds_matrix[np.arange(len(results_bet365)), idx_map].round(round_decimals)\n",
        "\n",
        "    # 5) Simulación\n",
        "    results_bet365['bet_outcome'] = np.where(\n",
        "        results_bet365['predicted_result'] == results_bet365['true_result'],\n",
        "        results_bet365['predicted_odds'] * stake,\n",
        "        0.0\n",
        "    ).round(round_decimals)\n",
        "    results_bet365['net_profit'] = (results_bet365['bet_outcome'] - stake).round(round_decimals)\n",
        "\n",
        "    # 6) Métricas baseline\n",
        "    classes = [0,1,2]\n",
        "    acc = float(accuracy_score(y_test, bet365_pred))\n",
        "    ll  = float(log_loss(y_test, bet365_proba, labels=classes))\n",
        "    y_bin = label_binarize(y_test, classes=classes)\n",
        "    brier = float(np.mean(np.sum((bet365_proba - y_bin)**2, axis=1)))\n",
        "\n",
        "    total_profit = float(results_bet365['net_profit'].sum())\n",
        "    roi = total_profit / (stake * len(results_bet365)) if len(results_bet365) else np.nan\n",
        "\n",
        "    metrics = {\n",
        "        \"n_test_with_odds\": int(len(results_bet365)),\n",
        "        \"accuracy\": acc,\n",
        "        \"log_loss\": ll,\n",
        "        \"brier\": brier,\n",
        "        \"total_profit\": total_profit,\n",
        "        \"roi\": roi\n",
        "    }\n",
        "\n",
        "    print(\"Baseline Bet365 (TEST)\")\n",
        "    rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    print(f\"Rango TEST: Seasons {rng}\")\n",
        "    print(f\"Partidos: {metrics['n_test_with_odds']}\")\n",
        "    print(f\"Accuracy: {acc:.3f} | LogLoss: {ll:.3f} | Brier: {brier:.3f}\")\n",
        "    print(f\"Beneficio neto: {total_profit:.2f} | ROI: {roi*100:.2f}% (stake={stake})\")\n",
        "\n",
        "    # Ordenado opcional por fecha si existe\n",
        "    if 'Date' in results_bet365.columns:\n",
        "        results_bet365 = results_bet365.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    return results_bet365, metrics"
      ],
      "metadata": {
        "id": "YCffYKYyKA9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_bet365, met_bet365 = build_bet365_results_table(df, train_until_season=2024, test_until_season=2025, with_odds=True, meta_df=df_old, stake=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx0TTHlYKDtk",
        "outputId": "b8342827-527c-4e86-dae3-4b97a2a2d916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Bet365 (TEST)\n",
            "Rango TEST: Seasons 2025..2025\n",
            "Partidos: 21\n",
            "Accuracy: 0.524 | LogLoss: 0.933 | Brier: 0.551\n",
            "Beneficio neto: -3.17 | ROI: -15.10% (stake=1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS2LABEL = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "\n",
        "def _pull_cols_aligned(source: pd.DataFrame | None, idx, cols: list[str]) -> pd.DataFrame:\n",
        "    if source is None:\n",
        "        return pd.DataFrame(index=idx)\n",
        "    have = [c for c in cols if c in source.columns]\n",
        "    if not have:\n",
        "        return pd.DataFrame(index=idx)\n",
        "    return source.reindex(idx)[have]\n",
        "\n",
        "def plot_cumulative_profit_model_vs_bet365(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    meta_df: pd.DataFrame | None = None,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3,\n",
        "    return_table: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Traza beneficio acumulado del modelo (apuesta al resultado predicho) vs baseline Bet365\n",
        "    para el TEST: Season ∈ (train_until_season, test_until_season] (si se indica).\n",
        "    - Usa cuotas B365 de df y/o meta_df.\n",
        "    - Ordena por Date si está disponible (si no, por índice).\n",
        "    - Devuelve la tabla usada si return_table=True.\n",
        "    \"\"\"\n",
        "    # 1) Reconstruir TEST\n",
        "    X_test, y_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        r = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {r}).\")\n",
        "        return pd.DataFrame() if return_table else None\n",
        "\n",
        "    # 2) Alinear features a las del fit y predecir con el modelo\n",
        "    X_test = _align_to_fit_columns(X_test, scaler)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred_model = model.predict(X_test_scaled)          # clases (0=A,1=D,2=H)\n",
        "\n",
        "    # 3) Traer cuotas y metadatos (Date, equipos)\n",
        "    idx = X_test.index\n",
        "    want_odds = ['B365H','B365D','B365A']\n",
        "    odds_df  = _pull_cols_aligned(df,      idx, want_odds)\n",
        "    odds_old = _pull_cols_aligned(meta_df, idx, want_odds)\n",
        "\n",
        "    for c in want_odds:\n",
        "        if c not in odds_df.columns: odds_df[c] = np.nan\n",
        "    for c in want_odds:\n",
        "        if c in odds_old.columns:\n",
        "            odds_df[c] = odds_df[c].where(odds_df[c].notna(), odds_old[c])\n",
        "\n",
        "    # exigir cuotas completas y > 0\n",
        "    mask_ok = odds_df[want_odds].notna().all(axis=1)\n",
        "    for c in want_odds:\n",
        "        mask_ok &= (pd.to_numeric(odds_df[c], errors='coerce') > 0)\n",
        "    if not mask_ok.any():\n",
        "        print(\"⚠️ No hay partidos con cuotas Bet365 completas en el TEST.\")\n",
        "        return pd.DataFrame() if return_table else None\n",
        "\n",
        "    # Reducir todo a las filas válidas\n",
        "    odds_df = odds_df.loc[mask_ok].astype(float)\n",
        "    y_test  = y_test.loc[mask_ok]\n",
        "    y_pred_model = pd.Series(y_pred_model, index=X_test.index).loc[mask_ok].to_numpy()\n",
        "    X_test = X_test.loc[mask_ok]\n",
        "\n",
        "    # Meta: Date y nombres si existen (df -> meta_df)\n",
        "    meta_cols = {}\n",
        "    for c in ['Date','HomeTeam_norm','AwayTeam_norm']:\n",
        "        s = None\n",
        "        if c in df.columns:\n",
        "            s = df.reindex(odds_df.index)[c]\n",
        "        elif meta_df is not None and c in meta_df.columns:\n",
        "            s = meta_df.reindex(odds_df.index)[c]\n",
        "        if s is None:\n",
        "            meta_cols[c] = pd.Series(index=odds_df.index, dtype='object')\n",
        "        else:\n",
        "            meta_cols[c] = s\n",
        "\n",
        "    # 4) Predicción del baseline Bet365 (escoge la cuota más baja => mayor prob. implícita)\n",
        "    #    También calculamos probabilidades implícitas normalizadas por si quieres guardarlas\n",
        "    inv = 1.0 / odds_df[want_odds]\n",
        "    overround = inv.sum(axis=1).replace(0, np.nan)\n",
        "    prob_norm = inv.div(overround, axis=0)  # columnas: B365H/D/A\n",
        "\n",
        "    # Orden de clases (0=Away,1=Draw,2=Home) ⇒ columnas [A, D, H]\n",
        "    bet365_proba = np.column_stack([\n",
        "        prob_norm['B365A'].to_numpy(),\n",
        "        prob_norm['B365D'].to_numpy(),\n",
        "        prob_norm['B365H'].to_numpy()\n",
        "    ])\n",
        "    bet365_pred = bet365_proba.argmax(axis=1)\n",
        "\n",
        "    # 5) Tabla base\n",
        "    tbl = pd.DataFrame(index=odds_df.index)\n",
        "    tbl['Date'] = pd.to_datetime(meta_cols['Date'], errors='coerce')\n",
        "    tbl['HomeTeam_norm'] = meta_cols['HomeTeam_norm'].astype('string')\n",
        "    tbl['AwayTeam_norm'] = meta_cols['AwayTeam_norm'].astype('string')\n",
        "    tbl['true_result']   = y_test.values\n",
        "    tbl['model_pred']    = y_pred_model\n",
        "    tbl['bet365_pred']   = bet365_pred\n",
        "\n",
        "    # 6) Retornos por partido (stake=1 por defecto)\n",
        "    # Modelo: si acierta, retorna la cuota del mercado predicho; si falla, -1\n",
        "    odds_matrix = odds_df[['B365A','B365D','B365H']].to_numpy()   # A,D,H\n",
        "    idx_model = tbl['model_pred'].map({0:0,1:1,2:2}).to_numpy()\n",
        "    chosen_odds_model = odds_matrix[np.arange(len(tbl)), idx_model]\n",
        "\n",
        "    tbl['model_return'] = np.where(\n",
        "        tbl['model_pred'] == tbl['true_result'],\n",
        "        chosen_odds_model - 1.0,  # neto con stake=1\n",
        "        -1.0\n",
        "    ).round(round_decimals)\n",
        "\n",
        "    # Bet365 baseline: igual mecánica\n",
        "    idx_b365 = tbl['bet365_pred'].map({0:0,1:1,2:2}).to_numpy()\n",
        "    chosen_odds_b365 = odds_matrix[np.arange(len(tbl)), idx_b365]\n",
        "    tbl['bet365_return'] = np.where(\n",
        "        tbl['bet365_pred'] == tbl['true_result'],\n",
        "        chosen_odds_b365 - 1.0,\n",
        "        -1.0\n",
        "    ).round(round_decimals)\n",
        "\n",
        "    # 7) Orden cronológico y acumulados\n",
        "    if tbl['Date'].notna().any():\n",
        "        tbl = tbl.sort_values('Date').reset_index(drop=True)\n",
        "        # formatear fecha al final para legibilidad\n",
        "        tbl['Date'] = tbl['Date'].dt.strftime('%Y-%m-%d')\n",
        "    else:\n",
        "        tbl = tbl.reset_index(drop=True)\n",
        "\n",
        "    tbl['model_cumsum']  = tbl['model_return'].cumsum().round(round_decimals)\n",
        "    tbl['bet365_cumsum'] = tbl['bet365_return'].cumsum().round(round_decimals)\n",
        "\n",
        "    # 8) Métricas rápidas por si quieres imprimir\n",
        "    acc_model  = float(accuracy_score(tbl['true_result'], tbl['model_pred']))\n",
        "    acc_b365   = float(accuracy_score(tbl['true_result'], tbl['bet365_pred']))\n",
        "    print(f\"Accuracy modelo: {acc_model:.3f} | Accuracy Bet365: {acc_b365:.3f}\")\n",
        "    print(f\"Total modelo: {tbl['model_cumsum'].iloc[-1]:.2f} | Total Bet365: {tbl['bet365_cumsum'].iloc[-1]:.2f}\")\n",
        "\n",
        "    # 9) Plot acumulados\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(tbl['model_cumsum'], label='Modelo', linewidth=2)\n",
        "    plt.plot(tbl['bet365_cumsum'], label='Bet365 (benchmark)', linewidth=2)\n",
        "    plt.axhline(0, linestyle='--', linewidth=1)\n",
        "    r = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    plt.title(f\"Evolución del beneficio acumulado (Seasons {r})\")\n",
        "    plt.xlabel(\"Número de partidos\")\n",
        "    plt.ylabel(\"Beneficio acumulado (unidades)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return tbl if return_table else None"
      ],
      "metadata": {
        "id": "iiIX0UrtLona"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tabla = plot_cumulative_profit_model_vs_bet365(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True, meta_df=df_old, stake=1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "QHo-O9E2Lrtr",
        "outputId": "fa41441e-e202-4188-a3d2-b88a71907eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy modelo: 0.582 | Accuracy Bet365: 0.545\n",
            "Total modelo: 40.23 | Total Bet365: -6.84\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp0H3HmVus9U"
      },
      "source": [
        "# **Modelos por fase de la temporada**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "pfJHwLI6zLIf",
        "outputId": "622b6508-4ffa-4492-b591-b5da2b3e54c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dc1a4eff-9e8f-41c2-ad1e-abe5a0732118\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>FTR</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>h_elo</th>\n",
              "      <th>a_elo</th>\n",
              "      <th>Season</th>\n",
              "      <th>h_avg_age</th>\n",
              "      <th>h_value_mio</th>\n",
              "      <th>...</th>\n",
              "      <th>pimp1</th>\n",
              "      <th>pimpx</th>\n",
              "      <th>pimp2</th>\n",
              "      <th>fase_temporada</th>\n",
              "      <th>has_xg_data</th>\n",
              "      <th>target</th>\n",
              "      <th>home_playstyle_equilibrado</th>\n",
              "      <th>home_playstyle_ofensivo</th>\n",
              "      <th>away_playstyle_equilibrado</th>\n",
              "      <th>away_playstyle_ofensivo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>2006-08-26</td>\n",
              "      <td>H</td>\n",
              "      <td>1.57</td>\n",
              "      <td>3.60</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1857.375122</td>\n",
              "      <td>1726.076904</td>\n",
              "      <td>2006</td>\n",
              "      <td>26.5</td>\n",
              "      <td>232.70</td>\n",
              "      <td>...</td>\n",
              "      <td>0.589005</td>\n",
              "      <td>0.256872</td>\n",
              "      <td>0.154123</td>\n",
              "      <td>inicio</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>D</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1701.504761</td>\n",
              "      <td>1723.469849</td>\n",
              "      <td>2006</td>\n",
              "      <td>27.1</td>\n",
              "      <td>41.90</td>\n",
              "      <td>...</td>\n",
              "      <td>0.404145</td>\n",
              "      <td>0.286010</td>\n",
              "      <td>0.309845</td>\n",
              "      <td>inicio</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>D</td>\n",
              "      <td>1.53</td>\n",
              "      <td>3.80</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1883.077393</td>\n",
              "      <td>1829.429443</td>\n",
              "      <td>2006</td>\n",
              "      <td>25.3</td>\n",
              "      <td>372.20</td>\n",
              "      <td>...</td>\n",
              "      <td>0.603270</td>\n",
              "      <td>0.242896</td>\n",
              "      <td>0.153834</td>\n",
              "      <td>inicio</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>A</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1693.620361</td>\n",
              "      <td>1769.739990</td>\n",
              "      <td>2006</td>\n",
              "      <td>25.9</td>\n",
              "      <td>49.30</td>\n",
              "      <td>...</td>\n",
              "      <td>0.298817</td>\n",
              "      <td>0.289479</td>\n",
              "      <td>0.411704</td>\n",
              "      <td>inicio</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>A</td>\n",
              "      <td>1.83</td>\n",
              "      <td>3.30</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1756.190308</td>\n",
              "      <td>1762.177246</td>\n",
              "      <td>2006</td>\n",
              "      <td>25.2</td>\n",
              "      <td>71.35</td>\n",
              "      <td>...</td>\n",
              "      <td>0.505771</td>\n",
              "      <td>0.280473</td>\n",
              "      <td>0.213756</td>\n",
              "      <td>inicio</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 71 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc1a4eff-9e8f-41c2-ad1e-abe5a0732118')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc1a4eff-9e8f-41c2-ad1e-abe5a0732118 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc1a4eff-9e8f-41c2-ad1e-abe5a0732118');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b91a5dac-9b4b-4901-9c32-4fce36e82849\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b91a5dac-9b4b-4901-9c32-4fce36e82849')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b91a5dac-9b4b-4901-9c32-4fce36e82849 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Date FTR  B365H  B365D  B365A        h_elo        a_elo  Season  \\\n",
              "380  2006-08-26   H   1.57   3.60   6.00  1857.375122  1726.076904    2006   \n",
              "381  2006-08-27   D   2.30   3.25   3.00  1701.504761  1723.469849    2006   \n",
              "382  2006-08-27   D   1.53   3.80   6.00  1883.077393  1829.429443    2006   \n",
              "383  2006-08-27   A   3.10   3.20   2.25  1693.620361  1769.739990    2006   \n",
              "384  2006-08-27   A   1.83   3.30   4.33  1756.190308  1762.177246    2006   \n",
              "\n",
              "     h_avg_age  h_value_mio  ...     pimp1     pimpx     pimp2  \\\n",
              "380       26.5       232.70  ...  0.589005  0.256872  0.154123   \n",
              "381       27.1        41.90  ...  0.404145  0.286010  0.309845   \n",
              "382       25.3       372.20  ...  0.603270  0.242896  0.153834   \n",
              "383       25.9        49.30  ...  0.298817  0.289479  0.411704   \n",
              "384       25.2        71.35  ...  0.505771  0.280473  0.213756   \n",
              "\n",
              "     fase_temporada  has_xg_data  target  home_playstyle_equilibrado  \\\n",
              "380          inicio            0       2                           1   \n",
              "381          inicio            0       1                           1   \n",
              "382          inicio            0       1                           1   \n",
              "383          inicio            0       0                           1   \n",
              "384          inicio            0       0                           1   \n",
              "\n",
              "     home_playstyle_ofensivo  away_playstyle_equilibrado  \\\n",
              "380                        0                           1   \n",
              "381                        0                           1   \n",
              "382                        0                           1   \n",
              "383                        0                           1   \n",
              "384                        0                           1   \n",
              "\n",
              "     away_playstyle_ofensivo  \n",
              "380                        0  \n",
              "381                        0  \n",
              "382                        0  \n",
              "383                        0  \n",
              "384                        0  \n",
              "\n",
              "[5 rows x 71 columns]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/TFM/data/processed/df_final.parquet'\n",
        "\n",
        "df = pd.read_parquet(file_path)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpTI1gP6z03D"
      },
      "source": [
        "## Modelo INICIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJrWM6AWw12f"
      },
      "outputs": [],
      "source": [
        "df_inicio = df[df['fase_temporada'] == 'inicio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWjefllP0CyB"
      },
      "outputs": [],
      "source": [
        "drop_cols = ['fase_temporada', 'FTR', 'target', 'Date','has_xg_data', 'overround', 'pimp1', 'a_pct_foreigners']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OWKEKBQ0DVr"
      },
      "outputs": [],
      "source": [
        "X_inicio = df_inicio.drop(columns=drop_cols)\n",
        "y_inicio = df_inicio['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRsw91fc0M5D"
      },
      "outputs": [],
      "source": [
        "X_train_inicio = X_inicio[df_inicio['Season'] <= 2023]\n",
        "y_train_inicio = y_inicio[df_inicio['Season'] <= 2023]\n",
        "\n",
        "X_test_inicio = X_inicio[df_inicio['Season'] > 2023]\n",
        "y_test_inicio = y_inicio[df_inicio['Season'] > 2023]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRw-9XJQ0M0w"
      },
      "outputs": [],
      "source": [
        "X_train_inicio = X_train_inicio.drop(columns=['Season'])\n",
        "X_test_inicio = X_test_inicio.drop(columns=['Season'])\n",
        "\n",
        "y_train_inicio = y_train_inicio.drop(columns=['Season'])\n",
        "y_test_inicio = y_test_inicio.drop(columns=['Season'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sePeQXZ0Mir",
        "outputId": "fda03b8a-9ed3-4c8f-9674-33b637674d2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2378"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train_inicio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeW_XRAa0tNn",
        "outputId": "77b84f5a-0319-4e83-ccd3-d9c94cb6395f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "137"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_test_inicio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq6rocyZ0wMv",
        "outputId": "1e6642b9-8f19-4924-9f8b-e294c5adaa03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression multinomial (INICIO):\n",
            "\n",
            "=== Train ===\n",
            "Accuracy: 0.5592935239697224\n",
            "Log Loss: 0.9367516269785796\n",
            "\n",
            "=== Test ===\n",
            "Accuracy: 0.5328467153284672\n",
            "Log Loss: 0.9592955079897749\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "# Pipeline con escalado + regresión logística\n",
        "model_inicio = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_inicio.fit(X_train_inicio, y_train_inicio)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred_inicio = model_inicio.predict(X_train_inicio)\n",
        "y_train_proba_inicio = model_inicio.predict_proba(X_train_inicio)\n",
        "y_test_pred_inicio = model_inicio.predict(X_test_inicio)\n",
        "y_test_proba_inicio = model_inicio.predict_proba(X_test_inicio)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Logistic Regression multinomial (INICIO):\")\n",
        "\n",
        "print(\"\\n=== Train ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train_inicio, y_train_pred_inicio))\n",
        "print(\"Log Loss:\", log_loss(y_train_inicio, y_train_proba_inicio))\n",
        "\n",
        "print(\"\\n=== Test ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_inicio, y_test_pred_inicio))\n",
        "print(\"Log Loss:\", log_loss(y_test_inicio, y_test_proba_inicio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS5VREQp1NKM",
        "outputId": "14decfd8-303c-4d4c-ee3a-c92fd0ddc8c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy cuotas (fase inicio): 0.5339960238568588\n",
            "Log Loss cuotas (fase inicio): 0.9689888955708615\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Variables de entrada y objetivo\n",
        "X_bet = df_inicio[['B365H', 'B365D', 'B365A']]\n",
        "y_bet = df_inicio['FTR'].map({'A': 0, 'D': 1, 'H': 2})\n",
        "y_bet_bin = label_binarize(y_bet, classes=[0, 1, 2])\n",
        "\n",
        "# Calcular probabilidades implícitas sin margen\n",
        "prob_h = 1 / X_bet['B365H']\n",
        "prob_d = 1 / X_bet['B365D']\n",
        "prob_a = 1 / X_bet['B365A']\n",
        "\n",
        "overround = prob_h + prob_d + prob_a\n",
        "prob_h /= overround\n",
        "prob_d /= overround\n",
        "prob_a /= overround\n",
        "\n",
        "# Predicción basada en la mayor probabilidad\n",
        "bet365_pred = np.array([\n",
        "    np.argmax([a, d, h])  # 0 = Away, 1 = Draw, 2 = Home\n",
        "    for a, d, h in zip(prob_a, prob_d, prob_h)\n",
        "])\n",
        "\n",
        "# Matriz de probabilidades para log loss\n",
        "bet365_proba = np.column_stack([prob_a, prob_d, prob_h])\n",
        "\n",
        "# Evaluación\n",
        "acc_inicio = accuracy_score(y_bet, bet365_pred)\n",
        "logloss_inicio = log_loss(y_bet_bin, bet365_proba)\n",
        "\n",
        "print(\"Accuracy cuotas (fase inicio):\", acc_inicio)\n",
        "print(\"Log Loss cuotas (fase inicio):\", logloss_inicio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoH2Hx_s2EqC"
      },
      "source": [
        "## Modelo MITAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDGKOASs2u3q",
        "outputId": "6ab33100-b984-49e7-a85e-59c8a02fe7ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression multinomial (MITAD):\n",
            "\n",
            "=== Train ===\n",
            "Accuracy: 0.5556989247311828\n",
            "Log Loss: 0.93106415341006\n",
            "\n",
            "=== Test ===\n",
            "Accuracy: 0.5\n",
            "Log Loss: 1.0832087367408858\n"
          ]
        }
      ],
      "source": [
        "df_mitad = df[df['fase_temporada'] == 'mitad']\n",
        "\n",
        "drop_cols = ['fase_temporada', 'FTR', 'target', 'Date','has_xg_data', 'overround', 'pimp1', 'a_pct_foreigners']\n",
        "\n",
        "X_mitad = df_mitad.drop(columns=drop_cols)\n",
        "y_mitad = df_mitad['target']\n",
        "\n",
        "X_train_mitad = X_mitad[df_mitad['Season'] <= 2023]\n",
        "y_train_mitad = y_mitad[df_mitad['Season'] <= 2023]\n",
        "\n",
        "X_test_mitad = X_mitad[df_mitad['Season'] > 2023]\n",
        "y_test_mitad = y_mitad[df_mitad['Season'] > 2023]\n",
        "\n",
        "X_train_mitad = X_train_mitad.drop(columns=['Season'])\n",
        "X_test_mitad = X_test_mitad.drop(columns=['Season'])\n",
        "\n",
        "y_train_mitad = y_train_mitad.drop(columns=['Season'])\n",
        "y_test_mitad = y_test_mitad.drop(columns=['Season'])\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "# Pipeline con escalado + regresión logística\n",
        "model_mitad = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_mitad.fit(X_train_mitad, y_train_mitad)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred_mitad = model_mitad.predict(X_train_mitad)\n",
        "y_train_proba_mitad = model_mitad.predict_proba(X_train_mitad)\n",
        "y_test_pred_mitad = model_mitad.predict(X_test_mitad)\n",
        "y_test_proba_mitad = model_mitad.predict_proba(X_test_mitad)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Logistic Regression multinomial (MITAD):\")\n",
        "\n",
        "print(\"\\n=== Train ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train_mitad, y_train_pred_mitad))\n",
        "print(\"Log Loss:\", log_loss(y_train_mitad, y_train_proba_mitad))\n",
        "\n",
        "print(\"\\n=== Test ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_mitad, y_test_pred_mitad))\n",
        "print(\"Log Loss:\", log_loss(y_test_mitad, y_test_proba_mitad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdAgwxvK27A-",
        "outputId": "7573bd08-3a21-468f-b6a0-68ba367e1770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy cuotas (fase mitad): 0.5369237046103631\n",
            "Log Loss cuotas (fase mitad): 0.9664413990317429\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Variables de entrada y objetivo\n",
        "X_bet = df_mitad[['B365H', 'B365D', 'B365A']]\n",
        "y_bet = df_mitad['FTR'].map({'A': 0, 'D': 1, 'H': 2})\n",
        "y_bet_bin = label_binarize(y_bet, classes=[0, 1, 2])\n",
        "\n",
        "# Calcular probabilidades implícitas sin margen\n",
        "prob_h = 1 / X_bet['B365H']\n",
        "prob_d = 1 / X_bet['B365D']\n",
        "prob_a = 1 / X_bet['B365A']\n",
        "\n",
        "overround = prob_h + prob_d + prob_a\n",
        "prob_h /= overround\n",
        "prob_d /= overround\n",
        "prob_a /= overround\n",
        "\n",
        "# Predicción basada en la mayor probabilidad\n",
        "bet365_pred = np.array([\n",
        "    np.argmax([a, d, h])  # 0 = Away, 1 = Draw, 2 = Home\n",
        "    for a, d, h in zip(prob_a, prob_d, prob_h)\n",
        "])\n",
        "\n",
        "# Matriz de probabilidades para log loss\n",
        "bet365_proba = np.column_stack([prob_a, prob_d, prob_h])\n",
        "\n",
        "# Evaluación\n",
        "acc_mitad = accuracy_score(y_bet, bet365_pred)\n",
        "logloss_mitad = log_loss(y_bet_bin, bet365_proba)\n",
        "\n",
        "print(\"Accuracy cuotas (fase mitad):\", acc_mitad)\n",
        "print(\"Log Loss cuotas (fase mitad):\", logloss_mitad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3OYzHaq3CeB"
      },
      "source": [
        "## Modelo FINAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUAnQqYo3Lu4",
        "outputId": "94e32ab6-1c4e-4e8c-d4b7-754ede09e478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression multinomial:\n",
            "\n",
            "=== Train ===\n",
            "Accuracy: 0.5694899391670566\n",
            "Log Loss: 0.9104440710091384\n",
            "\n",
            "=== Test ===\n",
            "Accuracy: 0.5042735042735043\n",
            "Log Loss: 0.9755798208990906\n"
          ]
        }
      ],
      "source": [
        "df_final = df[df['fase_temporada'] == 'final']\n",
        "\n",
        "drop_cols = ['fase_temporada', 'FTR', 'target', 'Date','has_xg_data', 'overround', 'pimp1', 'a_pct_foreigners']\n",
        "\n",
        "X_final = df_final.drop(columns=drop_cols)\n",
        "y_final = df_final['target']\n",
        "\n",
        "X_train_final = X_final[df_final['Season'] <= 2023]\n",
        "y_train_final = y_final[df_final['Season'] <= 2023]\n",
        "\n",
        "X_test_final = X_final[df_final['Season'] > 2023]\n",
        "y_test_final = y_final[df_final['Season'] > 2023]\n",
        "\n",
        "X_train_final = X_train_final.drop(columns=['Season'])\n",
        "X_test_final = X_test_final.drop(columns=['Season'])\n",
        "\n",
        "y_train_final = y_train_final.drop(columns=['Season'])\n",
        "y_test_final = y_test_final.drop(columns=['Season'])\n",
        "\n",
        "len(X_train_final)\n",
        "\n",
        "len(X_test_final)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "# Pipeline con escalado + regresión logística\n",
        "model_final = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "model_final.fit(X_train_final, y_train_final)\n",
        "\n",
        "# Predicciones\n",
        "y_train_pred_final = model_final.predict(X_train_final)\n",
        "y_train_proba_final = model_final.predict_proba(X_train_final)\n",
        "y_test_pred_final = model_final.predict(X_test_final)\n",
        "y_test_proba_final = model_final.predict_proba(X_test_final)\n",
        "\n",
        "# Evaluación\n",
        "print(\"Logistic Regression multinomial:\")\n",
        "\n",
        "print(\"\\n=== Train ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train_final, y_train_pred_final))\n",
        "print(\"Log Loss:\", log_loss(y_train_final, y_train_proba_final))\n",
        "\n",
        "print(\"\\n=== Test ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test_final, y_test_pred_final))\n",
        "print(\"Log Loss:\", log_loss(y_test_final, y_test_proba_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM-spiql3RiC",
        "outputId": "52e49ead-b986-45ed-bbf6-00bc31e9f616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy cuotas (fase final): 0.5607808340727596\n",
            "Log Loss cuotas (fase final): 0.9427790451312839\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Variables de entrada y objetivo\n",
        "X_bet = df_final[['B365H', 'B365D', 'B365A']]\n",
        "y_bet = df_final['FTR'].map({'A': 0, 'D': 1, 'H': 2})\n",
        "y_bet_bin = label_binarize(y_bet, classes=[0, 1, 2])\n",
        "\n",
        "# Calcular probabilidades implícitas sin margen\n",
        "prob_h = 1 / X_bet['B365H']\n",
        "prob_d = 1 / X_bet['B365D']\n",
        "prob_a = 1 / X_bet['B365A']\n",
        "\n",
        "overround = prob_h + prob_d + prob_a\n",
        "prob_h /= overround\n",
        "prob_d /= overround\n",
        "prob_a /= overround\n",
        "\n",
        "# Predicción basada en la mayor probabilidad\n",
        "bet365_pred = np.array([\n",
        "    np.argmax([a, d, h])  # 0 = Away, 1 = Draw, 2 = Home\n",
        "    for a, d, h in zip(prob_a, prob_d, prob_h)\n",
        "])\n",
        "\n",
        "# Matriz de probabilidades para log loss\n",
        "bet365_proba = np.column_stack([prob_a, prob_d, prob_h])\n",
        "\n",
        "# Evaluación\n",
        "acc_final = accuracy_score(y_bet, bet365_pred)\n",
        "logloss_final = log_loss(y_bet_bin, bet365_proba)\n",
        "\n",
        "print(\"Accuracy cuotas (fase final):\", acc_final)\n",
        "print(\"Log Loss cuotas (fase final):\", logloss_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsJYUqvoPlpq",
        "outputId": "2420ba55-363f-415b-fcc8-bd8820cc3e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/MODELOS.ipynb to html\n",
            "[NbConvertApp] WARNING | Alternative text is missing on 8 image(s).\n",
            "[NbConvertApp] Writing 1267860 bytes to /content/MODELOS.html\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to html /content/MODELOS.ipynb"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ny_spsZP25IM",
        "u-LZWUpHKgiI",
        "_AUraRaeqPH_",
        "LKjn9DwWtgyl",
        "DmmpBR0ity_a",
        "pp0H3HmVus9U",
        "tpTI1gP6z03D",
        "CoH2Hx_s2EqC",
        "F3OYzHaq3CeB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}