{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EzFV5f4-L4Ox",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0faef45f-bbcc-4a96-9186-9ecafa012f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN_DATE = 2025-09-27 | SEASON = 2025_26 | MATCHDAY = None | MODEL_VERSION = xgb-local\n",
            "ROOT = /content\n"
          ]
        }
      ],
      "source": [
        "# --- Parámetros (se pueden sobreescribir en CI) ---\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import os\n",
        "import pandas as pd\n",
        "import pytz\n",
        "\n",
        "# Zona horaria para \"hoy\"\n",
        "TZ = pytz.timezone(\"Europe/Madrid\")\n",
        "\n",
        "def _today_tz(tz=TZ) -> str:\n",
        "    return datetime.now(tz).date().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# RUN_DATE: prioridad -> valor ya definido (papermill/globals) -> env -> hoy (Europe/Madrid)\n",
        "_run_injected = globals().get(\"RUN_DATE\", None)\n",
        "if _run_injected not in (None, \"\", \"auto\", \"today\"):\n",
        "    RUN_DATE = str(_run_injected)\n",
        "else:\n",
        "    RUN_DATE = os.environ.get(\"RUN_DATE\", _today_tz())\n",
        "\n",
        "# Normaliza a YYYY-MM-DD\n",
        "RUN_DATE = pd.to_datetime(RUN_DATE, errors=\"coerce\").date().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# SEASON: si no viene dada, se calcula a partir de RUN_DATE (formato 2025_26)\n",
        "if \"SEASON\" in globals() and globals()[\"SEASON\"]:\n",
        "    SEASON = globals()[\"SEASON\"]\n",
        "else:\n",
        "    _dt = pd.to_datetime(RUN_DATE)\n",
        "    _y = int(_dt.year) if _dt.month >= 7 else int(_dt.year) - 1\n",
        "    SEASON = f\"{_y}_{(_y+1) % 100:02d}\"\n",
        "\n",
        "# MATCHDAY (jornada): permite inyección externa; por defecto None\n",
        "MATCHDAY = globals().get(\"MATCHDAY\", os.environ.get(\"MATCHDAY\", None))\n",
        "\n",
        "# Versión de modelo: respeta inyección / env, si no usa por defecto\n",
        "MODEL_VERSION = globals().get(\"MODEL_VERSION\", os.environ.get(\"MODEL_VERSION\", \"xgb-local\"))\n",
        "\n",
        "# --- Rutas coherentes local/CI ---\n",
        "ROOT   = Path.cwd()\n",
        "DATA   = ROOT / \"data\"\n",
        "RAW    = DATA / \"01_raw\"\n",
        "PROC   = DATA / \"02_processed\"\n",
        "FEAT   = DATA / \"03_features\"\n",
        "MODELS = DATA / \"04_models\"\n",
        "OUT    = ROOT / \"outputs\"\n",
        "\n",
        "for p in [RAW, PROC, FEAT, MODELS, OUT]:\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Reproducibilidad\n",
        "import random, numpy as np\n",
        "random.seed(42); np.random.seed(42)\n",
        "\n",
        "print(f\"RUN_DATE = {RUN_DATE} | SEASON = {SEASON} | MATCHDAY = {MATCHDAY} | MODEL_VERSION = {MODEL_VERSION}\")\n",
        "print(f\"ROOT = {ROOT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZs2bMOYL7I7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, json\n",
        "\n",
        "def load_feat(name: str):\n",
        "    return pd.read_parquet(FEAT / name)\n",
        "\n",
        "def save_model(obj, name: str):\n",
        "    from joblib import dump\n",
        "    MODELS.mkdir(parents=True, exist_ok=True)\n",
        "    dump(obj, MODELS / name)\n",
        "\n",
        "def save_predictions(df: pd.DataFrame, name: str = \"predictions_next.csv\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(OUT / name, index=False)\n",
        "\n",
        "def save_json(obj, name: str = \"metrics_overview.json\"):\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "    with open(OUT / name, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(obj, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny_spsZP25IM"
      },
      "source": [
        "# **MODELOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v6i6bPn0tuc4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-LZWUpHKgiI"
      },
      "source": [
        "# **PREDICCIÓN: Logistic Regression multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "oqodyksQuVIn",
        "outputId": "e755956e-3a6a-4ca2-c078-c592f84eff0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leído: /content/data/03_features/df_final.parquet · filas= 7290 · cols= 76\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   B365A  B365D  B365H        Date FTR HomeTeam_norm AwayTeam_norm  \\\n",
              "0   6.00    3.6   1.57  2006-08-26   H      valencia         betis   \n",
              "1   3.75    3.2   2.00  2006-08-27   D    ath bilbao      sociedad   \n",
              "\n",
              "         h_elo        a_elo  Season  ...  a_squad_size_prev_season  \\\n",
              "0  1857.375122  1726.076904    2006  ...                      33.0   \n",
              "1  1755.359253  1701.137573    2006  ...                      31.0   \n",
              "\n",
              "   a_pct_foreigners_prev_season  has_xg_data  target  \\\n",
              "0                         24.24            0     2.0   \n",
              "1                         22.58            0     1.0   \n",
              "\n",
              "   home_playstyle_defensivo  home_playstyle_equilibrado  \\\n",
              "0                     False                       False   \n",
              "1                     False                        True   \n",
              "\n",
              "   home_playstyle_ofensivo  away_playstyle_defensivo  \\\n",
              "0                     True                      True   \n",
              "1                    False                     False   \n",
              "\n",
              "   away_playstyle_equilibrado  away_playstyle_ofensivo  \n",
              "0                       False                    False  \n",
              "1                        True                    False  \n",
              "\n",
              "[2 rows x 76 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ee7c022-84ea-4dc2-a898-5fdf3cee2793\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B365A</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365H</th>\n",
              "      <th>Date</th>\n",
              "      <th>FTR</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>h_elo</th>\n",
              "      <th>a_elo</th>\n",
              "      <th>Season</th>\n",
              "      <th>...</th>\n",
              "      <th>a_squad_size_prev_season</th>\n",
              "      <th>a_pct_foreigners_prev_season</th>\n",
              "      <th>has_xg_data</th>\n",
              "      <th>target</th>\n",
              "      <th>home_playstyle_defensivo</th>\n",
              "      <th>home_playstyle_equilibrado</th>\n",
              "      <th>home_playstyle_ofensivo</th>\n",
              "      <th>away_playstyle_defensivo</th>\n",
              "      <th>away_playstyle_equilibrado</th>\n",
              "      <th>away_playstyle_ofensivo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.00</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2006-08-26</td>\n",
              "      <td>H</td>\n",
              "      <td>valencia</td>\n",
              "      <td>betis</td>\n",
              "      <td>1857.375122</td>\n",
              "      <td>1726.076904</td>\n",
              "      <td>2006</td>\n",
              "      <td>...</td>\n",
              "      <td>33.0</td>\n",
              "      <td>24.24</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.75</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2006-08-27</td>\n",
              "      <td>D</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1755.359253</td>\n",
              "      <td>1701.137573</td>\n",
              "      <td>2006</td>\n",
              "      <td>...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>22.58</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 76 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ee7c022-84ea-4dc2-a898-5fdf3cee2793')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ee7c022-84ea-4dc2-a898-5fdf3cee2793 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ee7c022-84ea-4dc2-a898-5fdf3cee2793');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e2888312-0e80-44b3-a6fb-1d4a41c3eded\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2888312-0e80-44b3-a6fb-1d4a41c3eded')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e2888312-0e80-44b3-a6fb-1d4a41c3eded button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)\n",
        "\n",
        "print(\"Leído:\", IN_PATH, \"· filas=\", len(df), \"· cols=\", df.shape[1])\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9p6IXV2flpz"
      },
      "source": [
        "Sin SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (BASELINE, sin SMOTE) + B365 + export (sin df_old)\n",
        "# =========================\n",
        "\n",
        "# --- Detectar automáticamente la próxima jornada COMPLETA (10) ---\n",
        "def _season_from_run_date(run_date_str: str) -> int:\n",
        "    d = pd.to_datetime(run_date_str)\n",
        "    return int(d.year) if d.month >= 7 else int(d.year) - 1\n",
        "\n",
        "# df_final ya cargado como df\n",
        "_df_dates = df.copy()\n",
        "_df_dates[\"Date\"] = pd.to_datetime(_df_dates[\"Date\"]).dt.date\n",
        "\n",
        "season_auto = _season_from_run_date(RUN_DATE)\n",
        "today_d = pd.to_datetime(RUN_DATE).date()\n",
        "\n",
        "# 1) Intento con lo que ya hay en df (sin filtrar por fecha para no perder el viernes)\n",
        "grp_all = (_df_dates[_df_dates[\"Season\"] == season_auto]\n",
        "           .groupby(\"Wk\")\n",
        "           .agg(n=(\"Wk\",\"size\"), dmin=(\"Date\",\"min\"), dmax=(\"Date\",\"max\"))\n",
        "           .reset_index()\n",
        "           .sort_values([\"dmin\",\"Wk\"]))\n",
        "\n",
        "wk_next = None; start_date = None; end_date = None\n",
        "if not grp_all.empty:\n",
        "    cand = grp_all[(grp_all[\"n\"] >= 10) & (grp_all[\"dmax\"] >= today_d)]\n",
        "    if len(cand):\n",
        "        row = cand.iloc[0]\n",
        "        wk_next = int(row[\"Wk\"])\n",
        "        start_date = row[\"dmin\"]; end_date = row[\"dmax\"]\n",
        "\n",
        "# 2) Fallback: parquet de jornadas si aún no está completo en df\n",
        "if wk_next is None:\n",
        "    PROC = Path(PROC) if \"PROC\" in globals() else Path(\"./data/02_processed\")\n",
        "    for wk_path in [PROC/\"wk_actualizado_2005_2025.parquet\", PROC/\"wk_2005_2025.parquet\"]:\n",
        "        if wk_path.exists():\n",
        "            wk = pd.read_parquet(wk_path)\n",
        "            wk = wk[wk[\"Season\"] == season_auto].copy()\n",
        "            wk[\"Date\"] = pd.to_datetime(wk[\"Date\"], errors=\"coerce\").dt.date\n",
        "            g = (wk.groupby(\"Wk\")\n",
        "                   .agg(n=(\"Wk\",\"size\"), dmin=(\"Date\",\"min\"), dmax=(\"Date\",\"max\"))\n",
        "                   .reset_index()\n",
        "                   .sort_values([\"dmin\",\"Wk\"]))\n",
        "            cand2 = g[(g[\"n\"] >= 10) & (g[\"dmax\"] >= today_d)]\n",
        "            if len(cand2):\n",
        "                row = cand2.iloc[0]\n",
        "                wk_next = int(row[\"Wk\"])\n",
        "                start_date = row[\"dmin\"]; end_date = row[\"dmax\"]\n",
        "                break\n",
        "\n",
        "assert wk_next is not None, \"No pude detectar la próxima jornada.\"\n",
        "PRED_SEASON = season_auto\n",
        "print(f\"[AUTO] Próxima jornada: Season={PRED_SEASON}  Wk={wk_next}  ({start_date}–{end_date})\")\n",
        "\n",
        "# --- Normaliza fechas en df (df_final ya cargado) ---\n",
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "# --- Índices a predecir: por jornada completa (no por fechas) ---\n",
        "mask_pred = (\n",
        "    (df[\"Season\"] == PRED_SEASON) &\n",
        "    (df[\"Wk\"] == wk_next)\n",
        ")\n",
        "pred_idx_sorted = (\n",
        "    df.loc[mask_pred]\n",
        "      .assign(_idx=lambda x: x.index)\n",
        "      .sort_values([\"Date\",\"_idx\"]).index.tolist()\n",
        ")\n",
        "print(f\"[BASE] partidos a predecir: {len(pred_idx_sorted)} en jornada {wk_next}\")\n",
        "\n",
        "# --- X,y evitando fugas (añadimos los nombres para NO usarlos como features) ---\n",
        "drop_cols = [\n",
        "    'FTR','target','Date','has_xg_data','overround','pimp2','B365D',\n",
        "    'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "    'HomeTeam_norm','AwayTeam_norm',  # excluir nombres del modelo\n",
        "    'row_id'\n",
        "]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df[\"target\"]\n",
        "\n",
        "df_dates = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.date\n",
        "mask_train = (y.notna()) & (df_dates < start_date)\n",
        "X_train = X.loc[mask_train].copy()\n",
        "y_train = y.loc[mask_train].astype(int)\n",
        "\n",
        "# X de predicción en el MISMO orden que exportaremos\n",
        "X_pred  = X.loc[pred_idx_sorted].copy()\n",
        "\n",
        "# quitar 'Season' si queda y alinear columnas\n",
        "for D in (X_train, X_pred):\n",
        "    if \"Season\" in D.columns:\n",
        "        D.drop(columns=[\"Season\"], inplace=True)\n",
        "X_pred = X_pred.reindex(columns=X_train.columns, fill_value=np.nan)\n",
        "\n",
        "# --- Modelo baseline ---\n",
        "pipe = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "# --- Predicción (ya en orden final) ---\n",
        "proba_pred  = pipe.predict_proba(X_pred)\n",
        "pred_labels = pipe.predict(X_pred)\n",
        "\n",
        "# map de clases a 1X2\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes    = list(pipe.named_steps[\"logreg\"].classes_)  # e.g. [0,1,2]\n",
        "pred_1x2   = pd.Series(pred_labels).map(class_map).values\n",
        "\n",
        "# probabilidades por H/D/A robustas a orden de clases\n",
        "proba_df = pd.DataFrame(proba_pred, columns=[class_map[c] for c in classes])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df.columns:\n",
        "        proba_df[lab] = np.nan\n",
        "proba_df = proba_df[[\"H\",\"D\",\"A\"]].reset_index(drop=True)\n",
        "\n",
        "# --- Nombres, cuotas, jornada y fechas del df en el orden de predicción ---\n",
        "need_cols = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"Wk\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "missing = [c for c in need_cols if c not in df.columns]\n",
        "assert not missing, f\"Faltan columnas en df_final: {missing}\"\n",
        "\n",
        "meta_ord = df.loc[pred_idx_sorted, need_cols].copy().reset_index(drop=True)\n",
        "meta_ord = meta_ord.rename(columns={\"Wk\": \"jornada\"})\n",
        "\n",
        "# probabilidades implícitas y overround\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / meta_ord[[\"B365H\",\"B365D\",\"B365A\"]]\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "# --- Resultado final + export ---\n",
        "out_base = pd.concat([\n",
        "    meta_ord[[\"Date\",\"jornada\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]],\n",
        "    pd.Series(pred_1x2, name=\"Pred\"),\n",
        "    proba_df.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1)\n",
        "\n",
        "# Asegura carpeta OUT\n",
        "try:\n",
        "    OUT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "    OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "# con sufijo (histórico)\n",
        "out_base.to_csv( OUT / f\"predictions_{suffix}_base.csv\", index=False)\n",
        "out_base.to_json(OUT / f\"predictions_{suffix}_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "# “current” (para la app)\n",
        "out_base.to_csv( OUT / \"predictions_current_base.csv\", index=False)\n",
        "out_base.to_json(OUT / \"predictions_current_base.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_base.head(10))\n",
        "print(\"Exportado BASE en:\", OUT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "gGG1KvmbHyPU",
        "outputId": "e104eeb0-065f-4924-98f0-e493adc6a77d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTO] Próxima jornada: Season=2025  Wk=7  (2025-09-26–2025-09-29)\n",
            "[BASE] partidos a predecir: 10 en jornada 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Date  jornada HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred  \\\n",
              "0  2025-09-26        7        girona       espanol   2.55   3.30   2.75    D   \n",
              "1  2025-09-27        7        getafe       levante   2.05   3.10   4.10    D   \n",
              "2  2025-09-27        7    ath madrid   real madrid   3.00   3.60   2.25    A   \n",
              "3  2025-09-27        7    villarreal    ath bilbao   2.10   3.25   3.70    H   \n",
              "4  2025-09-27        7      mallorca        alaves   2.35   3.00   3.40    D   \n",
              "5  2025-09-28        7     vallecano       sevilla   2.00   3.30   4.00    H   \n",
              "6  2025-09-28        7         betis       osasuna   1.75   3.80   4.50    H   \n",
              "7  2025-09-28        7         elche         celta   2.87   3.10   2.60    A   \n",
              "8  2025-09-28        7     barcelona      sociedad   1.30   5.50   9.50    H   \n",
              "9  2025-09-29        7      valencia   real oviedo   1.70   3.50   5.50    H   \n",
              "\n",
              "     Prob_H    Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.284438  0.406349  0.309214  0.370370  0.286195  0.343434   1.058824  \n",
              "1  0.330293  0.348261  0.321446  0.462687  0.305970  0.231343   1.054288  \n",
              "2  0.236097  0.340303  0.423600  0.315789  0.263158  0.421053   1.055556  \n",
              "3  0.400736  0.355985  0.243279  0.451728  0.291886  0.256386   1.054153  \n",
              "4  0.394830  0.402340  0.202830  0.404120  0.316561  0.279319   1.052983  \n",
              "5  0.467457  0.345514  0.187029  0.474820  0.287770  0.237410   1.053030  \n",
              "6  0.458432  0.338874  0.202694  0.540711  0.249012  0.210277   1.056809  \n",
              "7  0.263479  0.317903  0.418618  0.330071  0.305582  0.364347   1.055628  \n",
              "8  0.739343  0.178818  0.081839  0.728223  0.172125  0.099652   1.056312  \n",
              "9  0.479510  0.359695  0.160795  0.557164  0.270622  0.172214   1.055768  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9a617f3-b2b9-40f8-ba0f-98b6fe59b8aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>jornada</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-26</td>\n",
              "      <td>7</td>\n",
              "      <td>girona</td>\n",
              "      <td>espanol</td>\n",
              "      <td>2.55</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.75</td>\n",
              "      <td>D</td>\n",
              "      <td>0.284438</td>\n",
              "      <td>0.406349</td>\n",
              "      <td>0.309214</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.286195</td>\n",
              "      <td>0.343434</td>\n",
              "      <td>1.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>getafe</td>\n",
              "      <td>levante</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.330293</td>\n",
              "      <td>0.348261</td>\n",
              "      <td>0.321446</td>\n",
              "      <td>0.462687</td>\n",
              "      <td>0.305970</td>\n",
              "      <td>0.231343</td>\n",
              "      <td>1.054288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.25</td>\n",
              "      <td>A</td>\n",
              "      <td>0.236097</td>\n",
              "      <td>0.340303</td>\n",
              "      <td>0.423600</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>1.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.70</td>\n",
              "      <td>H</td>\n",
              "      <td>0.400736</td>\n",
              "      <td>0.355985</td>\n",
              "      <td>0.243279</td>\n",
              "      <td>0.451728</td>\n",
              "      <td>0.291886</td>\n",
              "      <td>0.256386</td>\n",
              "      <td>1.054153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>alaves</td>\n",
              "      <td>2.35</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.40</td>\n",
              "      <td>D</td>\n",
              "      <td>0.394830</td>\n",
              "      <td>0.402340</td>\n",
              "      <td>0.202830</td>\n",
              "      <td>0.404120</td>\n",
              "      <td>0.316561</td>\n",
              "      <td>0.279319</td>\n",
              "      <td>1.052983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>H</td>\n",
              "      <td>0.467457</td>\n",
              "      <td>0.345514</td>\n",
              "      <td>0.187029</td>\n",
              "      <td>0.474820</td>\n",
              "      <td>0.287770</td>\n",
              "      <td>0.237410</td>\n",
              "      <td>1.053030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>betis</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.75</td>\n",
              "      <td>3.80</td>\n",
              "      <td>4.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.458432</td>\n",
              "      <td>0.338874</td>\n",
              "      <td>0.202694</td>\n",
              "      <td>0.540711</td>\n",
              "      <td>0.249012</td>\n",
              "      <td>0.210277</td>\n",
              "      <td>1.056809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>elche</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.87</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.60</td>\n",
              "      <td>A</td>\n",
              "      <td>0.263479</td>\n",
              "      <td>0.317903</td>\n",
              "      <td>0.418618</td>\n",
              "      <td>0.330071</td>\n",
              "      <td>0.305582</td>\n",
              "      <td>0.364347</td>\n",
              "      <td>1.055628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1.30</td>\n",
              "      <td>5.50</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.739343</td>\n",
              "      <td>0.178818</td>\n",
              "      <td>0.081839</td>\n",
              "      <td>0.728223</td>\n",
              "      <td>0.172125</td>\n",
              "      <td>0.099652</td>\n",
              "      <td>1.056312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-29</td>\n",
              "      <td>7</td>\n",
              "      <td>valencia</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.479510</td>\n",
              "      <td>0.359695</td>\n",
              "      <td>0.160795</td>\n",
              "      <td>0.557164</td>\n",
              "      <td>0.270622</td>\n",
              "      <td>0.172214</td>\n",
              "      <td>1.055768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9a617f3-b2b9-40f8-ba0f-98b6fe59b8aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9a617f3-b2b9-40f8-ba0f-98b6fe59b8aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9a617f3-b2b9-40f8-ba0f-98b6fe59b8aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6d7b69e4-3fbb-400a-a809-7068aa726301\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d7b69e4-3fbb-400a-a809-7068aa726301')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6d7b69e4-3fbb-400a-a809-7068aa726301 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Exportado BASE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-26\",\n        \"max\": \"2025-09-29\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-09-27\",\n          \"2025-09-29\",\n          \"2025-09-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jornada\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"barcelona\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"sociedad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5331260013667813,\n        \"min\": 1.3,\n        \"max\": 3.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7297069426983837,\n        \"min\": 3.0,\n        \"max\": 5.5,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.088752950659529,\n        \"min\": 2.25,\n        \"max\": 9.5,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14639556158780279,\n        \"min\": 0.23609707593925655,\n        \"max\": 0.7393429001921749,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7393429001921749\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06280145295870317,\n        \"min\": 0.17881817769549105,\n        \"max\": 0.4063487178995416,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.17881817769549105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11136782571126112,\n        \"min\": 0.0818389221123341,\n        \"max\": 0.4236000959461038,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0818389221123341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12333372525757409,\n        \"min\": 0.3157894736842105,\n        \"max\": 0.7282229965156793,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7282229965156793\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04165076481216209,\n        \"min\": 0.17212543554006968,\n        \"max\": 0.3165610142630745,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.17212543554006968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0950859022483229,\n        \"min\": 0.09965156794425085,\n        \"max\": 0.42105263157894735,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.09965156794425085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017936763026703008,\n        \"min\": 1.0529828952857738,\n        \"max\": 1.058823529411765,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.056312108943688\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exportado BASE en: /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCI5w60foc4"
      },
      "source": [
        "Con SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PREDICCIÓN (SMOTE) + B365 + export (sin df_old)\n",
        "# =========================\n",
        "\n",
        "# --- Detectar automáticamente la próxima jornada COMPLETA (10), como en baseline actualizado ---\n",
        "def _season_from_run_date(run_date_str: str) -> int:\n",
        "    d = pd.to_datetime(run_date_str)\n",
        "    return int(d.year) if d.month >= 7 else int(d.year) - 1\n",
        "\n",
        "_df_dates = df.copy()\n",
        "_df_dates[\"Date\"] = pd.to_datetime(_df_dates[\"Date\"]).dt.date\n",
        "\n",
        "season_auto = _season_from_run_date(RUN_DATE)\n",
        "today_d = pd.to_datetime(RUN_DATE).date()\n",
        "\n",
        "# 1) Primero con lo que ya hay en df (sin filtrar por futuro para no perder el viernes)\n",
        "grp_all = (_df_dates[_df_dates[\"Season\"] == season_auto]\n",
        "           .groupby(\"Wk\")\n",
        "           .agg(n=(\"Wk\",\"size\"), dmin=(\"Date\",\"min\"), dmax=(\"Date\",\"max\"))\n",
        "           .reset_index()\n",
        "           .sort_values([\"dmin\",\"Wk\"]))\n",
        "\n",
        "wk_next = None; start_date = None; end_date = None\n",
        "if not grp_all.empty:\n",
        "    cand = grp_all[(grp_all[\"n\"] >= 10) & (grp_all[\"dmax\"] >= today_d)]\n",
        "    if len(cand):\n",
        "        row = cand.iloc[0]\n",
        "        wk_next = int(row[\"Wk\"])\n",
        "        start_date = row[\"dmin\"]; end_date = row[\"dmax\"]\n",
        "\n",
        "# 2) Fallback: parquet de jornadas si df no está completo\n",
        "if wk_next is None:\n",
        "    PROC = Path(PROC) if \"PROC\" in globals() else Path(\"./data/02_processed\")\n",
        "    for wk_path in [PROC/\"wk_actualizado_2005_2025.parquet\", PROC/\"wk_2005_2025.parquet\"]:\n",
        "        if wk_path.exists():\n",
        "            wk = pd.read_parquet(wk_path)\n",
        "            wk = wk[wk[\"Season\"] == season_auto].copy()\n",
        "            wk[\"Date\"] = pd.to_datetime(wk[\"Date\"], errors=\"coerce\").dt.date\n",
        "            g = (wk.groupby(\"Wk\")\n",
        "                   .agg(n=(\"Wk\",\"size\"), dmin=(\"Date\",\"min\"), dmax=(\"Date\",\"max\"))\n",
        "                   .reset_index()\n",
        "                   .sort_values([\"dmin\",\"Wk\"]))\n",
        "            cand2 = g[(g[\"n\"] >= 10) & (g[\"dmax\"] >= today_d)]\n",
        "            if len(cand2):\n",
        "                row = cand2.iloc[0]\n",
        "                wk_next = int(row[\"Wk\"])\n",
        "                start_date = row[\"dmin\"]; end_date = row[\"dmax\"]\n",
        "                break\n",
        "\n",
        "assert wk_next is not None, \"No pude detectar la próxima jornada.\"\n",
        "PRED_SEASON = season_auto\n",
        "print(f\"[AUTO] Próxima jornada: Season={PRED_SEASON}  Wk={wk_next}  ({start_date}–{end_date})\")\n",
        "\n",
        "# --- Normaliza fechas en df (df_final ya cargado) ---\n",
        "df = df.copy()\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"]).dt.date\n",
        "\n",
        "# --- Índices a predecir: por jornada completa (no por rango de fechas) ---\n",
        "mask_pred = (\n",
        "    (df[\"Season\"] == PRED_SEASON) &\n",
        "    (df[\"Wk\"] == wk_next)\n",
        ")\n",
        "pred_idx_sorted = (\n",
        "    df.loc[mask_pred]\n",
        "      .assign(_idx=lambda x: x.index)\n",
        "      .sort_values([\"Date\",\"_idx\"]).index.tolist()\n",
        ")\n",
        "print(f\"[SMOTE] partidos a predecir: {len(pred_idx_sorted)} en jornada {wk_next}\")\n",
        "\n",
        "# --- X,y evitando fugas (excluye nombres de equipos de las features) ---\n",
        "drop_cols = [\n",
        "    'FTR','target','Date','has_xg_data','overround','pimp2','B365D',\n",
        "    'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "    'HomeTeam_norm','AwayTeam_norm',  # <- excluir nombres del modelo\n",
        "    'row_id'\n",
        "]\n",
        "drop_cols = [c for c in drop_cols if c in df.columns]\n",
        "\n",
        "X = df.drop(columns=drop_cols)\n",
        "y = df[\"target\"]\n",
        "\n",
        "# === CAMBIO CLAVE (alineado con baseline): ENTRENAR SOLO CON PASADO ===\n",
        "df_dates = pd.to_datetime(df[\"Date\"], errors=\"coerce\").dt.date\n",
        "mask_train = (y.notna()) & (df_dates < start_date)\n",
        "\n",
        "X_train = X.loc[mask_train].copy()\n",
        "y_train = y.loc[mask_train].astype(int)\n",
        "\n",
        "# X de predicción en el MISMO orden de export\n",
        "X_pred  = X.loc[pred_idx_sorted].copy()\n",
        "\n",
        "# quitar 'Season' si queda y alinear columnas\n",
        "for D in (X_train, X_pred):\n",
        "    if \"Season\" in D.columns:\n",
        "        D.drop(columns=[\"Season\"], inplace=True)\n",
        "X_pred = X_pred.reindex(columns=X_train.columns, fill_value=np.nan)\n",
        "\n",
        "# --- Modelo SMOTE ---\n",
        "pipe_sm = ImbPipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\",  StandardScaler()),\n",
        "    (\"smote\",   SMOTE(random_state=42)),\n",
        "    (\"logreg\",  LogisticRegression(solver=\"saga\", penalty=\"l2\", max_iter=1000, random_state=42))\n",
        "])\n",
        "pipe_sm.fit(X_train, y_train)\n",
        "\n",
        "# --- Predicción (ya en orden final) ---\n",
        "proba_pred_sm  = pipe_sm.predict_proba(X_pred)\n",
        "pred_labels_sm = pipe_sm.predict(X_pred)\n",
        "\n",
        "class_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "classes_sm = list(pipe_sm.named_steps[\"logreg\"].classes_)\n",
        "pred_1x2_sm = pd.Series(pred_labels_sm).map(class_map).values\n",
        "\n",
        "proba_df_sm = pd.DataFrame(proba_pred_sm, columns=[class_map[c] for c in classes_sm])\n",
        "for lab in [\"H\",\"D\",\"A\"]:\n",
        "    if lab not in proba_df_sm.columns:\n",
        "        proba_df_sm[lab] = np.nan\n",
        "proba_df_sm = proba_df_sm[[\"H\",\"D\",\"A\"]].reset_index(drop=True)\n",
        "\n",
        "# --- Nombres, cuotas, jornada y fechas directamente de df (orden pred_idx_sorted) ---\n",
        "need_cols = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"Wk\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "missing = [c for c in need_cols if c not in df.columns]\n",
        "assert not missing, f\"Faltan columnas en df_final: {missing}\"\n",
        "\n",
        "meta_ord = df.loc[pred_idx_sorted, need_cols].copy().reset_index(drop=True)\n",
        "meta_ord = meta_ord.rename(columns={\"Wk\": \"jornada\"})\n",
        "\n",
        "# probabilidades implícitas y overround\n",
        "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "    inv = 1.0 / meta_ord[[\"B365H\",\"B365D\",\"B365A\"]]\n",
        "overround = inv.sum(axis=1)\n",
        "imp = inv.div(overround, axis=0)\n",
        "imp.columns = [\"Imp_H\",\"Imp_D\",\"Imp_A\"]\n",
        "\n",
        "# --- Resultado final + export ---\n",
        "out_sm = pd.concat([\n",
        "    meta_ord[[\"Date\",\"jornada\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]],\n",
        "    pd.Series(pred_1x2_sm, name=\"Pred\"),\n",
        "    proba_df_sm.rename(columns={\"H\":\"Prob_H\",\"D\":\"Prob_D\",\"A\":\"Prob_A\"}),\n",
        "    imp,\n",
        "    overround.rename(\"Overround\"),\n",
        "], axis=1)\n",
        "\n",
        "# Asegura carpeta OUT (misma que baseline)\n",
        "try:\n",
        "    OUT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "    OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "suffix = f\"{PRED_SEASON}_{start_date}_{end_date}\"\n",
        "\n",
        "# con sufijo (histórico)\n",
        "out_sm.to_csv( OUT / f\"predictions_{suffix}_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / f\"predictions_{suffix}_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "# “current” (para la app)\n",
        "out_sm.to_csv( OUT / \"predictions_current_smote.csv\", index=False)\n",
        "out_sm.to_json(OUT / \"predictions_current_smote.json\", orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "display(out_sm.head(10))\n",
        "print(\"Exportado SMOTE en:\", OUT)"
      ],
      "metadata": {
        "id": "CqYO8FmNCdua",
        "outputId": "d7588c17-492f-4b70-f8de-6341178f725a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AUTO] Próxima jornada: Season=2025  Wk=7  (2025-09-26–2025-09-29)\n",
            "[SMOTE] partidos a predecir: 10 en jornada 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Date  jornada HomeTeam_norm AwayTeam_norm  B365H  B365D  B365A Pred  \\\n",
              "0  2025-09-26        7        girona       espanol   2.55   3.30   2.75    D   \n",
              "1  2025-09-27        7        getafe       levante   2.05   3.10   4.10    D   \n",
              "2  2025-09-27        7    ath madrid   real madrid   3.00   3.60   2.25    D   \n",
              "3  2025-09-27        7    villarreal    ath bilbao   2.10   3.25   3.70    D   \n",
              "4  2025-09-27        7      mallorca        alaves   2.35   3.00   3.40    D   \n",
              "5  2025-09-28        7     vallecano       sevilla   2.00   3.30   4.00    D   \n",
              "6  2025-09-28        7         betis       osasuna   1.75   3.80   4.50    D   \n",
              "7  2025-09-28        7         elche         celta   2.87   3.10   2.60    A   \n",
              "8  2025-09-28        7     barcelona      sociedad   1.30   5.50   9.50    H   \n",
              "9  2025-09-29        7      valencia   real oviedo   1.70   3.50   5.50    D   \n",
              "\n",
              "     Prob_H    Prob_D    Prob_A     Imp_H     Imp_D     Imp_A  Overround  \n",
              "0  0.165208  0.534987  0.299805  0.370370  0.286195  0.343434   1.058824  \n",
              "1  0.199491  0.447436  0.353072  0.462687  0.305970  0.231343   1.054288  \n",
              "2  0.120587  0.472663  0.406750  0.315789  0.263158  0.421053   1.055556  \n",
              "3  0.228825  0.519527  0.251649  0.451728  0.291886  0.256386   1.054153  \n",
              "4  0.240100  0.557328  0.202573  0.404120  0.316561  0.279319   1.052983  \n",
              "5  0.278788  0.536563  0.184649  0.474820  0.287770  0.237410   1.053030  \n",
              "6  0.281199  0.501805  0.216996  0.540711  0.249012  0.210277   1.056809  \n",
              "7  0.153430  0.415525  0.431045  0.330071  0.305582  0.364347   1.055628  \n",
              "8  0.570768  0.306818  0.122414  0.728223  0.172125  0.099652   1.056312  \n",
              "9  0.314457  0.515624  0.169919  0.557164  0.270622  0.172214   1.055768  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2450882a-4164-4492-92c5-cac9efe68261\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>jornada</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>Pred</th>\n",
              "      <th>Prob_H</th>\n",
              "      <th>Prob_D</th>\n",
              "      <th>Prob_A</th>\n",
              "      <th>Imp_H</th>\n",
              "      <th>Imp_D</th>\n",
              "      <th>Imp_A</th>\n",
              "      <th>Overround</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-09-26</td>\n",
              "      <td>7</td>\n",
              "      <td>girona</td>\n",
              "      <td>espanol</td>\n",
              "      <td>2.55</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.75</td>\n",
              "      <td>D</td>\n",
              "      <td>0.165208</td>\n",
              "      <td>0.534987</td>\n",
              "      <td>0.299805</td>\n",
              "      <td>0.370370</td>\n",
              "      <td>0.286195</td>\n",
              "      <td>0.343434</td>\n",
              "      <td>1.058824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>getafe</td>\n",
              "      <td>levante</td>\n",
              "      <td>2.05</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.10</td>\n",
              "      <td>D</td>\n",
              "      <td>0.199491</td>\n",
              "      <td>0.447436</td>\n",
              "      <td>0.353072</td>\n",
              "      <td>0.462687</td>\n",
              "      <td>0.305970</td>\n",
              "      <td>0.231343</td>\n",
              "      <td>1.054288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2.25</td>\n",
              "      <td>D</td>\n",
              "      <td>0.120587</td>\n",
              "      <td>0.472663</td>\n",
              "      <td>0.406750</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>1.055556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.70</td>\n",
              "      <td>D</td>\n",
              "      <td>0.228825</td>\n",
              "      <td>0.519527</td>\n",
              "      <td>0.251649</td>\n",
              "      <td>0.451728</td>\n",
              "      <td>0.291886</td>\n",
              "      <td>0.256386</td>\n",
              "      <td>1.054153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-09-27</td>\n",
              "      <td>7</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>alaves</td>\n",
              "      <td>2.35</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.40</td>\n",
              "      <td>D</td>\n",
              "      <td>0.240100</td>\n",
              "      <td>0.557328</td>\n",
              "      <td>0.202573</td>\n",
              "      <td>0.404120</td>\n",
              "      <td>0.316561</td>\n",
              "      <td>0.279319</td>\n",
              "      <td>1.052983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>D</td>\n",
              "      <td>0.278788</td>\n",
              "      <td>0.536563</td>\n",
              "      <td>0.184649</td>\n",
              "      <td>0.474820</td>\n",
              "      <td>0.287770</td>\n",
              "      <td>0.237410</td>\n",
              "      <td>1.053030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>betis</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>1.75</td>\n",
              "      <td>3.80</td>\n",
              "      <td>4.50</td>\n",
              "      <td>D</td>\n",
              "      <td>0.281199</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.216996</td>\n",
              "      <td>0.540711</td>\n",
              "      <td>0.249012</td>\n",
              "      <td>0.210277</td>\n",
              "      <td>1.056809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>elche</td>\n",
              "      <td>celta</td>\n",
              "      <td>2.87</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.60</td>\n",
              "      <td>A</td>\n",
              "      <td>0.153430</td>\n",
              "      <td>0.415525</td>\n",
              "      <td>0.431045</td>\n",
              "      <td>0.330071</td>\n",
              "      <td>0.305582</td>\n",
              "      <td>0.364347</td>\n",
              "      <td>1.055628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-09-28</td>\n",
              "      <td>7</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>1.30</td>\n",
              "      <td>5.50</td>\n",
              "      <td>9.50</td>\n",
              "      <td>H</td>\n",
              "      <td>0.570768</td>\n",
              "      <td>0.306818</td>\n",
              "      <td>0.122414</td>\n",
              "      <td>0.728223</td>\n",
              "      <td>0.172125</td>\n",
              "      <td>0.099652</td>\n",
              "      <td>1.056312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-09-29</td>\n",
              "      <td>7</td>\n",
              "      <td>valencia</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>D</td>\n",
              "      <td>0.314457</td>\n",
              "      <td>0.515624</td>\n",
              "      <td>0.169919</td>\n",
              "      <td>0.557164</td>\n",
              "      <td>0.270622</td>\n",
              "      <td>0.172214</td>\n",
              "      <td>1.055768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2450882a-4164-4492-92c5-cac9efe68261')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2450882a-4164-4492-92c5-cac9efe68261 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2450882a-4164-4492-92c5-cac9efe68261');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fbe34f96-98b5-4372-9a82-a1f0a4ccf747\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbe34f96-98b5-4372-9a82-a1f0a4ccf747')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fbe34f96-98b5-4372-9a82-a1f0a4ccf747 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Exportado SMOTE en:\\\", OUT)\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-26\",\n        \"max\": \"2025-09-29\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"2025-09-27\",\n          \"2025-09-29\",\n          \"2025-09-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jornada\",\n      \"properties\": {\n        \"dtype\": \"Int64\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HomeTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"barcelona\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AwayTeam_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"sociedad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5331260013667813,\n        \"min\": 1.3,\n        \"max\": 3.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7297069426983837,\n        \"min\": 3.0,\n        \"max\": 5.5,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B365A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.088752950659529,\n        \"min\": 2.25,\n        \"max\": 9.5,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pred\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12689905187594638,\n        \"min\": 0.12058656795428158,\n        \"max\": 0.5707680925889136,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.5707680925889136\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07510419054552993,\n        \"min\": 0.30681812890176935,\n        \"max\": 0.557327665590882,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.30681812890176935\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prob_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10478922513274347,\n        \"min\": 0.12241377850931702,\n        \"max\": 0.43104477579210965,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.12241377850931702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12333372525757409,\n        \"min\": 0.3157894736842105,\n        \"max\": 0.7282229965156793,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7282229965156793\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_D\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04165076481216209,\n        \"min\": 0.17212543554006968,\n        \"max\": 0.3165610142630745,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.17212543554006968\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Imp_A\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0950859022483229,\n        \"min\": 0.09965156794425085,\n        \"max\": 0.42105263157894735,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.09965156794425085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overround\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017936763026703008,\n        \"min\": 1.0529828952857738,\n        \"max\": 1.058823529411765,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.056312108943688\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exportado SMOTE en: /content/outputs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AUraRaeqPH_"
      },
      "source": [
        "# **EVALUACIÓN HISTÓRICA: Logistic Regression multinomial**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Iqi91Ub6gI-T"
      },
      "outputs": [],
      "source": [
        "IN_PATH = FEAT / \"df_final.parquet\"\n",
        "df = pd.read_parquet(IN_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Shn3mE9kGbe"
      },
      "source": [
        "Sin SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Eval LogReg (SIN SMOTE) walk-forward por jornada → métricas POR TEMPORADA\n",
        "# ============================================\n",
        "\n",
        "# --- si df no existe, intenta cargarlo del proyecto ---\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    try:\n",
        "        ROOT\n",
        "    except NameError:\n",
        "        ROOT = Path(\".\")\n",
        "    try:\n",
        "        DATA\n",
        "    except NameError:\n",
        "        DATA = ROOT / \"data\"\n",
        "    FEAT = DATA / \"03_features\"\n",
        "    df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# ---------- util: asegurar orden [0,1,2] en y_proba ----------\n",
        "def _ensure_probs_012(y_proba: np.ndarray, classes_model: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Devuelve matriz (N,3) en orden fijo [0,1,2]; si falta alguna clase en el modelo, rellena con NaN.\"\"\"\n",
        "    pos = {int(c): i for i, c in enumerate(classes_model)}\n",
        "    out = np.full((y_proba.shape[0], 3), np.nan, dtype=float)\n",
        "    for cls in (0, 1, 2):\n",
        "        if cls in pos:\n",
        "            out[:, cls] = y_proba[:, pos[cls]]\n",
        "    return out\n",
        "\n",
        "# ===== Eval: LogReg SIN SMOTE (walk-forward por jornada, salida por temporada) =====\n",
        "def run_logreg_eval_no_smote(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    SALIDA (igual que antes): métricas agregadas POR TEMPORADA.\n",
        "    NOVEDAD: el TEST se evalúa jornada a jornada (walk-forward).\n",
        "    Para cada jornada del test, se entrena SOLO con partidos anteriores a la fecha mínima de esa jornada.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- columnas a excluir de X (mismas reglas que usas en todo el notebook) ---\n",
        "    drop_cols_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_cols_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                      ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                       'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    # --- X/y + filas válidas ---\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        # si usamos cuotas como features (H y A), exige que existan\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in df.columns:\n",
        "                valid &= df[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' en los datos.\")\n",
        "    if 'Wk' not in df.columns:\n",
        "        raise ValueError(\"Falta 'Wk' para el walk-forward por jornada.\")\n",
        "\n",
        "    # fechas reales para el corte temporal\n",
        "    dates_all = pd.to_datetime(df.loc[X_all.index, 'Date'], errors='coerce')\n",
        "\n",
        "    # --- seasons de test (como en tu código original) ---\n",
        "    test_mask_season = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask_season &= (X_all['Season'] <= test_until_season)\n",
        "    seasons_test = sorted(X_all.loc[test_mask_season, 'Season'].dropna().astype(int).unique())\n",
        "\n",
        "    if not seasons_test:\n",
        "        print(\"⚠️ TEST vacío tras filtrar seasons.\")\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    # acumuladores (test de toda la season)\n",
        "    all_idx_test, all_y_true, all_y_pred, all_y_proba = [], [], [], []\n",
        "    train_metrics_per_wk = []\n",
        "    last_model = None\n",
        "    last_scaler = None\n",
        "\n",
        "    for seas in seasons_test:\n",
        "        idx_season = X_all.index[X_all['Season'] == seas]\n",
        "        wk_info = (pd.DataFrame({\n",
        "                        'idx': idx_season,\n",
        "                        'Wk':  df.loc[idx_season, 'Wk'].values,\n",
        "                        'Date': dates_all.loc[idx_season].values\n",
        "                   })\n",
        "                   .dropna(subset=['Wk','Date']))\n",
        "        if wk_info.empty:\n",
        "            continue\n",
        "\n",
        "        # orden de jornadas según la fecha mínima (y Wk como desempate natural del groupby)\n",
        "        wk_order = (wk_info.groupby('Wk')['Date']\n",
        "                            .min()\n",
        "                            .sort_values(kind='mergesort')\n",
        "                            .index.tolist())\n",
        "\n",
        "        for wk in wk_order:\n",
        "            idx_wk = wk_info.loc[wk_info['Wk'] == wk, 'idx'].tolist()\n",
        "            if not idx_wk:\n",
        "                continue\n",
        "\n",
        "            cut_date = pd.to_datetime(wk_info.loc[wk_info['Wk'] == wk, 'Date']).min()\n",
        "\n",
        "            # TRAIN: todo lo anterior al primer partido de la jornada\n",
        "            train_mask = (dates_all < cut_date)\n",
        "            X_tr_full = X_all.loc[train_mask].copy()\n",
        "            y_tr_full = y_all.loc[train_mask].copy()\n",
        "\n",
        "            # TEST: solo la jornada wk\n",
        "            X_te_full = X_all.loc[idx_wk].copy()\n",
        "            y_te_full = y_all.loc[idx_wk].copy()\n",
        "\n",
        "            # quitar Season de features\n",
        "            X_tr = X_tr_full.drop(columns=['Season']) if 'Season' in X_tr_full.columns else X_tr_full\n",
        "            X_te = X_te_full.drop(columns=['Season']) if 'Season' in X_te_full.columns else X_te_full\n",
        "\n",
        "            if (len(X_tr) == 0) or (len(np.unique(y_tr_full)) < 2):\n",
        "                continue\n",
        "\n",
        "            # escalado + modelo de la jornada\n",
        "            scaler = StandardScaler()\n",
        "            X_tr_s = scaler.fit_transform(X_tr)\n",
        "            X_te_s = scaler.transform(X_te)\n",
        "\n",
        "            model = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, random_state=random_state)\n",
        "            model.fit(X_tr_s, y_tr_full)\n",
        "\n",
        "            # métricas de TRAIN (por jornada)\n",
        "            ytr_pred  = model.predict(X_tr_s)\n",
        "            ytr_proba = model.predict_proba(X_tr_s)\n",
        "            classes_used = model.classes_\n",
        "            ytr_bin  = label_binarize(y_tr_full, classes=classes_used)\n",
        "            brier_tr = float(np.mean(np.sum((ytr_proba - ytr_bin)**2, axis=1)))\n",
        "            acc_tr   = float(accuracy_score(y_tr_full, ytr_pred))\n",
        "            ll_tr    = float(log_loss(y_tr_full, ytr_proba, labels=classes_used))\n",
        "            train_metrics_per_wk.append({\n",
        "                \"n_train\": int(len(y_tr_full)),\n",
        "                \"accuracy\": acc_tr,\n",
        "                \"log_loss\": ll_tr,\n",
        "                \"brier\": brier_tr\n",
        "            })\n",
        "\n",
        "            # predicción TEST (jornada)\n",
        "            yte_pred  = model.predict(X_te_s)\n",
        "            yte_proba = model.predict_proba(X_te_s)\n",
        "            yte_proba_012 = _ensure_probs_012(yte_proba, classes_model=classes_used)\n",
        "\n",
        "            all_idx_test.extend(idx_wk)\n",
        "            all_y_true.extend(y_te_full.tolist())\n",
        "            all_y_pred.extend(yte_pred.tolist())\n",
        "            all_y_proba.append(yte_proba_012)\n",
        "\n",
        "            last_model = model\n",
        "            last_scaler = scaler\n",
        "\n",
        "    if not all_idx_test:\n",
        "        print(\"⚠️ No hubo jornadas válidas en test.\")\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    # agregación de TEST por temporada (formato idéntico al original)\n",
        "    y_test_concat  = np.array(all_y_true, dtype=int)\n",
        "    y_pred_concat  = np.array(all_y_pred, dtype=int)\n",
        "    y_proba_concat = np.vstack(all_y_proba)  # (N,3) con posibles NaN si faltó alguna clase\n",
        "\n",
        "    # proba segura para log_loss (sin NaN y normalizada por fila)\n",
        "    proba_safe = y_proba_concat.copy()\n",
        "    proba_safe[np.isnan(proba_safe)] = 0.0\n",
        "    row_sums = proba_safe.sum(axis=1, keepdims=True)\n",
        "    zero_rows = (row_sums == 0).ravel()\n",
        "    if zero_rows.any():\n",
        "        proba_safe[zero_rows, :] = 1.0/3.0\n",
        "        row_sums[zero_rows, :] = 1.0\n",
        "    proba_safe = proba_safe / row_sums\n",
        "\n",
        "    y_bin_full = label_binarize(y_test_concat, classes=[0,1,2])\n",
        "    brier_te = float(np.mean(np.sum((proba_safe - y_bin_full)**2, axis=1)))\n",
        "    acc_te   = float(accuracy_score(y_test_concat, y_pred_concat))\n",
        "    ll_te    = float(log_loss(y_test_concat, proba_safe, labels=[0,1,2]))\n",
        "\n",
        "    # TRAIN agregado (promedio ponderado por nº de train de cada jornada)\n",
        "    if train_metrics_per_wk:\n",
        "        w = np.array([m[\"n_train\"] for m in train_metrics_per_wk], dtype=float)\n",
        "        w /= w.sum()\n",
        "        acc_tr_w = float(np.sum([m[\"accuracy\"] * w[i] for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        ll_tr_w  = float(np.sum([m[\"log_loss\"] * w[i]  for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        br_tr_w  = float(np.sum([m[\"brier\"] * w[i]     for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        n_tr_last = int(train_metrics_per_wk[-1][\"n_train\"])\n",
        "    else:\n",
        "        acc_tr_w = ll_tr_w = br_tr_w = np.nan\n",
        "        n_tr_last = 0\n",
        "\n",
        "    metrics_train = {\n",
        "        \"accuracy\": acc_tr_w,\n",
        "        \"log_loss\": ll_tr_w,\n",
        "        \"brier\":    br_tr_w,\n",
        "        \"n_train\":  n_tr_last\n",
        "    }\n",
        "    seasons_text = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    metrics_test = {\n",
        "        \"accuracy\": acc_te,\n",
        "        \"log_loss\": ll_te,\n",
        "        \"brier\":    brier_te,\n",
        "        \"n_test\":   int(len(y_test_concat)),\n",
        "        \"season_min\": int(min(seasons_test)),\n",
        "        \"season_max\": int(max(seasons_test)),\n",
        "    }\n",
        "\n",
        "    print(\"Logistic Regression (sin SMOTE)\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train (promedio ponderado por jornada) ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {seasons_text}, walk-forward por jornada) ===\"); print(metrics_test)\n",
        "\n",
        "    return last_model, last_scaler, (metrics_train, metrics_test), \\\n",
        "           pd.Series(y_test_concat, index=all_idx_test), \\\n",
        "           y_pred_concat, proba_safe, np.array(all_idx_test)\n",
        "\n",
        "# ===== Bucle que guarda eval_grid.json y metrics_by_season.csv =====\n",
        "ROOT = Path(\".\")\n",
        "OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "\n",
        "rows = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        model, scaler, (mtr_tr, mtr_te), y_test, yte_pred, yte_proba, idx_test = run_logreg_eval_no_smote(\n",
        "            df,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=True,\n",
        "            random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "\n",
        "        # rango de jornadas presentes en el test de esa season (para referencia)\n",
        "        wk_min = wk_max = None\n",
        "        if \"Wk\" in df.columns and len(idx_test):\n",
        "            wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "            if len(wks):\n",
        "                wk_min = int(wks.min())\n",
        "                wk_max = int(wks.max())\n",
        "\n",
        "        rows.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "                \"wk_min\": wk_min,\n",
        "                \"wk_max\": wk_max,\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SKIP] test={test_season} → {e}\")\n",
        "\n",
        "# guardar salidas (mismo formato que ya usabas)\n",
        "with open(OUT / \"eval_grid.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows:\n",
        "    flat = []\n",
        "    for r in rows:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "            \"wk_min\":      te[\"wk_min\"],\n",
        "            \"wk_max\":      te[\"wk_max\"],\n",
        "        })\n",
        "    pd.DataFrame(flat).sort_values(\"test_season\").to_csv(\n",
        "        OUT / \"metrics_by_season.csv\", index=False\n",
        "    )\n",
        "\n",
        "print(f\"Guardados:\\n- {OUT/'eval_grid.json'}\\n- {OUT/'metrics_by_season.csv'}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ImH0ccxnudDV",
        "outputId": "7e1af7bb-ac0f-4b0b-ca22-558efb41e152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.6, 'log_loss': 0.8503040399360499, 'brier': 0.5104307269727479, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4263157894736842, 'log_loss': 1.2349125387397448, 'brier': 0.7084656252008951, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5565789473684211, 'log_loss': 0.9214888832439952, 'brier': 0.552017798278286, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008, walk-forward por jornada) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.0946781196370998, 'brier': 0.6514989943768685, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5482456140350878, 'log_loss': 0.9341333936534477, 'brier': 0.5582402681906519, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009, walk-forward por jornada) ===\n",
            "{'accuracy': 0.531578947368421, 'log_loss': 0.9731693801920157, 'brier': 0.5740858195095201, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5486842105263158, 'log_loss': 0.9279406338478252, 'brier': 0.5543308157141086, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5842105263157895, 'log_loss': 0.9611714000747812, 'brier': 0.5600985795015131, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5673684210526316, 'log_loss': 0.92567347721971, 'brier': 0.5503509561104474, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9618637854826373, 'brier': 0.569337462696509, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5649122807017544, 'log_loss': 0.9258206035623451, 'brier': 0.5508649323751328, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5263157894736842, 'log_loss': 0.9812522610577148, 'brier': 0.5741574692017298, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5620300751879699, 'log_loss': 0.9300982185449254, 'brier': 0.5525997571886312, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9816107988614631, 'brier': 0.5792206499536022, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5588815789473685, 'log_loss': 0.932953241748893, 'brier': 0.5539945012156289, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5578947368421052, 'log_loss': 0.9533905266381169, 'brier': 0.5579255333473289, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5590643274853802, 'log_loss': 0.9302045400187785, 'brier': 0.551695173347987, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9554489087510584, 'brier': 0.5668172018067045, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.56, 'log_loss': 0.9296168555376824, 'brier': 0.5512567599140625, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016, walk-forward por jornada) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9424364646555844, 'brier': 0.5572641920758349, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.562200956937799, 'log_loss': 0.9280061580011343, 'brier': 0.5499175362118004, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5368421052631579, 'log_loss': 0.9718768790598807, 'brier': 0.5759491180403586, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5622807017543859, 'log_loss': 0.9302030199327271, 'brier': 0.551172040254874, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018, walk-forward por jornada) ===\n",
            "{'accuracy': 0.48947368421052634, 'log_loss': 1.0447989195979441, 'brier': 0.6239512631509635, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5562753036437247, 'log_loss': 0.9373991477942386, 'brier': 0.5558697065701285, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4710526315789474, 'log_loss': 1.0046309623103469, 'brier': 0.60042492501783, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5513157894736842, 'log_loss': 0.941053099742395, 'brier': 0.5583159465810769, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5131578947368421, 'log_loss': 1.0027102003334487, 'brier': 0.5957333636955684, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5503508771929825, 'log_loss': 0.9443762569444348, 'brier': 0.5603350753522194, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5078947368421053, 'log_loss': 1.000834198335483, 'brier': 0.5976131120685585, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9470694509392333, 'brier': 0.561971765511791, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9845858767265123, 'brier': 0.5857510525064845, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5503095975232198, 'log_loss': 0.9487672055459645, 'brier': 0.56301460337696, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9526624544514743, 'brier': 0.5671253491342783, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5497076023391813, 'log_loss': 0.9484854524823103, 'brier': 0.562807791558073, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9582196819419253, 'brier': 0.5659048337474383, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5520775623268698, 'log_loss': 0.9485428490794315, 'brier': 0.5627369524063253, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4666666666666667, 'log_loss': 0.9598671705854682, 'brier': 0.5768538551458187, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados:\n",
            "- outputs/eval_grid.json\n",
            "- outputs/metrics_by_season.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5tGcF-y9Ymk",
        "outputId": "93594634-e80c-4c5a-98ab-d19beb6430f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5497076023391813, 'log_loss': 0.9484854524823103, 'brier': 0.562807791558073, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9582196819419253, 'brier': 0.5659048337474383, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n"
          ]
        }
      ],
      "source": [
        "# LOCAL\n",
        "model, scaler, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = \\\n",
        "    run_logreg_eval_no_smote(df, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFOHEHwvkEAJ"
      },
      "source": [
        "Con SMOTE:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# Eval LogReg (CON SMOTE) walk-forward por jornada → métricas POR TEMPORADA\n",
        "# ============================================\n",
        "\n",
        "# --- SMOTE (imbalanced-learn) ---\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "except Exception as e:\n",
        "    raise ImportError(\"⚠️ Necesitas 'imbalanced-learn' para usar SMOTE. Instálalo e inténtalo de nuevo.\") from e\n",
        "\n",
        "# --- si df no existe, intenta cargarlo del proyecto ---\n",
        "try:\n",
        "    df\n",
        "except NameError:\n",
        "    try:\n",
        "        ROOT\n",
        "    except NameError:\n",
        "        ROOT = Path(\".\")\n",
        "    try:\n",
        "        DATA\n",
        "    except NameError:\n",
        "        DATA = ROOT / \"data\"\n",
        "    FEAT = DATA / \"03_features\"\n",
        "    df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# ---------- util: asegurar orden [0,1,2] en y_proba ----------\n",
        "def _ensure_probs_012(y_proba: np.ndarray, classes_model: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Devuelve matriz (N,3) en orden fijo [0,1,2]; si falta alguna clase en el modelo, rellena con NaN.\"\"\"\n",
        "    pos = {int(c): i for i, c in enumerate(classes_model)}\n",
        "    out = np.full((y_proba.shape[0], 3), np.nan, dtype=float)\n",
        "    for cls in (0, 1, 2):\n",
        "        if cls in pos:\n",
        "            out[:, cls] = y_proba[:, pos[cls]]\n",
        "    return out\n",
        "\n",
        "# ===== Eval: LogReg CON SMOTE (walk-forward por jornada, salida por temporada) =====\n",
        "def run_logreg_eval(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    SALIDA (igual que tu versión previa): métricas agregadas POR TEMPORADA.\n",
        "    NOVEDAD: el TEST se evalúa jornada a jornada (walk-forward).\n",
        "      - Para cada jornada de la season de test, entrena SOLO con partidos anteriores a la fecha mínima de esa jornada.\n",
        "      - Usa SMOTE en el set de entrenamiento de cada jornada (después de escalar).\n",
        "    Devuelve:\n",
        "      last_model, last_scaler, (metrics_train, metrics_test),\n",
        "      y_test_series(index=idx_test), y_pred_test(np.ndarray), proba_test(np.ndarray Nx3), idx_test(np.ndarray)\n",
        "    \"\"\"\n",
        "\n",
        "    # --- columnas a excluir de X (coherente con tus otras celdas) ---\n",
        "    drop_cols_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_cols_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                      ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                       'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_cols_common + drop_cols_mode))\n",
        "\n",
        "    # --- X/y + filas válidas ---\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in df.columns:\n",
        "                valid &= df[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' en los datos.\")\n",
        "    if 'Wk' not in df.columns:\n",
        "        raise ValueError(\"Falta 'Wk' en df para el walk-forward por jornada.\")\n",
        "\n",
        "    # fechas reales para el corte temporal\n",
        "    dates_all = pd.to_datetime(df.loc[X_all.index, 'Date'], errors='coerce')\n",
        "\n",
        "    # --- seasons de test (como antes) ---\n",
        "    test_mask_season = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask_season &= (X_all['Season'] <= test_until_season)\n",
        "    seasons_test = sorted(X_all.loc[test_mask_season, 'Season'].dropna().astype(int).unique())\n",
        "    if not seasons_test:\n",
        "        print(\"⚠️ TEST vacío tras filtrar seasons.\")\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    # acumuladores del TEST de toda la (s) season(s)\n",
        "    all_idx_test, all_y_true, all_y_pred, all_y_proba = [], [], [], []\n",
        "    train_metrics_per_wk = []\n",
        "    last_model = None\n",
        "    last_scaler = None\n",
        "\n",
        "    for seas in seasons_test:\n",
        "        idx_season = X_all.index[X_all['Season'] == seas]\n",
        "        wk_info = (pd.DataFrame({\n",
        "                        'idx': idx_season,\n",
        "                        'Wk':  df.loc[idx_season, 'Wk'].values,\n",
        "                        'Date': dates_all.loc[idx_season].values\n",
        "                   })\n",
        "                   .dropna(subset=['Wk','Date']))\n",
        "        if wk_info.empty:\n",
        "            continue\n",
        "\n",
        "        # orden de jornadas según la fecha mínima\n",
        "        wk_order = (wk_info.groupby('Wk')['Date']\n",
        "                            .min()\n",
        "                            .sort_values(kind='mergesort')\n",
        "                            .index.tolist())\n",
        "\n",
        "        for wk in wk_order:\n",
        "            idx_wk = wk_info.loc[wk_info['Wk'] == wk, 'idx'].tolist()\n",
        "            if not idx_wk:\n",
        "                continue\n",
        "\n",
        "            cut_date = pd.to_datetime(wk_info.loc[wk_info['Wk'] == wk, 'Date']).min()\n",
        "\n",
        "            # TRAIN: todo lo anterior a la primera fecha de la jornada\n",
        "            train_mask = (dates_all < cut_date)\n",
        "            X_tr_full = X_all.loc[train_mask].copy()\n",
        "            y_tr_full = y_all.loc[train_mask].copy()\n",
        "\n",
        "            # TEST: solo esa jornada\n",
        "            X_te_full = X_all.loc[idx_wk].copy()\n",
        "            y_te_full = y_all.loc[idx_wk].copy()\n",
        "\n",
        "            # quitar Season de features\n",
        "            X_tr = X_tr_full.drop(columns=['Season']) if 'Season' in X_tr_full.columns else X_tr_full\n",
        "            X_te = X_te_full.drop(columns=['Season']) if 'Season' in X_te_full.columns else X_te_full\n",
        "\n",
        "            if (len(X_tr) == 0) or (len(np.unique(y_tr_full)) < 2):\n",
        "                continue\n",
        "\n",
        "            # escalado\n",
        "            scaler = StandardScaler()\n",
        "            X_tr_s = scaler.fit_transform(X_tr)\n",
        "            X_te_s = scaler.transform(X_te)\n",
        "\n",
        "            # SMOTE robusto (elige k según la clase minoritaria)\n",
        "            _, counts = np.unique(y_tr_full, return_counts=True)\n",
        "            min_count = int(counts.min()) if len(counts) else 0\n",
        "            if min_count <= 1:\n",
        "                X_res, y_res = X_tr_s, y_tr_full\n",
        "            else:\n",
        "                k = max(1, min(5, min_count - 1))\n",
        "                try:\n",
        "                    sm = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "                    X_res, y_res = sm.fit_resample(X_tr_s, y_tr_full)\n",
        "                except Exception:\n",
        "                    X_res, y_res = X_tr_s, y_tr_full\n",
        "\n",
        "            # modelo\n",
        "            model = LogisticRegression(\n",
        "                solver='saga', penalty='l2', max_iter=1000, random_state=random_state\n",
        "            )\n",
        "            model.fit(X_res, y_res)\n",
        "\n",
        "            # métricas de TRAIN (del modelo ya entrenado con SMOTE)\n",
        "            ytr_pred  = model.predict(X_tr_s)\n",
        "            ytr_proba = model.predict_proba(X_tr_s)\n",
        "            classes_used = model.classes_\n",
        "            ytr_bin  = label_binarize(y_tr_full, classes=classes_used)\n",
        "            brier_tr = float(np.mean(np.sum((ytr_proba - ytr_bin)**2, axis=1)))\n",
        "            acc_tr   = float(accuracy_score(y_tr_full, ytr_pred))\n",
        "            ll_tr    = float(log_loss(y_tr_full, ytr_proba, labels=classes_used))\n",
        "            train_metrics_per_wk.append({\n",
        "                \"n_train\": int(len(y_tr_full)),\n",
        "                \"accuracy\": acc_tr,\n",
        "                \"log_loss\": ll_tr,\n",
        "                \"brier\": brier_tr\n",
        "            })\n",
        "\n",
        "            # predicción TEST (jornada)\n",
        "            yte_pred  = model.predict(X_te_s)\n",
        "            yte_proba = model.predict_proba(X_te_s)\n",
        "            yte_proba_012 = _ensure_probs_012(yte_proba, classes_model=classes_used)\n",
        "\n",
        "            all_idx_test.extend(idx_wk)\n",
        "            all_y_true.extend(y_te_full.tolist())\n",
        "            all_y_pred.extend(yte_pred.tolist())\n",
        "            all_y_proba.append(yte_proba_012)\n",
        "\n",
        "            last_model = model\n",
        "            last_scaler = scaler\n",
        "\n",
        "    if not all_idx_test:\n",
        "        print(\"⚠️ No hubo jornadas válidas en test.\")\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "    # agregación de TEST por temporada (formato idéntico al de tu pipeline original)\n",
        "    y_test_concat  = np.array(all_y_true, dtype=int)\n",
        "    y_pred_concat  = np.array(all_y_pred, dtype=int)\n",
        "    y_proba_concat = np.vstack(all_y_proba)  # (N,3) con posibles NaN si faltó una clase\n",
        "\n",
        "    # proba segura para log_loss/brier (sin NaN; normalizada por fila)\n",
        "    proba_safe = y_proba_concat.copy()\n",
        "    proba_safe[np.isnan(proba_safe)] = 0.0\n",
        "    row_sums = proba_safe.sum(axis=1, keepdims=True)\n",
        "    zero_rows = (row_sums == 0).ravel()\n",
        "    if zero_rows.any():\n",
        "        proba_safe[zero_rows, :] = 1.0/3.0\n",
        "        row_sums[zero_rows, :] = 1.0\n",
        "    proba_safe = proba_safe / row_sums\n",
        "\n",
        "    y_bin_full = label_binarize(y_test_concat, classes=[0,1,2])\n",
        "    brier_te = float(np.mean(np.sum((proba_safe - y_bin_full)**2, axis=1)))\n",
        "    acc_te   = float(accuracy_score(y_test_concat, y_pred_concat))\n",
        "    ll_te    = float(log_loss(y_test_concat, proba_safe, labels=[0,1,2]))\n",
        "\n",
        "    # TRAIN agregado (promedio ponderado por nº de train de cada jornada)\n",
        "    if train_metrics_per_wk:\n",
        "        w = np.array([m[\"n_train\"] for m in train_metrics_per_wk], dtype=float)\n",
        "        w /= w.sum()\n",
        "        acc_tr_w = float(np.sum([m[\"accuracy\"] * w[i] for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        ll_tr_w  = float(np.sum([m[\"log_loss\"] * w[i]  for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        br_tr_w  = float(np.sum([m[\"brier\"] * w[i]     for i, m in enumerate(train_metrics_per_wk)]))\n",
        "        n_tr_last = int(train_metrics_per_wk[-1][\"n_train\"])\n",
        "    else:\n",
        "        acc_tr_w = ll_tr_w = br_tr_w = np.nan\n",
        "        n_tr_last = 0\n",
        "\n",
        "    metrics_train = {\n",
        "        \"accuracy\": acc_tr_w,\n",
        "        \"log_loss\": ll_tr_w,\n",
        "        \"brier\":    br_tr_w,\n",
        "        \"n_train\":  n_tr_last\n",
        "    }\n",
        "    seasons_text = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    metrics_test = {\n",
        "        \"accuracy\": acc_te,\n",
        "        \"log_loss\": ll_te,\n",
        "        \"brier\":    brier_te,\n",
        "        \"n_test\":   int(len(y_test_concat)),\n",
        "        \"season_min\": int(min(seasons_test)),\n",
        "        \"season_max\": int(max(seasons_test)),\n",
        "    }\n",
        "\n",
        "    print(\"Logistic Regression con SMOTE\", \"(con cuotas)\" if with_odds else \"(sin cuotas)\")\n",
        "    print(\"\\n=== Train (promedio ponderado por jornada) ===\"); print(metrics_train)\n",
        "    print(f\"\\n=== Test (Seasons {seasons_text}, walk-forward por jornada) ===\"); print(metrics_test)\n",
        "\n",
        "    return last_model, last_scaler, (metrics_train, metrics_test), \\\n",
        "           pd.Series(y_test_concat, index=all_idx_test), \\\n",
        "           y_pred_concat, proba_safe, np.array(all_idx_test)\n",
        "\n",
        "\n",
        "# ===== Bucle que guarda eval_grid_smote.json y metrics_by_season_smote.csv =====\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "\n",
        "rows_sm = []\n",
        "for test_season in seasons_all:\n",
        "    train_until = test_season - 1\n",
        "    if train_until < seasons_all[0]:\n",
        "        continue\n",
        "    try:\n",
        "        model, scaler, (mtr_tr, mtr_te), y_test, yte_pred, yte_proba, idx_test = run_logreg_eval(\n",
        "            df,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=True,\n",
        "            random_state=42\n",
        "        )\n",
        "        if mtr_te is None:\n",
        "            continue\n",
        "\n",
        "        # rango de jornadas presentes en el test de esa season (solo informativo)\n",
        "        wk_min = wk_max = None\n",
        "        if \"Wk\" in df.columns and idx_test is not None and len(idx_test):\n",
        "            wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "            if len(wks):\n",
        "                wk_min = int(wks.min())\n",
        "                wk_max = int(wks.max())\n",
        "\n",
        "        rows_sm.append({\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"metrics_train\": {\n",
        "                \"accuracy\": float(mtr_tr[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_tr[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_tr[\"brier\"]),\n",
        "                \"n_train\":  int(mtr_tr[\"n_train\"]),\n",
        "            },\n",
        "            \"metrics_test\": {\n",
        "                \"accuracy\": float(mtr_te[\"accuracy\"]),\n",
        "                \"log_loss\": float(mtr_te[\"log_loss\"]),\n",
        "                \"brier\":    float(mtr_te[\"brier\"]),\n",
        "                \"n_test\":   int(mtr_te[\"n_test\"]),\n",
        "                \"season_min\": int(mtr_te[\"season_min\"]),\n",
        "                \"season_max\": int(mtr_te[\"season_max\"]),\n",
        "                \"wk_min\": wk_min,\n",
        "                \"wk_max\": wk_max,\n",
        "            }\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"[SMOTE SKIP] test={test_season} → {e}\")\n",
        "\n",
        "# guardar salidas (mismo formato que ya usabas para SMOTE)\n",
        "with open(OUT / \"eval_grid_smote.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(rows_sm, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "if rows_sm:\n",
        "    flat_sm = []\n",
        "    for r in rows_sm:\n",
        "        te = r[\"metrics_test\"]\n",
        "        flat_sm.append({\n",
        "            \"test_season\": r[\"test_season\"],\n",
        "            \"train_until\": r[\"train_until\"],\n",
        "            \"acc_test\":    te[\"accuracy\"],\n",
        "            \"logloss_test\":te[\"log_loss\"],\n",
        "            \"brier_test\":  te[\"brier\"],\n",
        "            \"n_test\":      te[\"n_test\"],\n",
        "            \"wk_min\":      te[\"wk_min\"],\n",
        "            \"wk_max\":      te[\"wk_max\"],\n",
        "        })\n",
        "    pd.DataFrame(flat_sm).sort_values(\"test_season\").to_csv(\n",
        "        OUT / \"metrics_by_season_smote.csv\", index=False\n",
        "    )\n",
        "\n",
        "print(\"Guardados:\\n- outputs/eval_grid_smote.json\\n- outputs/metrics_by_season_smote.csv\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "U5vAsxnNwdSE",
        "outputId": "16ee2347-c310-4fbc-82c4-1afa125a7594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.6052631578947368, 'log_loss': 0.8793798310218244, 'brier': 0.523692392112868, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007, walk-forward por jornada) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.3494414120417446, 'brier': 0.7661194141297701, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9647718217284392, 'brier': 0.582134391362193, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008, walk-forward por jornada) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.1495529048749027, 'brier': 0.6940270060264039, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5140350877192983, 'log_loss': 0.9766692149791395, 'brier': 0.5859414553822485, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5052631578947369, 'log_loss': 1.0103624493077452, 'brier': 0.6020827559761309, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5125, 'log_loss': 0.9730329277874553, 'brier': 0.5841841986950229, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.009044728224987, 'brier': 0.5971040145487275, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9749564386011589, 'brier': 0.583167368232321, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9783782347468017, 'brier': 0.5781124855784574, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5083333333333333, 'log_loss': 0.9751847278974717, 'brier': 0.583967377715168, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012, walk-forward por jornada) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0464407705340644, 'brier': 0.6219848123946629, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9794976746216008, 'brier': 0.5860324279278233, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9971228486477329, 'brier': 0.5859234635771664, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5039473684210526, 'log_loss': 0.9818700755710192, 'brier': 0.5863903224411537, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.970422002513115, 'brier': 0.5759212004224779, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5093567251461988, 'log_loss': 0.9760204302029908, 'brier': 0.5816600917198619, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015, walk-forward por jornada) ===\n",
            "{'accuracy': 0.45526315789473687, 'log_loss': 1.019408267791883, 'brier': 0.609072054083051, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5097368421052632, 'log_loss': 0.975206772217476, 'brier': 0.5810247836174002, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 0.9914886966591454, 'brier': 0.5921446674474815, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5016746411483254, 'log_loss': 0.9743201540209397, 'brier': 0.5803731120209206, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017, walk-forward por jornada) ===\n",
            "{'accuracy': 0.46578947368421053, 'log_loss': 1.0429158819689923, 'brier': 0.6242820468852509, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5037280701754386, 'log_loss': 0.975879904764943, 'brier': 0.5809013223010673, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4, 'log_loss': 1.1046583767479627, 'brier': 0.6662653937337163, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.49858299595141703, 'log_loss': 0.9809997608146642, 'brier': 0.5842892778988256, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019, walk-forward por jornada) ===\n",
            "{'accuracy': 0.40789473684210525, 'log_loss': 1.0845882086972118, 'brier': 0.6517951035378253, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.4956766917293233, 'log_loss': 0.9835393399987066, 'brier': 0.5860707151517507, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0321666629094721, 'brier': 0.617694077437402, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.4982456140350877, 'log_loss': 0.9843751271079832, 'brier': 0.5866373891050684, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021, walk-forward por jornada) ===\n",
            "{'accuracy': 0.4631578947368421, 'log_loss': 1.039191504416154, 'brier': 0.6260655399038726, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5034539473684211, 'log_loss': 0.9851200116883061, 'brier': 0.5869814703331031, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022, walk-forward por jornada) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0435399236306386, 'brier': 0.6209486504875658, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5012383900928793, 'log_loss': 0.9872113846895132, 'brier': 0.5881998144023869, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9792553905618867, 'brier': 0.5901580888676006, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5001461988304093, 'log_loss': 0.9851707791657534, 'brier': 0.5868437108477133, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024, walk-forward por jornada) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9906024146619234, 'brier': 0.5895007033026378, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train (promedio ponderado por jornada) ===\n",
            "{'accuracy': 0.5013850415512465, 'log_loss': 0.9841414945443792, 'brier': 0.5860157980797667, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025, walk-forward por jornada) ===\n",
            "{'accuracy': 0.43333333333333335, 'log_loss': 1.0173246489644299, 'brier': 0.6160581127766295, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardados:\n",
            "- outputs/eval_grid_smote.json\n",
            "- outputs/metrics_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUnUvtBGahqH",
        "outputId": "5b3f9ba7-b83b-4471-aff3-f099fa19bd53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5013850415512465, 'log_loss': 0.9841414945443792, 'brier': 0.5860157980797667, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43333333333333335, 'log_loss': 1.0173246489644299, 'brier': 0.6160581127766295, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n"
          ]
        }
      ],
      "source": [
        "# LOCAL\n",
        "model_sm, scaler_sm, (mtr_tr_sm, mtr_te_sm), y_test_sm, y_pred_sm, y_proba_sm, idx_test_sm = \\\n",
        "    run_logreg_eval(df, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WA-02xbP30g"
      },
      "source": [
        "Con este modelo obtengo el mejor **Accuracy** (porcentaje de aciertos totales), pero esta métrica ignora como de seguras son esas esas predicciones.\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Número de aciertos}}{\\text{Número total de predicciones}}\n",
        "$$\n",
        "\n",
        "Para ello se utiliza el **Log Loss** (Cross-Entropy Loss), métrica que mide qué tan buenas son las probabilidades que predice mi modelo de clasificación. A esta métrica no solo le importa acertar la clase, sino cuán seguro está el modelo.\n",
        "\n",
        "$$\n",
        "\\text{LogLoss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} y_{ij} \\cdot \\log(p_{ij})\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $y_{ij}$ = 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "\n",
        "Tener un Log Loss alto en este caso significaría dar una probabilidad alta a la clase incorrecta, o lo que es lo mismo, dar una probabilidad baja a la clase correcta.\n",
        "\n",
        "Por último añadí también el **Brier Score**, que es una métrica que evalúa cuán cercanas están las probabilidades predichas por tu modelo respecto a la realidad, comparando la distribución de probabilidades contra la clase real (codificada en one-hot). Es como un error cuadrático medio (MSE) para probabilidades.\n",
        "\n",
        "$$\n",
        "\\text{Brier Score} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=1}^{K} (p_{ij} - y_{ij})^2\n",
        "$$\n",
        "\n",
        "donde:\n",
        "\n",
        "- $N$ es el número de ejemplos.\n",
        "- $K$ es el número de clases (en este caso 3: victoria local, empate, victoria visitante).\n",
        "- $p_{ij}$ es la probabilidad predicha por el modelo de que el ejemplo $i$ pertenezca a la clase $j$.\n",
        "- $y_{ij}$ es 1 si la clase real del ejemplo $i$ es la clase $j$, y 0 en caso contrario.\n",
        "\n",
        "Un Brier Score de 0 significa que las probabilidades dadas por el modelo son perfectas, mientras que uno del 0.66 en nuestro caso sería un modelo completamente aleatorio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKjn9DwWtgyl"
      },
      "source": [
        "## Selección de variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agXuwrpyY1A-"
      },
      "source": [
        "La función `forward_selection` implementa un algoritmo clásico de selección de variables hacia adelante (**forward feature selection**) sobre un modelo de regresión logística multiclase con escalado de variables.\n",
        "\n",
        "Va añadiendo sucesivamente la variable que mejor mejora el rendimiento del modelo (según accuracy o log_loss), una por una.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nec5nM-N88pl"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.metrics import accuracy_score, log_loss\n",
        "# import numpy as np\n",
        "\n",
        "# def forward_selection(X, y, max_features=20, scoring='accuracy'):\n",
        "#     selected_features = []\n",
        "#     remaining_features = list(X.columns)\n",
        "#     scores = []\n",
        "\n",
        "#     for i in range(min(max_features, len(remaining_features))):\n",
        "#         best_score = -np.inf if scoring == 'accuracy' else np.inf\n",
        "#         best_feature = None\n",
        "\n",
        "#         for feature in remaining_features:\n",
        "#             current_features = selected_features + [feature]\n",
        "\n",
        "#             model = make_pipeline(\n",
        "#                 StandardScaler(),\n",
        "#                 LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "#             )\n",
        "\n",
        "#             model.fit(X[current_features], y)\n",
        "#             y_pred = model.predict(X[current_features])\n",
        "#             y_proba = model.predict_proba(X[current_features])\n",
        "\n",
        "#             if scoring == 'accuracy':\n",
        "#                 score = accuracy_score(y, y_pred)\n",
        "#                 if score > best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             elif scoring == 'log_loss':\n",
        "#                 score = log_loss(y, y_proba)\n",
        "#                 if score < best_score:\n",
        "#                     best_score = score\n",
        "#                     best_feature = feature\n",
        "#             else:\n",
        "#                 raise ValueError(\"scoring debe ser 'accuracy' o 'log_loss'.\")\n",
        "\n",
        "#         if best_feature is not None:\n",
        "#             selected_features.append(best_feature)\n",
        "#             remaining_features.remove(best_feature)\n",
        "#             scores.append(best_score)\n",
        "\n",
        "#         print(f\"[{i+1}] Añadida: {best_feature} | Score: {best_score:.4f}\")\n",
        "\n",
        "#     return selected_features, scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9w77D7IQ6ORb"
      },
      "outputs": [],
      "source": [
        "# selected, scores = forward_selection(X_train, y_train, max_features=81, scoring='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94wsZYs0akpR"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "\n",
        "# # Suponemos que tienes las listas: selected (variables) y scores (métricas acumuladas)\n",
        "\n",
        "# # Calcular diferencia respecto al valor anterior\n",
        "# deltas = np.diff([0] + scores)\n",
        "# colors = ['blue' if delta >= 0 else 'red' for delta in deltas]\n",
        "\n",
        "# plt.figure(figsize=(12,6))\n",
        "# bar_width = 0.6  # Reducir ancho de barra para separarlas\n",
        "# indices = np.arange(len(selected))\n",
        "\n",
        "# plt.bar(indices, scores, color=colors, width=bar_width)\n",
        "# plt.xticks(indices, selected, rotation=90)\n",
        "# plt.xlabel('Variables añadidas')\n",
        "# plt.ylabel('Valor de la métrica')\n",
        "# plt.title('Evolución del rendimiento al añadir variables')\n",
        "\n",
        "# plt.ylim(min(scores) - 0.01, max(scores) + 0.01)\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r5Zlw7IZTRM"
      },
      "source": [
        "Se implementó un proceso de selección hacia adelante (forward selection) sobre el modelo de regresión logística con variables estandarizadas. Este procedimiento consiste en partir sin predictores y añadir, en cada iteración, la variable que mayor mejora produce en el rendimiento del modelo. Se evaluaron dos métricas complementarias como criterio de selección: el accuracy (para priorizar aciertos de clasificación) y el log loss (para priorizar la calibración de las probabilidades). Esta técnica permitió reducir la dimensionalidad del conjunto original y determinar el orden de relevancia de las variables desde el punto de vista predictivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmmpBR0ity_a"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zu7wer0OnyON"
      },
      "source": [
        "## **MATRIZ DE CONFUSIÓN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Split de TEST con tope de temporada ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Excluimos también los nombres y posibles IDs para que NO entren en X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'  # <- añadido\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    # válidas: sin NaN en y ni en X; si with_odds, exige cuotas clave\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.loc[test_mask].index  # <- AÑADIDO: índices del df original (tras el filtrado de válidos)\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Alinea X para que tenga EXACTAMENTE las columnas usadas en el fit.\n",
        "    - Usa feature_names si se proporcionan; si no, intenta fitter.feature_names_in_.\n",
        "    - Elimina columnas extra.\n",
        "    - Lanza error si faltan columnas del fit.\n",
        "    \"\"\"\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # si el scaler/model se entrenó con arrays numpy sin nombres\n",
        "\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Matriz de confusión con rango de test configurable ----------\n",
        "def plot_confusion_for_logreg(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None   # opcional: forzar lista de features del fit\n",
        "):\n",
        "    # 1) reconstruir TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # 4) plot\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = model.classes_\n",
        "    display_labels = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    ConfusionMatrixDisplay.from_predictions(\n",
        "        y_test, y_pred,\n",
        "        labels=classes_used,\n",
        "        display_labels=display_labels,\n",
        "        cmap='Blues', colorbar=False\n",
        "    )\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "\n",
        "    # --- AÑADIDO: mostrar rango de jornadas del test en el título si existe Wk ---\n",
        "    wk_txt = \"\"\n",
        "    if \"Wk\" in df.columns and len(idx_test):\n",
        "        wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "        if len(wks):\n",
        "            wk_txt = f\" | Jornadas {int(wks.min())}–{int(wks.max())}\"\n",
        "\n",
        "    plt.title(f'Confusion Matrix (Seasons {rango}){wk_txt}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- Grid de matrices por temporada (guarda JSON para la app) ----------\n",
        "def build_confusion_grid(df: pd.DataFrame, out_dir: Path, model: str = \"base\", random_state: int = 42):\n",
        "    \"\"\"\n",
        "    Genera matrices de confusión por temporada y las guarda en:\n",
        "      outputs/confusion_grid_<model>.json\n",
        "    - model: \"base\" (sin SMOTE) | \"smote\"\n",
        "    - Split: train ≤ S-1, test = S\n",
        "    - Usa with_odds=True\n",
        "    \"\"\"\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, idx_test = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            elif model == \"smote\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, idx_test = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=True,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\"model debe ser 'base' o 'smote'.\")\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # y_test / y_pred pueden venir como Series -> convertir\n",
        "            y_true = np.asarray(y_test)\n",
        "            y_hat  = np.asarray(y_pred)\n",
        "\n",
        "            cm = confusion_matrix(y_true, y_hat, labels=[0, 1, 2]).tolist()  # 0=A,1=D,2=H\n",
        "\n",
        "            # --- AÑADIDO: rango de jornadas del set de test ---\n",
        "            wk_min = wk_max = None\n",
        "            if \"Wk\" in df.columns and idx_test is not None and len(idx_test):\n",
        "                wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "                if len(wks):\n",
        "                    wk_min = int(wks.min())\n",
        "                    wk_max = int(wks.max())\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"labels\": [\"A\",\"D\",\"H\"],\n",
        "                \"matrix\": cm,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "                # ---- AÑADIDO ----\n",
        "                \"wk_min\": wk_min,\n",
        "                \"wk_max\": wk_max,\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[CONF {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_path = out_dir / f\"confusion_grid_{model}.json\"\n",
        "    out_path.write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_path}  ({len(rows)} temporadas)\")\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "# Asegúrate de tener OUT definido:\n",
        "# OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "build_confusion_grid(df, OUT, model=\"base\")\n",
        "build_confusion_grid(df, OUT, model=\"smote\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpKCrB09Oq3F",
        "outputId": "7c7c76c4-cc21-4d83-a84f-b5cf0e8bdfe3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6, 'log_loss': 0.8503040399360499, 'brier': 0.5104307269727479, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4263157894736842, 'log_loss': 1.234912538739745, 'brier': 0.7084656252008951, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5565789473684211, 'log_loss': 0.9214888832439952, 'brier': 0.552017798278286, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.0946781196370998, 'brier': 0.6514989943768685, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5482456140350878, 'log_loss': 0.9341333936534477, 'brier': 0.5582402681906519, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.531578947368421, 'log_loss': 0.9731693801920157, 'brier': 0.5740858195095201, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5486842105263158, 'log_loss': 0.9279406338478252, 'brier': 0.5543308157141086, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5842105263157895, 'log_loss': 0.9611714000747812, 'brier': 0.5600985795015131, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5673684210526316, 'log_loss': 0.92567347721971, 'brier': 0.5503509561104474, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9618637854826375, 'brier': 0.569337462696509, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5649122807017544, 'log_loss': 0.9258206035623451, 'brier': 0.5508649323751328, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5263157894736842, 'log_loss': 0.9812522610577148, 'brier': 0.5741574692017298, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5620300751879699, 'log_loss': 0.9300982185449254, 'brier': 0.5525997571886312, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9816107988614631, 'brier': 0.5792206499536022, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5588815789473685, 'log_loss': 0.932953241748893, 'brier': 0.5539945012156289, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5578947368421052, 'log_loss': 0.9533905266381169, 'brier': 0.5579255333473289, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5590643274853802, 'log_loss': 0.9302045400187785, 'brier': 0.551695173347987, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9554489087510584, 'brier': 0.5668172018067045, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.56, 'log_loss': 0.9296168555376824, 'brier': 0.5512567599140625, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9424364646555845, 'brier': 0.5572641920758349, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.562200956937799, 'log_loss': 0.9280061580011343, 'brier': 0.5499175362118004, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5368421052631579, 'log_loss': 0.9718768790598807, 'brier': 0.5759491180403586, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5622807017543859, 'log_loss': 0.9302030199327271, 'brier': 0.551172040254874, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.48947368421052634, 'log_loss': 1.0447989195979444, 'brier': 0.6239512631509635, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5562753036437247, 'log_loss': 0.9373991477942386, 'brier': 0.5558697065701285, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.4710526315789474, 'log_loss': 1.0046309623103469, 'brier': 0.60042492501783, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5513157894736842, 'log_loss': 0.941053099742395, 'brier': 0.5583159465810769, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5131578947368421, 'log_loss': 1.0027102003334487, 'brier': 0.5957333636955684, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503508771929825, 'log_loss': 0.9443762569444348, 'brier': 0.5603350753522194, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5078947368421053, 'log_loss': 1.000834198335483, 'brier': 0.5976131120685585, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9470694509392333, 'brier': 0.561971765511791, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9845858767265123, 'brier': 0.5857510525064844, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503095975232198, 'log_loss': 0.9487672055459645, 'brier': 0.56301460337696, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9526624544514743, 'brier': 0.5671253491342783, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5497076023391813, 'log_loss': 0.9484854524823103, 'brier': 0.562807791558073, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9582196819419253, 'brier': 0.5659048337474383, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5520775623268698, 'log_loss': 0.9485428490794315, 'brier': 0.5627369524063253, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.4666666666666667, 'log_loss': 0.9598671705854682, 'brier': 0.5768538551458187, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/confusion_grid_base.json  (19 temporadas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6052631578947368, 'log_loss': 0.8793798310218244, 'brier': 0.523692392112868, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.3494414120417446, 'brier': 0.7661194141297701, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9647718217284392, 'brier': 0.582134391362193, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.1495529048749027, 'brier': 0.6940270060264039, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5140350877192983, 'log_loss': 0.9766692149791395, 'brier': 0.5859414553822485, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.5052631578947369, 'log_loss': 1.0103624493077452, 'brier': 0.6020827559761309, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5125, 'log_loss': 0.9730329277874553, 'brier': 0.5841841986950229, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.009044728224987, 'brier': 0.5971040145487275, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9749564386011589, 'brier': 0.583167368232321, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9783782347468017, 'brier': 0.5781124855784574, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5083333333333333, 'log_loss': 0.9751847278974717, 'brier': 0.583967377715168, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0464407705340646, 'brier': 0.6219848123946629, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9794976746216008, 'brier': 0.5860324279278233, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9971228486477329, 'brier': 0.5859234635771664, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5039473684210526, 'log_loss': 0.9818700755710192, 'brier': 0.5863903224411537, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.970422002513115, 'brier': 0.575921200422478, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5093567251461988, 'log_loss': 0.9760204302029908, 'brier': 0.5816600917198619, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45526315789473687, 'log_loss': 1.019408267791883, 'brier': 0.609072054083051, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5097368421052632, 'log_loss': 0.975206772217476, 'brier': 0.5810247836174002, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 0.9914886966591454, 'brier': 0.5921446674474815, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5016746411483254, 'log_loss': 0.9743201540209397, 'brier': 0.5803731120209206, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46578947368421053, 'log_loss': 1.0429158819689923, 'brier': 0.6242820468852509, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5037280701754386, 'log_loss': 0.975879904764943, 'brier': 0.5809013223010673, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4, 'log_loss': 1.1046583767479627, 'brier': 0.6662653937337163, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49858299595141703, 'log_loss': 0.9809997608146642, 'brier': 0.5842892778988256, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.40789473684210525, 'log_loss': 1.0845882086972118, 'brier': 0.6517951035378253, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4956766917293233, 'log_loss': 0.9835393399987066, 'brier': 0.5860707151517507, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0321666629094723, 'brier': 0.6176940774374018, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4982456140350877, 'log_loss': 0.9843751271079832, 'brier': 0.5866373891050684, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.4631578947368421, 'log_loss': 1.039191504416154, 'brier': 0.6260655399038726, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5034539473684211, 'log_loss': 0.9851200116883061, 'brier': 0.5869814703331031, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0435399236306386, 'brier': 0.6209486504875658, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5012383900928793, 'log_loss': 0.9872113846895132, 'brier': 0.5881998144023869, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9792553905618867, 'brier': 0.5901580888676006, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5001461988304093, 'log_loss': 0.9851707791657534, 'brier': 0.5868437108477133, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9906024146619237, 'brier': 0.5895007033026378, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5013850415512465, 'log_loss': 0.9841414945443792, 'brier': 0.5860157980797667, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43333333333333335, 'log_loss': 1.0173246489644299, 'brier': 0.6160581127766295, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/confusion_grid_smote.json  (19 temporadas)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FGsY5ECG9S4E"
      },
      "outputs": [],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "# plot_confusion_for_logreg(df, model, scaler, train_until_season=2023, test_until_season=2024, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBvnqoyz-uws"
      },
      "source": [
        "## **METRICAS DE CLASIFICACIÓN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- split TEST con tope de temporada --------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Excluimos también nombres de equipo (y row_id si existiese) para que NO entren como features\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para hacer el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.loc[test_mask].index  # <- índices de las filas usadas en TEST\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# -------- alinear columnas a las usadas en el fit --------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        # si se entrenó con arrays, no hay nombres; asumimos que X ya coincide\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Asegúrate de usar el MISMO esquema (with_odds / drop_cols) que en el fit, \"\n",
        "            \"o pasa explícitamente 'feature_names' del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# -------- classification_report con rango de test configurable --------\n",
        "def print_classification_report_for_logreg(\n",
        "    df: pd.DataFrame, model, scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    digits: int = 3,\n",
        "    feature_names: list[str] | None = None   # opcional: columnas del fit\n",
        "):\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # Alinear a columnas de entrenamiento\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # Predecir\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    # Etiquetas (orden estable 0=A,1=D,2=H)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "    classes_used = [c for c in [0,1,2] if c in classes_used]\n",
        "    target_names = [class2label[c] for c in classes_used]\n",
        "\n",
        "    # Mostrar rango de jornadas si existe Wk\n",
        "    wk_txt = \"\"\n",
        "    if \"Wk\" in df.columns and len(idx_test):\n",
        "        wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "        if len(wks):\n",
        "            wk_txt = f\" | Jornadas {int(wks.min())}–{int(wks.max())}\"\n",
        "\n",
        "    rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    print(f\"[Classification report] Seasons {rango}{wk_txt}\\n\")\n",
        "\n",
        "    print(\n",
        "        classification_report(\n",
        "            y_test, y_pred,\n",
        "            labels=classes_used,\n",
        "            target_names=target_names,\n",
        "            zero_division=0,\n",
        "            digits=digits\n",
        "        )\n",
        "    )\n",
        "\n",
        "# EJECUTAR EN LOCAL\n",
        "# print_classification_report_for_logreg(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)\n",
        "\n",
        "def build_classification_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",       # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,    # como acordamos para la app\n",
        "    random_state: int = 42\n",
        "):\n",
        "    \"\"\"\n",
        "    Exporta métricas de clasificación por temporada (train ≤ S-1, test = S).\n",
        "    Guarda: outputs/classification_grid_<model>.json\n",
        "            outputs/classification_by_season_<model>.csv (resumen tabular)\n",
        "    \"\"\"\n",
        "    from sklearn.metrics import classification_report\n",
        "\n",
        "    label_name = {0:\"A\", 1:\"D\", 2:\"H\"}  # tu codificación\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, idx_test = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                _, _, (_, mtr_te), y_test, y_pred, _, idx_test = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Orden de clases estable basado en el modelo (0,1,2)\n",
        "            classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "            classes_used = [c for c in [0,1,2] if c in classes_used]\n",
        "            target_names = [label_name[c] for c in classes_used]\n",
        "\n",
        "            rep = classification_report(\n",
        "                y_test, y_pred,\n",
        "                labels=classes_used,\n",
        "                target_names=target_names,\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "\n",
        "            per_class = {}\n",
        "            for c in classes_used:\n",
        "                nm = label_name[c]\n",
        "                if nm in rep:\n",
        "                    per_class[nm] = {\n",
        "                        \"precision\": float(rep[nm][\"precision\"]),\n",
        "                        \"recall\":    float(rep[nm][\"recall\"]),\n",
        "                        \"f1\":        float(rep[nm][\"f1-score\"]),\n",
        "                        \"support\":   int(rep[nm][\"support\"]),\n",
        "                    }\n",
        "\n",
        "            # --- AÑADIDO: rango de jornadas del set de test ---\n",
        "            wk_min = wk_max = None\n",
        "            if \"Wk\" in df.columns and idx_test is not None and len(idx_test):\n",
        "                wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "                if len(wks):\n",
        "                    wk_min = int(wks.min())\n",
        "                    wk_max = int(wks.max())\n",
        "\n",
        "            overall = {\n",
        "                \"accuracy\":     float(rep.get(\"accuracy\", mtr_te.get(\"accuracy\", float(\"nan\")))),\n",
        "                \"macro_avg\": {\n",
        "                    \"precision\": float(rep[\"macro avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"macro avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"macro avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"macro avg\"][\"support\"]),\n",
        "                },\n",
        "                \"weighted_avg\": {\n",
        "                    \"precision\": float(rep[\"weighted avg\"][\"precision\"]),\n",
        "                    \"recall\":    float(rep[\"weighted avg\"][\"recall\"]),\n",
        "                    \"f1\":        float(rep[\"weighted avg\"][\"f1-score\"]),\n",
        "                    \"support\":   int(rep[\"weighted avg\"][\"support\"]),\n",
        "                },\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "                # ---- AÑADIDO ----\n",
        "                \"wk_min\": wk_min,\n",
        "                \"wk_max\": wk_max,\n",
        "            }\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,\n",
        "                \"overall\": overall,\n",
        "            })\n",
        "\n",
        "            row_flat = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"accuracy\": overall[\"accuracy\"],\n",
        "                \"macro_f1\": overall[\"macro_avg\"][\"f1\"],\n",
        "                \"n_test\": overall[\"n_test\"],\n",
        "                # ---- AÑADIDO ----\n",
        "                \"wk_min\": overall[\"wk_min\"],\n",
        "                \"wk_max\": overall[\"wk_max\"],\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    row_flat[f\"precision_{nm}\"] = per_class[nm][\"precision\"]\n",
        "                    row_flat[f\"recall_{nm}\"]    = per_class[nm][\"recall\"]\n",
        "                    row_flat[f\"f1_{nm}\"]        = per_class[nm][\"f1\"]\n",
        "                    row_flat[f\"support_{nm}\"]   = per_class[nm][\"support\"]\n",
        "            flat.append(row_flat)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[CLASS {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (out_dir / f\"classification_grid_{model}.json\").write_text(\n",
        "        json.dumps(rows, ensure_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(f\"Guardado: {out_dir / f'classification_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(\n",
        "            out_dir / f\"classification_by_season_{model}.csv\", index=False\n",
        "        )\n",
        "        print(f\"Guardado: {out_dir / f'classification_by_season_{model}.csv'}\")\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Modelo base (sin SMOTE)\n",
        "build_classification_grid(df, OUT, model=\"base\", with_odds=True)\n",
        "\n",
        "# También SMOTE:\n",
        "build_classification_grid(df, OUT, model=\"smote\", with_odds=True)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrU2RlMGQh4m",
        "outputId": "d573beba-f785-4481-cbba-fd076b676464"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6, 'log_loss': 0.8503040399360499, 'brier': 0.5104307269727479, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4263157894736842, 'log_loss': 1.234912538739745, 'brier': 0.7084656252008951, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5565789473684211, 'log_loss': 0.9214888832439952, 'brier': 0.552017798278286, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.0946781196370998, 'brier': 0.6514989943768685, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5482456140350878, 'log_loss': 0.9341333936534477, 'brier': 0.5582402681906519, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.531578947368421, 'log_loss': 0.9731693801920157, 'brier': 0.5740858195095201, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5486842105263158, 'log_loss': 0.9279406338478252, 'brier': 0.5543308157141086, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5842105263157895, 'log_loss': 0.9611714000747812, 'brier': 0.5600985795015131, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5673684210526316, 'log_loss': 0.92567347721971, 'brier': 0.5503509561104474, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9618637854826375, 'brier': 0.569337462696509, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5649122807017544, 'log_loss': 0.9258206035623451, 'brier': 0.5508649323751328, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5263157894736842, 'log_loss': 0.9812522610577148, 'brier': 0.5741574692017298, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5620300751879699, 'log_loss': 0.9300982185449254, 'brier': 0.5525997571886312, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9816107988614631, 'brier': 0.5792206499536022, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5588815789473685, 'log_loss': 0.932953241748893, 'brier': 0.5539945012156289, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5578947368421052, 'log_loss': 0.9533905266381169, 'brier': 0.5579255333473289, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5590643274853802, 'log_loss': 0.9302045400187785, 'brier': 0.551695173347987, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9554489087510584, 'brier': 0.5668172018067045, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.56, 'log_loss': 0.9296168555376824, 'brier': 0.5512567599140625, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9424364646555845, 'brier': 0.5572641920758349, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.562200956937799, 'log_loss': 0.9280061580011343, 'brier': 0.5499175362118004, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5368421052631579, 'log_loss': 0.9718768790598807, 'brier': 0.5759491180403586, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5622807017543859, 'log_loss': 0.9302030199327271, 'brier': 0.551172040254874, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.48947368421052634, 'log_loss': 1.0447989195979444, 'brier': 0.6239512631509635, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5562753036437247, 'log_loss': 0.9373991477942386, 'brier': 0.5558697065701285, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.4710526315789474, 'log_loss': 1.0046309623103469, 'brier': 0.60042492501783, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5513157894736842, 'log_loss': 0.941053099742395, 'brier': 0.5583159465810769, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5131578947368421, 'log_loss': 1.0027102003334487, 'brier': 0.5957333636955684, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503508771929825, 'log_loss': 0.9443762569444348, 'brier': 0.5603350753522194, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5078947368421053, 'log_loss': 1.000834198335483, 'brier': 0.5976131120685585, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9470694509392333, 'brier': 0.561971765511791, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9845858767265123, 'brier': 0.5857510525064844, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503095975232198, 'log_loss': 0.9487672055459645, 'brier': 0.56301460337696, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9526624544514743, 'brier': 0.5671253491342783, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5497076023391813, 'log_loss': 0.9484854524823103, 'brier': 0.562807791558073, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9582196819419253, 'brier': 0.5659048337474383, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5520775623268698, 'log_loss': 0.9485428490794315, 'brier': 0.5627369524063253, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.4666666666666667, 'log_loss': 0.9598671705854682, 'brier': 0.5768538551458187, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/classification_grid_base.json  (19 temporadas)\n",
            "Guardado: outputs/classification_by_season_base.csv\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6052631578947368, 'log_loss': 0.8793798310218244, 'brier': 0.523692392112868, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.3494414120417446, 'brier': 0.7661194141297701, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9647718217284392, 'brier': 0.582134391362193, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.1495529048749027, 'brier': 0.6940270060264039, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5140350877192983, 'log_loss': 0.9766692149791395, 'brier': 0.5859414553822485, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.5052631578947369, 'log_loss': 1.0103624493077452, 'brier': 0.6020827559761309, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5125, 'log_loss': 0.9730329277874553, 'brier': 0.5841841986950229, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.009044728224987, 'brier': 0.5971040145487275, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9749564386011589, 'brier': 0.583167368232321, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9783782347468017, 'brier': 0.5781124855784574, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5083333333333333, 'log_loss': 0.9751847278974717, 'brier': 0.583967377715168, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0464407705340646, 'brier': 0.6219848123946629, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9794976746216008, 'brier': 0.5860324279278233, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9971228486477329, 'brier': 0.5859234635771664, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5039473684210526, 'log_loss': 0.9818700755710192, 'brier': 0.5863903224411537, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.970422002513115, 'brier': 0.575921200422478, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5093567251461988, 'log_loss': 0.9760204302029908, 'brier': 0.5816600917198619, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45526315789473687, 'log_loss': 1.019408267791883, 'brier': 0.609072054083051, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5097368421052632, 'log_loss': 0.975206772217476, 'brier': 0.5810247836174002, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 0.9914886966591454, 'brier': 0.5921446674474815, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5016746411483254, 'log_loss': 0.9743201540209397, 'brier': 0.5803731120209206, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46578947368421053, 'log_loss': 1.0429158819689923, 'brier': 0.6242820468852509, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5037280701754386, 'log_loss': 0.975879904764943, 'brier': 0.5809013223010673, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4, 'log_loss': 1.1046583767479627, 'brier': 0.6662653937337163, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49858299595141703, 'log_loss': 0.9809997608146642, 'brier': 0.5842892778988256, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.40789473684210525, 'log_loss': 1.0845882086972118, 'brier': 0.6517951035378253, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4956766917293233, 'log_loss': 0.9835393399987066, 'brier': 0.5860707151517507, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0321666629094723, 'brier': 0.6176940774374018, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4982456140350877, 'log_loss': 0.9843751271079832, 'brier': 0.5866373891050684, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.4631578947368421, 'log_loss': 1.039191504416154, 'brier': 0.6260655399038726, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5034539473684211, 'log_loss': 0.9851200116883061, 'brier': 0.5869814703331031, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0435399236306386, 'brier': 0.6209486504875658, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5012383900928793, 'log_loss': 0.9872113846895132, 'brier': 0.5881998144023869, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9792553905618867, 'brier': 0.5901580888676006, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5001461988304093, 'log_loss': 0.9851707791657534, 'brier': 0.5868437108477133, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9906024146619237, 'brier': 0.5895007033026378, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5013850415512465, 'log_loss': 0.9841414945443792, 'brier': 0.5860157980797667, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43333333333333335, 'log_loss': 1.0173246489644299, 'brier': 0.6160581127766295, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "Guardado: outputs/classification_grid_smote.json  (19 temporadas)\n",
            "Guardado: outputs/classification_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8foJ4svkocU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25135e84-60d9-4933-b835-8c2963004575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Classification report] Seasons 2025..2025 | Jornadas 0–0\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Away      0.467     0.467     0.467        15\n",
            "        Draw      0.303     0.556     0.392        18\n",
            "        Home      0.750     0.333     0.462        27\n",
            "\n",
            "    accuracy                          0.433        60\n",
            "   macro avg      0.507     0.452     0.440        60\n",
            "weighted avg      0.545     0.433     0.442        60\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "print_classification_report_for_logreg(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_-8dbe3DuYD"
      },
      "source": [
        "## **AUC Y CURVA ROC**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Split de TEST con tope de temporada (devuelve idx_test para jornadas) ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Excluir nombres de equipo/ids para que NO entren como features\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask  = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.loc[test_mask].index  # <- para jornadas\n",
        "    X_test = X_all.loc[test_mask].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[test_mask]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Alinear columnas de X a las usadas en el fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X  # entrenaste con arrays; asumimos que X ya coincide\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta de columnas del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Curvas ROC multiclase (muestra rango de jornadas del TEST) ----------\n",
        "def plot_multiclass_roc(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    feature_names: list[str] | None = None\n",
        "):\n",
        "    import matplotlib.pyplot as plt  # lazy import\n",
        "\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rango = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rango}).\")\n",
        "        return\n",
        "\n",
        "    # 2) Alinear columnas a las del fit\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "\n",
        "    # 3) Probabilidades\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    y_proba = model.predict_proba(X_test_scaled)\n",
        "\n",
        "    # 4) Binarización y etiquetas (usa SIEMPRE el orden real del modelo)\n",
        "    classes_used = list(getattr(model, \"classes_\", [0,1,2]))\n",
        "    y_bin = label_binarize(y_test, classes=classes_used)\n",
        "    class2label = {0:'Away', 1:'Draw', 2:'Home'}\n",
        "    labels_text = [class2label.get(c, str(c)) for c in classes_used]\n",
        "\n",
        "    # Título con rango de jornadas si existe Wk\n",
        "    wk_txt = \"\"\n",
        "    if \"Wk\" in df.columns and len(idx_test):\n",
        "        wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "        if len(wks):\n",
        "            wk_txt = f\" | Jornadas {int(wks.min())}–{int(wks.max())}\"\n",
        "\n",
        "    # 5) Curvas por clase\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    auc_per_class, weights = [], []\n",
        "    n = len(y_test)\n",
        "\n",
        "    for k, cls in enumerate(classes_used):\n",
        "        y_true_k = y_bin[:, k]\n",
        "        y_score_k = y_proba[:, k]\n",
        "        pos = int(y_true_k.sum())\n",
        "        neg = n - pos\n",
        "        if pos > 0 and neg > 0:\n",
        "            fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "            auc_k = roc_auc_score(y_true_k, y_score_k)\n",
        "            auc_per_class.append(auc_k)\n",
        "            weights.append(pos)\n",
        "            plt.plot(fpr, tpr, label=f\"{labels_text[k]} (AUC = {auc_k:.2f})\")\n",
        "        else:\n",
        "            print(f\"Nota: '{labels_text[k]}' no tiene suficientes positivos/negativos en TEST; omito su curva.\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    rango = (f\"{train_until_season+1}..{test_until_season}\"\n",
        "             if test_until_season is not None else f\">{train_until_season}\")\n",
        "    plt.title(f\"Curvas ROC por clase (Seasons {rango}){wk_txt}\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 6) AUC macro y weighted\n",
        "    if auc_per_class:\n",
        "        auc_macro = float(np.mean(auc_per_class))\n",
        "        auc_weighted = float(np.average(auc_per_class, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "        print(f\"\\nAUC macro: {auc_macro:.3f}\")\n",
        "        print(f\"AUC weighted: {auc_weighted:.3f}\")\n",
        "    else:\n",
        "        print(\"\\nNo se pudieron calcular AUCs (todas las clases carecen de positivos/negativos suficientes en TEST).\")\n",
        "\n",
        "# === Util para reducir puntos en curvas guardadas ===\n",
        "def _downsample_curve(x: np.ndarray, y: np.ndarray, max_points: int = 200):\n",
        "    if len(x) <= max_points:\n",
        "        return x.tolist(), y.tolist()\n",
        "    idx = np.linspace(0, len(x) - 1, max_points).round().astype(int)\n",
        "    return x[idx].tolist(), y[idx].tolist()\n",
        "\n",
        "# === ROC por temporada (train ≤ S-1, test = S) → outputs/roc_grid_<modelo>.json ===\n",
        "def build_roc_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    model: str = \"base\",        # \"base\" (sin SMOTE) | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    max_points: int = 200       # nº máx. de puntos por curva guardada\n",
        "):\n",
        "    label_name = {0: \"A\", 1: \"D\", 2: \"H\"}  # tu codificación 0/1/2\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    rows = []\n",
        "    flat = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval_no_smote(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval(\n",
        "                    df,\n",
        "                    train_until_season=train_until,\n",
        "                    test_until_season=test_season,\n",
        "                    with_odds=with_odds,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Orden REAL de columnas en y_proba:\n",
        "            classes_used = list(getattr(mdl, \"classes_\", [0,1,2]))\n",
        "\n",
        "            # Curvas por clase (si hay positivos y negativos)\n",
        "            y_bin = label_binarize(y_test, classes=classes_used)\n",
        "            per_class = {}\n",
        "            aucs, weights = [], []\n",
        "\n",
        "            for k, cls in enumerate(classes_used):\n",
        "                nm = label_name.get(cls, str(cls))\n",
        "                y_true_k = y_bin[:, k]\n",
        "                y_score_k = y_proba[:, k]\n",
        "                pos = int(y_true_k.sum())\n",
        "                neg = int(len(y_true_k) - pos)\n",
        "                if pos > 0 and neg > 0:\n",
        "                    fpr, tpr, _ = roc_curve(y_true_k, y_score_k)\n",
        "                    auc_k = float(roc_auc_score(y_true_k, y_score_k))\n",
        "                    fpr_l, tpr_l = _downsample_curve(fpr, tpr, max_points=max_points)\n",
        "                    per_class[nm] = {\n",
        "                        \"auc\": auc_k,\n",
        "                        \"support_pos\": pos,\n",
        "                        \"fpr\": fpr_l,\n",
        "                        \"tpr\": tpr_l,\n",
        "                    }\n",
        "                    aucs.append(auc_k)\n",
        "                    weights.append(pos)\n",
        "\n",
        "            if not per_class:\n",
        "                continue\n",
        "\n",
        "            auc_macro = float(np.mean(aucs))\n",
        "            auc_weighted = float(np.average(aucs, weights=weights)) if sum(weights) > 0 else auc_macro\n",
        "\n",
        "            # --- Añadir rango de jornadas del set de test ---\n",
        "            wk_min = wk_max = None\n",
        "            if \"Wk\" in df.columns and idx_test is not None and len(idx_test):\n",
        "                wks = pd.to_numeric(df.loc[idx_test, \"Wk\"], errors=\"coerce\").dropna().astype(int)\n",
        "                if len(wks):\n",
        "                    wk_min = int(wks.min())\n",
        "                    wk_max = int(wks.max())\n",
        "\n",
        "            rows.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"per_class\": per_class,     # dict con A/D/H presentes\n",
        "                \"overall\": {\n",
        "                    \"auc_macro\": auc_macro,\n",
        "                    \"auc_weighted\": auc_weighted,\n",
        "                    \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "                    \"wk_min\": wk_min,       # <-- jornada\n",
        "                    \"wk_max\": wk_max,       # <-- jornada\n",
        "                }\n",
        "            })\n",
        "\n",
        "            # fila plana para CSV (útil en tablas)\n",
        "            rowf = {\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"auc_macro\": auc_macro,\n",
        "                \"auc_weighted\": auc_weighted,\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "                \"wk_min\": wk_min,          # <-- jornada\n",
        "                \"wk_max\": wk_max,          # <-- jornada\n",
        "            }\n",
        "            for nm in [\"A\",\"D\",\"H\"]:\n",
        "                if nm in per_class:\n",
        "                    rowf[f\"auc_{nm}\"] = per_class[nm][\"auc\"]\n",
        "                    rowf[f\"support_pos_{nm}\"] = per_class[nm][\"support_pos\"]\n",
        "            flat.append(rowf)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ROC {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    (out_dir / f\"roc_grid_{model}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    print(f\"Guardado: {out_dir / f'roc_grid_{model}.json'}  ({len(rows)} temporadas)\")\n",
        "\n",
        "    if flat:\n",
        "        pd.DataFrame(flat).sort_values(\"test_season\").to_csv(out_dir / f\"roc_by_season_{model}.csv\", index=False)\n",
        "        print(f\"Guardado: {out_dir / f'roc_by_season_{model}.csv'}\")\n",
        "\n",
        "# --- EJECUCIÓN ---\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "build_roc_grid(df, OUT, model=\"base\",  with_odds=True)\n",
        "build_roc_grid(df, OUT, model=\"smote\", with_odds=True)"
      ],
      "metadata": {
        "id": "_Btx8f9iUOHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "izcriACtp027",
        "outputId": "4031643c-5a91-412c-bf24-1ec8d89eea58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAArSpJREFUeJzs3XVck9sfB/DPGBtslKKUigKKgRjYjQl2XLtAVEyMa2F3e1VsrwoGdl31WoiBiYnYcU0sxKIHq/P7gx/TOWqwMeL7fr14KWfneZ7vs2cb351znnM4jDEGQgghhBCS7+npOgBCCCGEEKIZlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRQgghhBQQlNgRUkCEhISAw+EgJCRE16Gka//+/TA3N0d8fLyuQyEky3r16oUePXpkuf62bdvA4XC0GFHeYWdnhwEDBug6DPILSuzykJcvX2Lo0KFwcHCAoaEhTE1N0bBhQ6xatQoikUjX4WnF7NmzweFwFD88Hg92dnYYPXo0oqOj09xGIpFg9erVqF27NkxMTGBsbIzatWtj9erVkEgkaW4jk8mwdetWNG3aFObm5jAwMICdnR28vLxw+/ZtLZ4hSSWTyTBr1iyMGjUKxsbGinKxWIxVq1bBxcUFpqamKFKkCCpXrowhQ4bg6dOnOow4bzl8+DB69uwJBwcHCIVCVKhQAePHj0/3fXLs2DHUqFEDhoaGKF26NGbNmgWpVKpU59y5cxg4cCDKly8PoVAIBwcHDB48GJ8+fVLZX9OmTZXeq6k/rVu3ztb5JCYmYt26dXBzc4ONjQ1MTEzg4uKCDRs2QCaTqdSXy+VYunQp7O3tYWhoiKpVq2LPnj0qdbZt24aOHTvC1tYWRkZGcHZ2xvz585GUlKSyz7TOh8PhYPHixUr1fH19cejQIdy7dy9b55oRDocDHx8fje+3oPP390elSpVgaGgIR0dHrFmzJlv7ycrrKr/R13UAJMWJEyfQvXt3GBgYwMPDA87OzhCLxbhy5QomTpyIR48eYdOmTboOU2s2bNgAY2NjJCQk4Ny5c1izZg3CwsJw5coVpXoJCQlo164dLl68iPbt22PAgAHQ09PD6dOnMWbMGBw+fBgnTpyAkZGRYhuRSIQ//vgDp0+fRpMmTTB16lSYm5vjzZs32L9/P7Zv346IiAiUKlUqt0+7UPn333/x7NkzDBkyRKm8a9euOHXqFHr37g1vb29IJBI8ffoUx48fR4MGDVCxYkUdRZy3DBkyBCVKlEC/fv1QunRpPHjwAGvXrsXJkycRFhYGgUCgqHvq1Cl07twZTZs2xZo1a/DgwQPMnz8fUVFR2LBhg6Ker68vvn//ju7du8PR0RGvXr3C2rVrcfz4cYSHh8Pa2lophlKlSmHRokVKZSVKlMjW+bx69QqjRo1CixYtMG7cOJiamiIoKAgjRozA9evXsX37dqX606ZNw+LFi+Ht7Y3atWvj6NGj6NOnDzgcDnr16gUgJVn08vJCvXr1MGzYMFhaWiI0NBSzZs3CuXPncP78eZWWtFatWsHDw0OpzMXFReX3WrVqYfny5dixY0e2zpdozt9//41hw4aha9euGDduHC5fvozRo0cjMTERvr6+au0rK6+rfIcRnXv16hUzNjZmFStWZB8/flR5/L///mN+fn4aOVZ8fLxG9qMps2bNYgDYly9flMp79uzJALAbN24olQ8ZMoQBYGvWrFHZ19q1axkANmzYMKXykSNHMgBs5cqVKttIpVK2bNky9u7du5yfTA7l9NpcuHCBAWAXLlzQTEAa1rFjR9aoUSOlsps3bzIAbMGCBSr1pVIp+/r1a26Fl+eldV23b9/OALDNmzcrlTs5ObFq1aoxiUSiKJs2bRrjcDjsyZMnirKLFy8ymUymtO3FixcZADZt2jSlcldXV1a5cmUNnEmKL1++sIcPH6qUe3l5MQDsv//+U5S9f/+e8Xg8NnLkSEWZXC5njRs3ZqVKlWJSqZQxxlhycjK7evWqyj7nzJnDALDg4GClcgBK+8zIX3/9xYyMjFhcXFymdbdu3cqy+udVnRgyI5FIWHJyskb2lVVlypRhnp6euXa8xMREVqxYMdauXTul8r59+zIjIyP2/fv3LO8rq6+r/IYSuzxg2LBhDECaH0i/e/36NQPAtm7dqvIYADZr1izF76lJ06NHj1jv3r1ZkSJFWPXq1dmyZcsYAPbmzRuVfUyePJnxeDzFm+PSpUusW7duzNbWlvH5fFaqVCk2duxYlpiYqLTdp0+f2IABA1jJkiUZn89n1tbWrGPHjuz169cZnk96iV1qkrZ7925F2bt37xiXy2XNmzdPd3/NmjVj+vr6ikTt3bt3TF9fn7Vq1SrDODKSmjDt3buXTZkyhVlZWTGhUMg6dOjAIiIiVOrv37+f1ahRgxkaGrJixYqxvn37svfv3yvV8fT0ZEZGRuzFixesTZs2zNjYmHXq1CnDON6/f88GDhzIbGxsGJ/PZ3Z2dmzYsGGKD/K0EjtNX7+TJ0+yRo0aMaFQyIyNjVnbtm3T/OP8O5FIxPh8Pps9e7ZS+Z49exgAFhISkuk+Up8DLy8vZmlpyfh8PnNycmL+/v5KdZKTk9mMGTNYjRo1mKmpKRMKhaxRo0bs/PnzKvvbs2cPq1GjBjM2NmYmJibM2dlZ5UvUy5cvWbdu3VjRokWZQCBgdevWZcePH1eqk/rc79u3j82fP5+VLFmSGRgYsObNmyslKIwx9vz5c/bHH38wKysrZmBgwEqWLMl69uzJoqOjs/Qc/Co2NpYBYOPGjVOUPXr0iAFg69atU6r74cMHBoDNmzcv0/2am5uzP/74Q6ksNbGTSCRZSm6y69ixYwwAO3bsmKJs3bp1is+yX+3evZsBYJcvX85wn/fv32cA2OrVq5XKU5OqxMREJhKJMtzHvXv3GAB2+PDhTM8hp4nd58+f2cCBA5mlpSUzMDBgVatWZdu2bVOqk/q3YNmyZWzlypXMwcGB6enpsbt37yo+V//77z/m6enJzMzMmKmpKRswYABLSEhQ2k9AQABr1qwZs7CwYHw+n1WqVImtX79eJU65XM7mzZvHSpYsyQQCAWvatCl7+PChSmL37ds3Nn78eObs7MyMjIyYiYkJa926NQsPD1fZ5+rVq5mTkxMTCASsSJEirGbNmmzXrl0ZPl8nTpxgANiJEyeUyq9du8YAsMDAwAy3/1VOX1d5FXXF5gH//vsvHBwc0KBBA63sP7WbZeHChWCMoX379pg0aRL279+PiRMnKtXdv38/3NzcULRoUQDAgQMHkJiYiOHDh6NYsWK4efMm1qxZg/fv3+PAgQOK7bp27YpHjx5h1KhRsLOzQ1RUFIKDgxEREQE7Ozu1Y37z5g0AKOIAUrqXZDKZSrfJrzw8PHDhwgWcPn0agwcPxqlTpyCVStG/f3+1Y/jdggULwOFw4Ovri6ioKPj5+aFly5YIDw9XdINt27YNXl5eqF27NhYtWoTPnz9j1apVuHr1Ku7evYsiRYoo9ieVSuHu7o5GjRrhr7/+glAoTPfYHz9+RJ06dRAdHY0hQ4agYsWK+PDhAw4ePIjExETw+fw0t9Pk9QsMDISnpyfc3d2xZMkSJCYmYsOGDWjUqBHu3r2b4XW+c+cOxGIxatSooVRepkwZAMCuXbvQsGFD6Oun/5H0+fNn1KtXTzEmycLCAqdOncKgQYMQGxuLsWPHAgBiY2OxZcsWRdduXFwc/P394e7ujps3b6J69eoAgODgYPTu3RstWrTAkiVLAABPnjzB1atXMWbMGMUxGzRogMTERIwePRrFihXD9u3b0bFjRxw8eBBdunRRinHx4sXQ09PDhAkTEBMTg6VLl6Jv3764ceMGgJTxhO7u7khOTsaoUaNgbW2NDx8+4Pjx44iOjoaZmVm655+WyMhIAEDx4sUVZXfv3gUA1KpVS6luiRIlUKpUKcXj6YmPj0d8fLzSPlM9f/4cRkZGEIvFsLKygre3N2bOnAkej6dW3BlJ75yMjIxQqVIlpbp16tRRPN6oUSO19plq27ZtWL9+PRhjqFSpEqZPn44+ffqo1HNycoJAIMDVq1dVrrsmiUQiNG3aFC9evICPjw/s7e1x4MABDBgwANHR0YrXZqqtW7ciKSkJQ4YMgYGBAczNzRWP9ejRA/b29li0aBHCwsKwZcsWWFpaKl7vQMowmMqVK6Njx47Q19fHv//+ixEjRkAul2PkyJGKejNnzsT8+fPRtm1btG3bFmFhYXBzc4NYLFaK59WrVzhy5Ai6d+8Oe3t7fP78GX///TdcXV3x+PFjRdf95s2bMXr0aHTr1g1jxoxBUlIS7t+/jxs3bqT5/KdK7/Vds2ZN6Onp4e7du+jXr1+Wnuucvq7yLF1nloVdTEwMA5Bpa02q7LTY9e7dW6Vu/fr1Wc2aNZXKUrvFduzYoSj7vWWHMcYWLVrEOBwOe/v2LWOMsR8/fii+OaorNcZnz56xL1++sDdv3rCAgAAmEAiYhYWF0rfLsWPHMgDs7t276e4vLCxMqQXjzz//zHSbzKS2xpQsWZLFxsYqyvfv388AsFWrVjHGGBOLxczS0pI5Ozsrffs/fvw4A8BmzpypKPP09GQA2OTJk7MUg4eHB9PT02O3bt1SeUwulyvF+WuLnaauX1xcHCtSpAjz9vZWKo+MjGRmZmYq5b/bsmULA8AePHigErurqysDwKysrFjv3r3ZunXrFLH9atCgQczGxkale7ZXr17MzMxMca5SqVSlO+rHjx/MysqKDRw4UFE2ZswYZmpqmmF3S+pr7tdv7nFxccze3p7Z2dkpujFTn/tKlSopHXvVqlVK53337l0GgB04cCDD5yurBg0axLhcLnv+/LmiLLVFPq3W5Nq1a7N69epluM958+YxAOzcuXNK5QMHDmSzZ89mhw4dYjt27GAdO3ZkAFiPHj00ci6MpbS2Ojk5MXt7e6Vu5Hbt2jEHBweV+gkJCVl6H7Vs2ZKZmpqyHz9+KJU3aNCA+fn5saNHj7INGzYwZ2dnBiDNFivGGCtfvjxr06ZNpueRkxY7Pz8/BoDt3LlTUSYWi1n9+vWZsbGx4jMo9W+Bqakpi4qKUtpn6ufqr693xhjr0qULK1asmFJZWp8R7u7uSs93VFQU4/P5rF27dorPG8YYmzp1KgOg1GKXlJSk0r3/+vVrZmBgwObOnaso69SpU7a69keOHMm4XG6aj1lYWLBevXpleV85fV3lVXRXrI7FxsYCAExMTLR2jGHDhqmU9ezZE3fu3MHLly8VZfv27YOBgQE6deqkKPt1QHZCQgK+fv2KBg0agDGm+OYkEAjA5/MREhKCHz9+ZCvGChUqwMLCAnZ2dhg4cCDKlSuHU6dOKbVixcXFAcj4uUp9LPV51eTz6+HhobSfbt26wcbGBidPngQA3L59G1FRURgxYgQMDQ0V9dq1a4eKFSvixIkTKvscPnx4pseVy+U4cuQIOnTooPItFUCG0ypo6voFBwcjOjoavXv3xtevXxU/XC4XdevWxYULFzI8h2/fvgFQboFNjT0oKAjz589H0aJFsWfPHowcORJlypRBz549FXd8MsZw6NAhdOjQAYwxpRjc3d0RExODsLAwAACXy1W0YMrlcnz//h1SqRS1atVS1AGAIkWKICEhAcHBwenGffLkSdSpU0fpW7uxsTGGDBmCN2/e4PHjx0r1vby8lFpPGzduDCClFQOAokUuKCgIiYmJGT5nmdm9ezf8/f0xfvx4ODo6KspT76A3MDBQ2cbQ0DDDO+wvXbqEOXPmoEePHmjevLnSY/7+/pg1axb++OMP9O/fH0ePHoW3tzf279+P69ev5+hcUvn4+ODx48dYu3atUuutSCRK93xSH0/PwoULcfbsWSxevFipxRyAonW2Y8eOGDZsGO7cuQNnZ2dMnTo1zX0WLVoUX79+zebZZc3JkydhbW2N3r17K8p4PB5Gjx6N+Ph4XLx4Ual+165dYWFhkea+fv/sb9y4Mb59+6b4XASUPyNiYmLw9etXuLq64tWrV4iJiQEAnD17FmKxGKNGjVL6vEltJf+VgYEB9PRSUguZTIZv377B2NgYFSpUUHn/vX//Hrdu3crsKVEiEonS7aHI7PWd1r6y+7rKyyix0zFTU1MAP5MWbbC3t1cp6969O/T09LBv3z4AKX84Dxw4gDZt2ihiAoCIiAgMGDAA5ubmMDY2hoWFBVxdXQFA8aY3MDDAkiVLcOrUKVhZWaFJkyZYunSpovsjKw4dOoTg4GDs3r0b9erVQ1RUlNIHDvAzOcvoufo9+dPk8/vrH08gJSkpV66cotv47du3AFKS1N9VrFhR8XgqfX39LN2J++XLF8TGxsLZ2VntmDV1/f777z8AQPPmzWFhYaH0c+bMGURFRWUpHsaYSpmBgQGmTZuGJ0+e4OPHj9izZw/q1auH/fv3K6aB+PLlC6Kjo7Fp0yaV43t5eQGAUgzbt29H1apVYWhoiGLFisHCwgInTpxQnDMAjBgxAuXLl0ebNm1QqlQpDBw4EKdPn1aK7e3bt2lez9Sum9+vaenSpZV+T01kUxNme3t7jBs3Dlu2bEHx4sXh7u6OdevWKcWVFZcvX8agQYPg7u6OBQsWKD2W+r5JTk5W2S4pKUnlfZXq6dOn6NKlC5ydnbFly5YsxTF+/HgAKX/4c2rZsmXYvHkz5s2bh7Zt2yo9JhAI0j2f1MfTsm/fPkyfPh2DBg3K0pcoPp8PHx8fREdH486dOyqPM8a0Pj/d27dv4ejoqEiOUqX3mkvr8z1VZq9HICW5bdmyJYyMjFCkSBFYWFhg6tSpAH5+RqQe8/fPQAsLC5Uva3K5HCtXroSjoyMMDAxQvHhxWFhY4P79+0qvc19fXxgbG6NOnTpwdHTEyJEjcfXq1XTPJZVAIFDp/k316+s7Pj4ekZGRaf6kbp/d11VeR4mdjpmamqJEiRJ4+PBhluqn96GS1rxPqdJ6cZYoUQKNGzfG/v37AQDXr19HREQEevbsqbTPVq1a4cSJE/D19cWRI0cQHByMbdu2AUh5A6caO3Ysnj9/jkWLFsHQ0BAzZsxApUqVMh3Pk6pJkyZo2bIlevfujeDgYAgEAvTt21fpGKkfbPfv3093P6mPOTk5AYBiqowHDx5kKY7c9Os3W23Q5PVLrRsYGIjg4GCVn6NHj2YYS7FixQAg0xZdGxsb9OrVC5cuXYKjoyP2798PqVSqOH6/fv3SPH5wcDAaNmwIANi5cycGDBiAsmXLwt/fH6dPn0ZwcDCaN2+udM6WlpYIDw/HsWPH0LFjR1y4cAFt2rSBp6enGs+yMi6Xm2b5rwnt8uXLcf/+fUWr0OjRo1G5cmW8f/8+S8e4d+8eOnbsCGdnZxw8eFBlXKKNjQ0ApDkX3adPn9KcnuTdu3dwc3ODmZkZTp48meUWbltbWwDA9+/fs1Q/Pdu2bYOvry+GDRuG6dOnqzxuY2ODyMhIlS8GqeeY1jkFBwfDw8MD7dq1w8aNG7McS0bn9OPHjzTH6elSRslHZq/Hly9fokWLFvj69StWrFiBEydOIDg4GH/++ScA5c+IrFq4cCHGjRuHJk2aYOfOnQgKCkJwcDAqV66s8nn+7Nkz7N27F40aNcKhQ4fQqFEjzJo1K8P929jYQCaTqXyZFIvF+Pbtm+K18Ndff8HGxibNn2vXrin2pe7rKl/QURcw+UXqFB7Xrl3LtG7qmLzfp+54+fJlumPsfr/jNNX69esZAPb06VM2ZswYJhQKlabcSB0PtH37dqXtzpw5k+44v1TPnz9nQqGQ9e3bN8PzSS/G1DEqe/bsUZRFREQwLpfLWrZsme7+mjdvrnRXbOo2bm5uGcaRkdTxU1OmTFEql8vlzMbGhrm7uzPGft6Vldb4nEqVKimNaUy9KzYrZDIZMzU1zXQc5u9j7DR5/VLHEwYFBWUp5t9duXKFAWBHjx7N8jZdu3ZlANinT5+YVCplJiYmaY4X/V2nTp2Yg4OD0lggxlLGU5UpUybd7WQyGRs6dKjSVBvly5dnderUUam7ePFipbFzqc/972PnMhoTm+rq1atpTi+SlhcvXjBra2tWvnx5lXFVqR4+fJjhXbG/jnNijLGvX7+yihUrMktLS6Wxelnx4MEDBoAtXLhQre1+deTIEcblclnXrl1VxmalSr1L/ve7F3ft2sUAsEuXLimVX79+nRkZGbEGDRqkOYYsI2vWrEnz81gikTBDQ0M2fvz4TPeRkzF2bm5uzNraWuW52Lt3LwPA/v33X8aY8l2xv8vsczX1bveVK1cyACpjWlPHzqXWS71L9PTp00r1oqKiVMbYVatWjTVr1kwlppIlSzJXV9d0n4fk5GTWrl07xuVyM7xDOXXM8u93xaa+j1LHiL98+ZIFBwen+ZM664O6r6v8glrs8oBJkybByMgIgwcPxufPn1Uef/nyJVatWgUgpYWvePHiuHTpklKd9evXq33crl27gsvlYs+ePThw4ADat2+vNLFv6rc99su3GcaYIpZUiYmJKrO6ly1bFiYmJmk2c2dF3759UapUKaW7t2xtbeHl5YWzZ88qTbKaauPGjTh//jwGDRqk6OK0tbWFt7c3zpw5k+bM5HK5HMuXL89Sa8mOHTuUunQPHjyIT58+oU2bNgBS7tKytLTExo0blc771KlTePLkCdq1a5f1J+AXenp66Ny5M/799980V8lgaXRvApq9fu7u7jA1NcXChQvTXN3jy5cvGZ5DzZo1wefzVeL/77//EBERoVI/OjoaoaGhKFq0KCwsLMDlctG1a1ccOnQozdbtX4+f1nnfuHEDoaGhStukjvtLpaenh6pVqwL42Y3Ztm1b3Lx5U2nbhIQEbNq0CXZ2doqW4ayKjY1VWf2hSpUq0NPTy/S9EhkZCTc3N+jp6SEoKCjdcVWVK1dGxYoVsWnTJqWW/A0bNoDD4aBbt25K59K2bVt8+PABJ0+eVOlq+zXu3+NjjGH+/PkAUl4fqRITE/H06VOVsWhPnz5VudaXLl1Cr1690KRJE+zatSvdFuxOnTqBx+Mpfc4xxrBx40aULFlSaUaB1PeanZ0djh8/nm6LVlqv2bi4OPj5+aF48eKoWbOm0mOPHz9GUlKS1mYvSNW2bVtERkYqhskAKXfQr1mzBsbGxoqhFJqQ1nslJiYGW7duVarXsmVL8Hg8rFmzRqmun59fmvv8/TPpwIED+PDhg1LZ7+8/Pp8PJycnMMbSXUEISBkOYm5urvI3YMOGDRAKhYrPWQcHB7Rs2TLNn9TuY3VeV/kJTXeSB5QtWxa7d+9Gz549UalSJaWVJ65du6a41T3V4MGDsXjxYgwePBi1atXCpUuX8Pz5c7WPa2lpiWbNmmHFihWIi4tT6oYFUroxy5YtiwkTJuDDhw8wNTXFoUOHVLrTnj9/jhYtWqBHjx5wcnKCvr4+/vnnH3z+/DnbM3fzeDyMGTMGEydOxOnTpxXLFq1cuRJPnz7FiBEjlMqDgoJw9OhRuLq6Yvny5Ur7Wr58OV6+fInRo0fj8OHDaN++PYoWLYqIiAgcOHAAT58+zVKc5ubmaNSoEby8vPD582f4+fmhXLly8Pb2VsS8ZMkSeHl5wdXVFb1791ZMd2JnZ6fo3siOhQsX4syZM3B1dcWQIUNQqVIlfPr0CQcOHMCVK1dUBoUDmr1+pqam2LBhA/r3748aNWqgV69esLCwQEREBE6cOIGGDRti7dq16cZvaGgINzc3nD17FnPnzlWU37t3D3369EGbNm3QuHFjmJub48OHD9i+fTs+fvwIPz8/xR+fxYsX48KFC6hbty68vb3h5OSE79+/IywsDGfPnlV0nbVv3x6HDx9Gly5d0K5dO7x+/RobN26Ek5OT0hq1gwcPxvfv39G8eXOUKlUKb9++xZo1a1C9enVFt//kyZOxZ88etGnTBqNHj4a5uTm2b9+O169f49ChQ2p3pZ8/fx4+Pj7o3r07ypcvD6lUisDAQEXimpHWrVvj1atXmDRpEq5cuaK0KouVlRVatWql+H3ZsmXo2LEj3Nzc0KtXLzx8+BBr167F4MGDlaZ26Nu3L27evImBAwfiyZMnePLkieIxY2NjdO7cGQAQFhaG3r17o3fv3ihXrhxEIhH++ecfXL16FUOGDFGaxubmzZto1qwZZs2ahdmzZyvKK1WqBFdXV8Vaxm/fvkXHjh0Vyeav0+8AQNWqVRWJdqlSpTB27FgsW7YMEokEtWvXxpEjR3D58mXs2rVL8RqJi4uDu7s7fvz4gYkTJ6rcsFS2bFnUr18fALBu3TrFTUmlS5fGp0+fEBAQgIiICAQGBqoM0A8ODoZQKFR6nrVhyJAh+PvvvzFgwADcuXMHdnZ2OHjwIK5evQo/Pz+N3mjn5uYGPp+PDh06YOjQoYiPj8fmzZthaWmp1JVvYWGBCRMmYNGiRWjfvj3atm2Lu3fv4tSpUypd0+3bt8fcuXPh5eWFBg0a4MGDB9i1axccHBxUjm1tbY2GDRvCysoKT548wdq1a9GuXbsMz1EgEGDevHkYOXIkunfvDnd3d1y+fBk7d+7EggULlKZ7yUxWX1f5jk7aCUmanj9/zry9vZmdnR3j8/nMxMSENWzYkK1Zs4YlJSUp6iUmJrJBgwYxMzMzZmJiwnr06KFoElenK5YxxjZv3swAMBMTkzSbvx8/fsxatmzJjI2NWfHixZm3t7dios7U7qWvX7+ykSNHsooVKzIjIyNmZmbG6taty/bv35/pOWcUY0xMDDMzM1Npvk9OTmYrV65kNWvWZEZGRkwoFLIaNWowPz8/JhaL0zyOVCplW7ZsYY0bN2ZmZmaMx+OxMmXKMC8vr0ynQkntZtuzZw+bMmUKs7S0ZAKBgLVr1y7NaTn27dvHXFxcmIGBATM3N89wgmJ1vH37lnl4eDALCwtmYGDAHBwc2MiRIzOcoFjT1+/ChQvM3d2dmZmZMUNDQ1a2bFk2YMAAdvv27UzjP3z4MONwOErTcHz+/JktXryYubq6MhsbG6avr8+KFi3Kmjdvzg4ePKiyj8+fP7ORI0cyW1tbxuPxmLW1NWvRogXbtGmToo5cLmcLFy5kZcqUYQYGBszFxYUdP36ceXp6KnXFHjx4kLm5uSkmOy5dujQbOnQo+/Tpk9IxUycoLlKkCDM0NGR16tRJd4LizLpiX716xQYOHMjKli3LDA0Nmbm5OWvWrBk7e/Zsps8fgHR/0uri+ueff1j16tWZgYEBK1WqFJs+fbrK+6NMmTLp7vPX5+rVq1ese/fuzM7OjhkaGjKhUMhq1qzJNm7cqNLlnfpc/PpZlBr/r3Gm1kvv5/ftZTKZ4rry+XxWuXJlpSlBfn2+0/v5tcvwzJkzrFWrVsza2prxeDxWpEgR5ubmpjLNS6q6deuyfv36pfnY77LaFSuXyxkANnr0aKXyz58/My8vL1a8eHHG5/NZlSpVVLrzNdEVy1jKhNBVq1ZlhoaGzM7Oji1ZsoQFBASo1JPJZGzOnDnMxsYmwwmKk5KS2Pjx4xX1GjZsyEJDQ5mrq6vS9f/7779ZkyZNWLFixZiBgQErW7YsmzhxIouJicn0eWOMsU2bNrEKFSowPp/PypYty1auXKnyWsyKrLyu8hsOY+n04xBCAAAhISFo1qwZDhw4oNSNRdQjk8ng5OSEHj16YN68eboOh5AsCw8PR40aNRAWFqaY4DojqROVZ/bnNTY2FmZmZpg+fTq9J4jG0Bg7Qkiu4HK5mDt3LtatW6fUJUpIXrd48WJ069YtS0mdOlLncFN3rCYhGaExdoSQXNOzZ0+VsZyE5HV79+7V6P7u37+Ps2fPYsWKFShWrFi2b6wiJC3UYkcIIYTkosOHD2Pq1Kmws7PDqVOnlCaFJySnaIwdIYQQQkgBQS12hBBCCCEFBCV2hBBCCCEFRKG7eUIul+Pjx48wMTHR+mLOhBBCCCE5xRhDXFwcSpQokenE6IUusfv48aNikWdCCCGEkPzi3bt3iiUz01PoErvUpUrevXun1TuRJBIJzpw5Azc3N/B4PK0dh2QdXZO8ia5L3kPXJG+i65I35cZ1iY2Nha2tbZaWlCt0iV1q96upqanWEzuhUAhTU1N6A+YRdE3yJroueQ9dk7yJrkvelJvXJStDyOjmCUIIIYSQAoISO0IIIYSQAoISO0IIIYSQAqLQjbHLKplMBolEku3tJRIJ9PX1kZSUBJlMpsHISHbRNUnB4/HA5XJ1HQYhhBAtoMTuN4wxREZGIjo6Osf7sba2xrt372i+vDyCrslPRYoUgbW1daF/HgghpKChxO43qUmdpaUlhEJhtv/wyeVyxMfHw9jYONPJBEnuoGuSktwmJiYiKioKAGBjY6PjiAghhGgSJXa/kMlkiqSuWLFiOdqXXC6HWCyGoaFhoU0i8hq6JikEAgEAICoqCpaWltQtSwghBUjh/euWhtQxdUKhUMeREKJdqa/xnIwjJYQQkvdQYpcGGndECjp6jRNCSMFEiR0hhBBCSAGh08Tu0qVL6NChA0qUKAEOh4MjR45kuk1ISAhq1KgBAwMDlCtXDtu2bdN6nESz/P394ebmpuswCozHjx+jVKlSSEhI0HUohBBCdEyniV1CQgKqVauGdevWZan+69ev0a5dOzRr1gzh4eEYO3YsBg8ejKCgIC1Hmn+EhoaCy+WiXbt2ug4lTUlJSZgxYwZmzZql8tj79+/B5/Ph7Oys8tibN2/A4XAQHh6u8ljTpk0xduxYpbK7d++ie/fusLKygqGhIRwdHTFkyBC8ePFCU6eigjGGmTNnwsbGBgKBAC1btsR///2X4TZ2dnbgcDgqPyNHjlTUadq0qcrjw4YNUzzu5OSEevXqYcWKFVo7N0IIIfmDThO7Nm3aYP78+ejSpUuW6m/cuBH29vZYvnw5KlWqBB8fH3Tr1g0rV67UcqT5h7+/P0aNGoVLly7h48ePug5HxcGDB2FqaoqGDRuqPLZt2zb06NEDsbGxuHHjRraPcfz4cdSrVw/JycnYtWsXnjx5gp07d8LMzAwLFy7MSfgZWrp0KVavXo2NGzfixo0bMDIygru7O5KSktLd5tatW/j06ZPiJzg4GADQvXt3pXre3t5K9ZYuXar0uJeXFzZs2ACpVKr5EyOEEJJv5KvpTkJDQ9GyZUulMnd3d5XWmsIqPj4e+/btw+3btxEZGYlt27Zh6tSpAFKSnX79+uHbt2/gcrkIDw+Hi4sLfH19sXjxYgDA4MGDkZSUhJ07d+Lbt2/w8fHBpUuX8OPHD5QtWxZTp05F7969AQA7duzAn3/+iY8fP8LAwEARQ+fOnWFiYoLAwMA0Y9y7dy86dOigUs4Yw9atW7F+/XqUKlUK/v7+qFu3rtrPQWJiIry8vNC2bVv8888/inJ7e3vUrl0b7969U3ufWcEYg5+fH6ZPn45OnToBSHmOrKyscOTIEfTq1SvN7SwsLJR+X7x4McqWLQtXV1elcqFQCGtr63SP36pVK3z//h0XL15EixYtcng2hJDcwhiDSJK1lXAkEimSZUCiWAoeS/sGKMYYkmTpf5nMRoCAJFFz+yuAJBIJEsVxkMtkAI+n63DyV2IXGRkJKysrpTIrKyvExsZCJBIp5uf6VXJyMpKTkxW/x8bGAki5EL9P9SCRSMAYg1wuh1wuB6Dem+5XjDGIxDJwkyXZvgNRwOOqte3evXtRsWJFODo6ok+fPhg3bhx8fX3B4XDQsGFDxMXF4c6dO6hVqxZCQkJQvHhxhISEKM714sWLmDhxIuRyORITE1GjRg1MnDgRpqamOHnyJPr37w97e3vUqVMHXbt2xejRo3HkyBFF61JUVBROnDiB06dPK/b5uytXrqBv374qj58/fx6JiYlo3rw5bGxs0KhRIyxfvhxGRkYAoKj/67X5Vep1O3XqFL5+/YoJEyao1GOMwczMTFH3d8OHD8euXbsyfI5TXz+/e/XqFSIjI9G8eXPFvk1MTFC3bl1cu3YNPXr0yHC/ACAWi7Fz5078+eefYIyBMaZ4bNeuXdi5cyesra3Rvn17TJ8+XWlaHn19fVSvXh2XLl1Cs2bNMj2WXC4HYwwSiUTn89ilvg9p6pW8g65J7mCModeWWwiLiFZjK31Munk+vT1CWGYjuMK3GoiOZEaeLIeewc+Oz0Y/GsG6eEmtHEud92K+SuyyY9GiRZgzZ45K+ZkzZ1Tmq9PX14e1tTXi4+MhFosBACKxDPVXXM+VWH8XOq4eBPys/9HdvHkzunbtitjYWDRo0ADR0dE4deoUGjVqBA6HgypVqiAoKAjly5fH2bNnMWzYMCxduhQfP35EbGwsXrx4gZo1ayI2NhYmJibw9vZW7NvDwwMnTpzArl27ULFiRQBA165dsWXLFri7uwNI6QYuVaoUatSokWYCFBMTg5iYGJiZmak8/vfff6NLly5ISEhA6dKlUaZMGQQGBqJPnz4AUlojgZRxmb9vK5VKIRaLERsbi4cPHwIASpYsmW4SFhcXl2b5hAkTMHTo0Ayf4/T2+fLlSwApLWu/1jE3N8f79+/T3e5X//zzD6Kjo/HHH38o1e/cuTNGjRoFa2trPHr0CHPmzMGjR49UWkUtLCzw4sWLLB1LLBZDJBLh0qVLeab7NrUbmuQddE20K1kGhEVo8M8wR0JJXS6JuRWDjzs+orRPaRhVSGmAuHLlCoR8E60cLzEx662m+Sqxs7a2xufPn5XKPn/+DFNT0zRb6wBgypQpGDdunOL32NhY2Nraws3NDaampkp1k5KS8O7dOxgbG8PQ0BAAoC/W3R89E1MTCPlZu0TPnj1DWFgYjh49qjivnj17Yu/evWjbti0AoFmzZrh+/TqmTp2K69evY+nSpfj3339x//59fP/+HSVKlICLiwuAlFU4Fi1ahAMHDuDDhw8Qi8VITk6GqampYv8jRoxA3bp1ERcXh5IlS2Lfvn3w8vKCmZlZmjGm3rVZrFgxpec+Ojoax48fx6VLlxTlHh4e2LNnj+ImAWNjYwCAkZGRynXT19cHn8+HqampolvYxMREpR5jDHFxcTAxMUmzJfT3+upIbVn8/bj6+vrgcDhZ2veePXvQunVrVKhQQal89OjRiv/Xr18fDg4OaNWqFb58+YKyZcsqHjMxMYFEIsnSsZKSkiAQCNCkSRPFa11XJBIJgoOD0apVK/DyQDcGoWuSWxLFUkXr23Vf10y/yEskUpw/fx7NmzcHj6f6t0EkFaHVkZT//9v+NAz10/67mGXiBJiurwIAiPO+CcbL4f4KgOjoaEybMguHD6UM9al4rwL+HrUBV65cQYfWnWCgpc/TrHxhT5WvErv69evj5MmTSmXBwcGoX79+utsYGBgojQFLxePxVD6wZDIZOBwO9PT0FEtOGRnw8Hiuu9qxyuVyxMXGwcTUJNvLV6nTFbt161ZIpVKUKlVKUcYYg4GBAdatWwczMzM0a9YMW7duxYMHD8Dj8eDk5ISmTZsqxtG5uroqYk29EcDPzw9VqlSBkZERxo4dC4lEoqhTs2ZNVKtWDTt37oSbmxsePXqEEydOpHu+FhYW4HA4iImJUaqzd+9eJCUlKV3H1O7SFy9eoHz58ihSpAiAlNa23/cfHR2NIkWKQE9PT5EUPX/+XOV1kdpFmnqNfzds2DDs3Lkzw+c5teXwdyVKlAAAfPnyBSVL/myKj4qKQvXq1TN9Dbx9+xbnzp3D4cOHM62bel6vXr2Co6Ojojx1LGRWXm96enrgcDhpvg90JS/FQlLQNdGuX8fJmRoZZvpFXiKRwIALmBkZpnldeJKfwzcsTYtCyMvhKkpig5QxdgCExUsCfKOc7S+fCw4OhpeXFz58+AA9PT1MmTIFM2fOBIfDgZBvAgPDtK+LJqizX53eFRsfH4/w8HDFFBavX79GeHg4IiIiAKS0tnl4eCjqDxs2DK9evcKkSZPw9OlTrF+/Hvv378eff/6ptRhTLph+tn4EfG62txXy9bOc1EmlUuzYsQPLly9XPJ/h4eG4d+8eSpQogT179gAAGjdujLi4OKxcuVIxOL9p06YICQlBSEgImjZtqtjn1atX0alTJ/Tr1w/VqlWDg4MDnj9/rnLswYMHY9u2bdi6dStatmwJW1vbdOPk8/lwcnLC48ePlcr9/f0xfvx4ldgbN26MgIAAACldmsWLF8edO3eUtk3tQi5fvjwAwM3NDcWLF1e5azRVTExMuvHNnTtXKYa0ftJjb28Pa2trnDt3Tim2GzduZPjFI9XWrVthaWmZpWlqUuOwsbFRKn/48KGixZUQQohmJCQkwMfHB25ubvjw4QMcHR1x9epVzJ8/H3w+X9fhqWI6dOHCBQZA5cfT05MxxpinpydzdXVV2aZ69eqMz+czBwcHtnXrVrWOGRMTwwCwmJgYlcdEIhF7/PgxE4lE2Tyjn2QyGfvx4weTyWQ53ldm/vnnH8bn81l0dLTKY5MmTWK1atVS/F69enXG5XLZhg0bGGOMffv2jfF4PAaAPX36VFHvzz//ZLa2tuzq1avs8ePHbPDgwczU1JR16tRJaf/R0dFMKBQyPp/P9u7dm2ms48aNY127dlX8fvfuXQaAPXnyRKXu+vXrmbW1NZNIJIwxxhYuXMiKFSvGdu7cyV68eMFu3LjB2rdvz+zs7FhiYqJiuyNHjjAej8c6dOjAgoOD2evXr9mtW7fYhAkTWJcuXbR2TRYvXsyKFCnCjh49yu7fv886derE7O3tlV5PzZs3Z2vWrFHaTiaTsdKlSzNfX1+Vfb548YLNnTuX3b59m71+/ZodPXqUOTg4sCZNmijVe/36NeNwOOzNmzdZilWTr/WcEovF7MiRI0wsFus6FPJ/dE1yR0KyhJXxPc7K+B5nCcmSTOtndl0SxAnMeZszc97mzBLECTkPMDmesVmmKT/J8TnfXz61Z88eRX4ycuRIFh+v/Fzkxvslo9zldzpN7HShICZ27du3Z23btk3zsRs3bjAA7N69e4wxxsaMGaOSSFWrVo1ZW1srbfft2zfWqVMnZmxszCwtLdn06dOZh4eHSmLHGGP9+/dn5ubmLCkpKdNYHz16xAQCgSIJ9fHxYU5OTmnW/fTpE9PT02NHjx5ljDEmlUrZ6tWrWZUqVZhQKGSlSpViPXv2ZK9fv1bZ9tatW+yPP/5gFhYWzMDAgJUrV455e3uzO3fuaO2ayOVyNmPGDGZlZcUMDAxYixYt2LNnz5TqlClThs2aNUupLCgoiAFQqcsYYxEREaxJkybM3NxccR4TJ05Uef0uXLiQubu7ZzlWSuxIRuia5A5K7PIHuVzOhg0bxoKCgtJ8PK8ldhzGfplToRCIjY2FmZkZYmJi0rx54vXr17C3t8/xgHK5XI7Y2FiYmppme4xdftGiRQtUrlwZq1evzlL97t27o0aNGpgyZYqWI1NWUK+JWCyGo6Mjdu/enebEz2nR5Gs9pyQSCU6ePIm2bdvSeK48gq5J7kgUS+E0M2XlpMdz3bM0xi6j65IoSUTd3Snzf97oc0MDY+wSgIUp44cx9WOhGWP36NEjTJ48GTt27EDRokUzrZ8b75eMcpffFZy/biTX/fjxA//88w9CQkKUlsDKzLJlyxR3uZKci4iIwNSpU7Oc1BFCCFElk8mwfPly1KxZE8ePH8/1xgdNyVd3xZK8xcXFBT9+/MCSJUtUpujIiJ2dHUaNGqXFyAqXcuXKoVy5croOgxBC8q03b97A09MTly5dAgC0bds2zTXN8wNK7Ei2vXnzRtchEEIIIdnGGENAQADGjh2L+Ph4GBkZYeXKlRg8eHC2V43SNUrsCCGEEFIorVy5EuPHjwcANGrUCNu3b4eDg4OOo8oZSuwIIYTkSYwxiKQiXYehNSKpDOD8f/lKqQjgZLzyhFQqhZiJIZKKIIHq2qEF+bnSlgEDBmDt2rUYPnw4xo0bp/O1szWBEjtCCCF5DmMMHqc8EP4lXNehaJVJytLbaHpgZpa3mbt/rpaiKfiio6MRGBgIHx8fcDgcmJub48mTJ2muUJVfUWJHCCEkzxFJRQU+qdMWF0sXCHK6TmwBdO7cOXh5eeHdu3cwMzNTrGxVkJI6gBI7QggheVxIj5ACmaiIJDLUnHcWAHBnRksIeJl3xQYFBcHd3R36+un/+RboC/LtwH9tSExMxJQpUxRzrZYtW1Zpne2ChhI7QggheZpAX5DzyXbzIiYFWMpaoynnmMkExZCAz+FDoC+giaOz6NatW+jfvz+ePXsGABg+fDiWLl1aoOdSpQmKSa569uwZrK2tERcXp+tQCgSxWAw7Ozvcvn1b16EQQkiesmbNGtSvXx/Pnj2DjY0NTp06hfXr1xfopA6gxK7AGDBgADgcDjgcDng8HqysrNCqVSsEBARALpfrOjyFKVOmYNSoUTAxMVF5rGLFijAwMEBkZKTKY3Z2dvDz81Mpnz17NqpXr65UFhkZiVGjRsHBwQEGBgawtbVFhw4dcO7cOU2dRpoOHDiAihUrwtDQEFWqVMHJkyczrB8SEqK4Zr/+/Hr+GzZsQNWqVWFqagpTU1PUr18fp06dUjzO5/MxYcIE+Pr6au28CCEkP6patSrkcjl69eqFhw8fonXr1roOKVdQYleAtG7dGp8+fcKbN29w6tQpNGvWDGPGjEH79u0hlUrT3U4iUb1tXhsiIiJw/PhxDBgwQOWxK1euQCQSoVu3bti+fXu2j/HmzRvUrFkT58+fx7Jly/DgwQOcPn0azZo10+pqF9euXUPv3r0xaNAg3L17F507d0bnzp3x8OHDTLd99uwZPn36pPixtLRUPFaqVCksXrwYd+7cwe3bt9G8eXN06tQJjx49UtTp27cvrly5olRGCCGFjVwux/379xW/u7q6IiwsDHv27IG5ubkOI8tdlNgVIAYGBrC2tkbJkiVRo0YNTJ06FUePHsWpU6ewbds2RT0Oh4MNGzagY8eOMDIywoIFCyCTyTBo0CDY29tDIBCgQoUKWLVqlWKbhw8fQk9PD1++fAEAfP/+HXp6eujVq5eizvz589GoUaN049u/fz+qVauGkiVLqjzm7++PPn36oH///ggICMj2czBixAhwOBzcvHkTXbt2Rfny5VG5cmWMGzcO165dy/Z+M7Nq1Sq0bt0aEydORKVKlTBv3jzUqFEDa9euzXRbS0tLWFtbK3709H6+LTt06IC2bdvC0dER5cuXx4IFC2BsbIzr168r6hQtWhQNGzbE3r17tXJuhBCS1719+xYtWrRA/fr18eLFC0X57z06hQEldplhDBAnZO9Hkpj9bcUJKcfOoebNm6NatWo4fPiwUvns2bPRpUsXPHjwAAMHDoRcLkepUqVw4MABPH78GDNnzsTUqVOxf/9+AEDlypVRrFgxXLx4EQBw+fJlpd8B4OLFi2jatGm6sVy+fBm1atVSKY+Li8OBAwfQr18/tGrVCjExMbh8+bLa5/r9+3ecPn0aI0eOhJGRkcrjRYoUSXfbXbt2wdjYOMOfjGIKDQ1Fy5Ytlcrc3d0RGhqaadzVq1eHjY0NWrVqhatXr6ZbTyaTYe/evUhISED9+vWVHqtTp062njNCCMnPGGPYtm0bqlSpgpCQEADIUk9JQUZ3xWZGkggsLKH2ZnoAiuT02FM/AnzVBEVdFStWVGqeBoA+ffrAy8tLqWzOnDmK/9vb2yM0NBT79+9Hjx49wOFw0KRJE4SEhKBbt24ICQmBl5cXtmzZgqdPn6Js2bK4du0aJk2alG4cb9++TTOx27t3LxwdHVG5cmUAQK9eveDv74/GjRurdZ4vXrwAYwwVK1ZUazsA6NixI+rWrZthnbRaGlNFRkbCyspKqczKyirN8YKpbGxssHHjRtSqVQvJycnYsmULmjZtihs3bqBGjRqKeg8ePED9+vWRlJQEY2Nj/PPPP3ByclLaV4kSJfD27dsM4yckqxhjSJYBiWIpeEw302aIpLKf/5fIUu4gLWASxbLMK5F0RUVFYciQITh69CgAoEGDBti+fTvKlSun48h0ixK7QoAxpjKnUVoJ1rp16xAQEICIiAiIRCKIxWKlZmxXV1ds2rQJQErr3MKFC/H8+XOEhITg+/fvkEgkaNiwYbpxiEQiGBoaqpQHBASgX79+it/79esHV1dXrFmzJs2bLDI6z+wyMTFR61iaUKFCBVSoUEHxe4MGDfDy5UusXLkSgYGBSvXCw8MRExODgwcPwtPTExcvXlRK7gQCARITE3M1flIwMcbQa8sthEXoY9LN87oLhCNWrMpQc95ZxbQghADA0aNH4e3tjS9fvoDH42HevHmYMGFCgVgSLKcoscsMT5jScqYmuVyO2Lg4mJqYKI2ZUvvYGvDkyRPY29srlf3eVbl3715MmDABy5cvR/369WFiYoJly5bhxo0bijpNmzbF2LFj8d9//+Hx48do1KgRnj59ipCQEPz48QO1atWCUJh+zMWLF8ePHz+Uyh4/fozr16/j5s2bSnd2pnY7ent7AwBMTU0RExOjss/o6GiYmZkBABwdHcHhcPD06dMsPjM/7dq1C0OHDs2wzqlTp9JtRbS2tsbnz5+Vyj5//gxra2u14qhTpw6uXLmiVMbn8xXfQGvWrIlbt25h1apV+PvvvxV1vn//DgsLC7WORUhaRBIZwiKidR1GoVKrTNFMJycmym7fvo0vX76gSpUqCAwMRLVq1XQdUp5BiV1mOJzsdYfK5QBPlrJtdhM7DTh//jwePHiAP//8M8N6V69eRYMGDTBixAhF2cuXL5XqVKlSBUWLFsX8+fNRvXp1GBsbo2nTpliyZAl+/PiR4fg6AHBxccHjx4+Vyvz9/dGkSROsW7dOqXzr1q3w9/dXJHYVKlTAnTt3VPYZFhamaPUyNzeHu7s71q1bh9GjR6skr9HR0ekm2Tntiq1fvz7OnTuHsWPHKsqCg4NVxsJlJjw8HDY2NhnWkcvlSE5OVip7+PAhXFxc1DoWyV8YY7myyPuvC9NfGNcIpkaqrey5QSQVoc0/Kf+/M6NlgVx5IpWAx6WVIrIgOTlZsfzXjBkzYG5ujhEjRhS4JcFyihK7AiQ5ORmRkZGQyWT4/PkzTp8+jUWLFqF9+/aKNfHS4+joiB07diAoKAj29vYIDAzErVu3lFr6UsfZ7dq1CxMmTACQMk9QcnIyzp07h3HjxmV4DHd3dwwePBgymQxcLhcSiQSBgYGYO3cunJ2dleoOHjwYK1aswKNHj1C5cmX8+eefaNy4MRYsWIA//vgDMpkMe/bsQWhoKNavX6/Ybt26dWjYsCHq1KmDuXPnomrVqpBKpQgODsaGDRvSvZkhp12xY8aMgaurK5YvX4527dph7969uH37tqLrGkiZw+/Dhw/YsWMHAMDPzw/29vaoXLkykpKSsGXLFpw/fx5nzpxR2qZNmzYoXbo04uLisHv3boSEhCAoKEjp+JcvX8a8efOyHT/J2xhj8DjlkWtrp6Z2gXbMeCrGXCPgcTNdlYEUXCKRCFOmTMGVK1dw7do18Pl88Pn8TBssCiu6K7YAOX36NGxsbGBnZ4fWrVvjwoULWL16NY4ePZrpuIOhQ4fijz/+QM+ePVG3bl18+/ZNqfUulaurK2QymaJ1Tk9PD02aNAGHw8lwfB0AtGnTBvr6+jh7NmVtxGPHjuHbt2/o0qWLSt1KlSqhUqVK8Pf3B5Ay/uzUqVM4deoUGjZsiKZNm+LatWs4d+6cUlLo4OCAsLAwNGvWDOPHj4ezszNatWqFc+fOqbQKalKDBg2we/dubNq0CdWqVcPBgwdx5MgRpdg+ffqEiIgIxe9isRjjx49HlSpV4Orqinv37uHs2bNo0aKFok5UVBQ8PDxQoUIFtGjRArdu3UJQUBBatWqlqBMaGoqYmBh069ZNa+dHdEskFeVaUpfX0IL2hdvt27dRo0YNrFq1Cnfu3MHp06d1HVKex2E5GXGeD8XGxsLMzAwxMTEwNTVVeiwpKQmvX7+Gvb19moP81SGXyxEbGwtTU9Psj7ErgNatW4djx46ptDjlhoJ6TXr27Ilq1aph6tSpWd5Gk6/1nJJIJDh58iTatm1L61+mI1GSiLq7U4YKhPQI0Wqi8+vC9Ncnu8JUqNvXBy1o/1Ouv1fECT9nhdDQLA1ZJZFIsHDhQsybNw8ymQw2NjbYsmUL2rZtm2sxZFVuXJeMcpffUds2yVVDhw5FdHQ04uLicv0u1IJILBajSpUq1CVRiKQsFq+ZG6vSpLIwPbWWkdz19OlT9O/fX7EGdo8ePbB+/XoUK1ZMx5HlD5TYkVylr6+PadOm6TqMAoPP52P69Om6DoMQQjRm5MiRuH37NooUKYINGzYorXBEMldw+qMIIYQQku/9/fff6NKlCx4+fEhJXTZQYkcIIYQQnWCMYceOHUorH5UrVw6HDx/OcIopkj7qiiWEEEJIrvvy5QuGDh2Kf/75BxwOB23btkXt2rV1HVa+Ry12hBBCCMlVx44dg7OzM/755x/weDwsWLCAJlnXEGqxI4QQQkiuiI2NxdixY7F161YAgLOzMwIDA5XWJSc5Q4kdIYQQQrROLpejcePGuH//PjgcDiZOnIi5c+fSkmAaRl2xhBBCCNE6PT09/Pnnn7C3t8fFixexZMkSSuq0gFrsiM41adIEw4YNQ58+fXQdSoEwefJkJCQkYM2aNboOpcBhjEEkFeX6cXVxTJIOxgBJom6OLZGAK0tOWRGC5cbKEzk/zzt37iAhIQFNmjQBAHh6eqJHjx4QCrU4yXYhR4ldATFgwABER0fjyJEjSuUhISFo1qwZfvz4gSJFiugktowcO3YMnz9/TnOuokWLFmH69OlYvHgxJk6cqPTY7NmzceTIEYSHhyuVv3nzBvb29rh7965izAZjDJs3b4a/vz8ePXoEfX19lCtXDv369cOQIUO09gETERGB4cOH48KFCzA2NoanpycWLVoEff2033ap1yotN2/eVLlb7MWLF3BxcQGXy0V0dLSifMKECXBwcMCff/4JBwcHjZ1PYccYg8cpj0K7ZitBSlIX4A68u6GTw/MAtAeA+zo5vFqkUikWLVqEuXPnwtLSEg8fPkTRokXB4XAoqdMy6oolOrV69Wp4eXmluXZrQEAAJk2ahICAgBwdo3///hg7diw6duyIY8eOISwsDDNmzMDRo0dx5syZHO07PTKZDO3atYNYLMa1a9ewfft2bNu2DTNnzkx3mwYNGuDTp09KP4MHD4a9vT1q1aqlVFcikaB3795o3Lixyn6KFy8Od3d3bNiwQePnVZiJpCKdJ3Uuli5aXSeWZEKSqLOkTqds6wFqLGP37NkzNGzYEDNnzoRUKkWDBg1QyJal1ylqsSuEDh06hJkzZ+LFixewsbHBqFGjMH78eMXjdnZ2GDx4MJ4/f47Dhw+jWLFiWLNmDerXr4/Bgwfj3LlzcHBwQEBAgFLCceXKFUyZMgW3b99G8eLF0aVLFyxatAhGRmkvHP3lyxecP38eq1atUnns4sWLEIlEmDt3Lnbs2IFr166hQYMGap/r/v37sWvXLhw5cgQdOnRAbGwsTE1N4eDggI4dOyI2NlbtfWbFmTNn8PjxY5w9exZWVlaoXr065s2bB19fX8yePRt8Pl9lGz6fD2tra8XvEokER48exahRo1QWQZ8+fToqVqyIFi1a4Nq1ayr76tChA6ZNm4Zly5Zp/uQIQnqE6CTBEugLVF4LREcmvAD4udvyJJFIEBR0Bu7ublpbbD5NPCGQhdedXC7HunXr4OvrC5FIhCJFimDdunXo3bs3vW5zESV2mcjumBq5XA6RVAR9iX6arVFZoY0P8Tt37qBHjx6YPXs2evbsiWvXrmHEiBEoVqwYBgwYoKi3cuVKLFy4EDNmzMDKlSvRv39/NGjQAAMHDsSyZcvg6+sLDw8PPHr0CBwOBy9fvkTr1q0xf/58BAQE4MuXL/Dx8YGPj4/itvbfXblyBUKhEJUqVVJ5zN/fH7179waPx0Pv3r3h7++frcRu165dqFChAjp16gS5XK70GIfDgZmZWbrbGhsbZ7jvfv36YePGjWk+FhoaiipVqsDKykpR5u7ujuHDh+PRo0dZmq/p2LFj+PbtG7y8vJTKz58/jwMHDiA8PByHDx9Oc9s6derg/fv3ePPmDezs7DI9FlGPQF8AoRotGKQA4gsBftpfWrWGI4GMa5By3NxM7LJAJBKhQ4cOOHfuHACgZcuW2Lp1K0qVKqXjyAofSuwyIZKKUHd3XZ0c+0afG2r98Th+/LhKMiKTyZR+X7FiBVq0aIEZM2YAAMqXL4/Hjx9j2bJlSold27ZtMXToUADAzJkzsWHDBtSuXRvdu3cHAPj6+qJ+/fr4/PkzrK2tsWjRIvTt2xdjx44FADg6OmL16tVwdXXFhg0bYGhoqBLv27dvYWVlpZL4xsbG4uDBgwgNDQWQkkA1btwYq1atyjTZ+t1///2HChUqqLVNqt/H7/3O1NQ03cciIyOVkjoAit8jIyOzdHx/f3+4u7srfTB++/YNAwYMwM6dOzM8fokSJQCkPMeU2BFCtE0gEMDS0hICgQDLli3D8OHDs92oQXKGErsCpFmzZirjqm7cuIF+/fopfn/y5Ak6deqkVKdhw4bw8/ODTCYDl8sFAFStWlXxeGpCUqVKFZWyqKgoWFtb4969e7h//z527dqlqMMYg1wux+vXr9NslROJRGkmfHv27EHZsmVRrVo1AED16tVRpkwZ7Nu3D4MGDcrak/FLDNlVrly5bG+bU+/fv0dQUBD279+vVO7t7Y0+ffoo7jBLj0CQ0k2YmKiju/cIIQXely9fwOFwULx4cQDA2rVrMWvWrGx/mSaaQYldJgT6Atzoo/5gWblcjri4OJiYmOSoK1YdRkZGKsnI+/fvs3XsX8dvpHYHp1WW2r0ZHx+PoUOHYvTo0Sr7Kl26dJrHKF68OH78+KFS/uvdq6nkcjkCAgIUiZ2pqSliYmJUtk29OzS1i7V8+fJ4+vRp+ieagZx0xVpbW+PmzZtKZZ8/f1Y8lpmtW7eiWLFi6Nixo1L5+fPncezYMfz1118AfibP+vr62LRpEwYOHAgA+P79OwDAwsIi02OR/IsxBpFElnlFNSSKNbs/UjD9+++/8Pb2Rv369XH48GFwOByYm5vD3Nxc16EVepTYZYLD4WRrLI1cLodUXwohT5inmqMrVaqEq1evKpVdvXoV5cuXV7TWZUeNGjXw+PFjtVq5XFxcEBkZiR8/fqBo0aIAgAcPHuD27dsICQlR+oD4/v07mjZtiqdPn6JixYqoUKEC3r9/j8+fPyt1eYaFhcHQ0FCRTPbp0we9evXC0aNH0aFDB6XjM8YQGxub7ji7nHTF1q9fHwsWLEBUVBQsLS0BAMHBwTA1NYWTk1OG+2WMYevWrfDw8FAZIB0aGqrUvX706FEsWbIE165dQ8mSJRXlDx8+BI/HQ+XKlTM8Fsm/GGPotjEUd96qfjkiRFtiY2Mxbtw4+Pv7A0gZ7vL9+3cUK1ZMx5GRVJTYFTLjx49H7dq1MW/ePPTs2ROhoaFYu3Yt1q9fn6P9+vr6ol69evDx8cHgwYNhZGSEx48fIzg4GGvXrk1zGxcXFxQvXhxXr15F+/btAaS01tWpUyfNrsbatWvD398fy5Ytg7u7OypUqIDevXtj/vz5sLa2RlhYGKZPn44xY8YoktQePXrgn3/+Qe/evTFt2jQ0aNAAdnZ2ePToEVauXIlRo0ahc+fOacaXk65YNzc3ODk5oX///li6dCkiIyMxffp0jBw5UjHT+s2bN+Hh4YFz584pJWXnz5/H69evMXjwYJX9/t6lffv2bejp6cHZ2Vmp/PLly2jcuLGiS5YUPCKJTKtJnb0Jg4CX/S97pOC5ePEiBgwYgDdv3oDD4WD8+PGYN29emkNqiO5QYlfI1KhRA/v378fMmTMxb9482NjYYO7cuUo3TmRH1apVcfHiRUybNg2NGzcGYwxly5ZFz549092Gy+XCy8sLu3btQvv27SEWi7Fz5074+vqmWb9r165Yvnw5Fi5cCB6PhzNnzmDq1Kno3bs3vnz5Ant7e4wZMwbjxo1TbMPhcLB7925s2rQJAQEBWLhwIfT19eHo6AgPDw+4u7vn6LwzOrfjx49j+PDhqF+/PoyMjODp6Ym5c+cq6iQmJuLZs2eQSCRK26beAVyxYsVsH3/v3r2YPXt2trcn+cvt6S0h5GsuCZNIJLgQfIamqCAAgKSkJEyfPh0rVqwAYwx2dnbYvn17pmN9iW5wWCGbNTC16y0mJkalKy0pKQmvX7+Gvb19jr+ByOVyxZxpeakrNq+JjIxE5cqVERYWhjJlymj1WIXlmpw6dQrjx4/H/fv3013lQpOv9ZySSCQ4efIk2rZtm7tzc6kpUZKouENe3TvWtRKPWAqnmUEAgMdz3SHka+57en65JrlOnAAsTLnjHFM/5vp0J7q6LrGxsahWrRrevHmDQYMGYcWKFRkORSlscuO6ZJS7/I5a7IhOWVtbw9/fHxEREVpP7AqLhIQEbN26Nd2kjhBCMiOVSsHlcsHhcGBqaorAwEB8//5d5YYukvfQJz/RufTGuJHs6datm65DIITkY8+fP4eHhwc8PT0xfPhwAECjRo10HBXJqoLbH0UIIYSQLGOMYd26dahevTpu3LiB+fPnIykpSddhETVRYkcIIYQUcu/fv4e7uzt8fHwgEonQokULXL9+XedjcIn6KLEjhBBCCinGGHbv3o0qVaogODgYAoEAa9aswZkzZ2Bra6vr8Eg20Bg7QgghpJB68eIFPDw8IJPJUKdOHezYsYOWBMvnKLEjhBBCCilHR0fMnDkTHA4HU6ZMobvpCwC6goQQQvImxgBJoq6j+Emch2LJpri4OPj6+mLkyJGKJQdnzpyp46iIJlFiRwghJO9hDAhwB97d0HUkBcbly5fh6emJ169f4+bNm7h582aBnqy9sKIrWkiEhISAw+EgOjpa16Gka/bs2ahevbquwyCE5AWSxLyb1NnWA3S88og6kpOTMWnSJLi6uuL169coXbo0li1bRkldAUUtdgVMaGgoGjVqhNatW+PEiRNaPVZISAiaNWuGHz9+oEiRIjne34QJEzBq1KicB0YIKVgmvAD4eSiR4gmBfLKObnh4OPr374+HDx8CALy8vODn50dLghVglNgVMP7+/hg1ahT8/f3x8eNHlChRQtchZYoxBplMBmNjYxgbG+s6HEJIXsMX5vq6rAVBaGgoXF1dIZFIYGFhgc2bN6NTp066DotoGbXDFiDx8fHYt28fhg8fjnbt2mHbtm0Z1r9y5QoaN24MgUAAW1tbjB49GgkJCYrHAwMDUatWLZiYmMDa2hp9+vRBVFQUAODNmzdo1qwZAKBo0aLgcDgYMGAAgJRm/9GjR8PS0hKGhoZo1KgRbt26pdhvarfwqVOnULNmTRgYGODKlSsqXbFyuRxz585FqVKlYGBggOrVq+P06dOaebIIIaSAq127NmrVqoUuXbrg4cOHlNQVEpTYZVFCQkK6P78vuZJRXZFIlKW62bF//35UrFgRFSpUQL9+/RAQEADGWJp1X758idatW6Nr1664f/8+9u3bhytXrsDHx0dRRyKRYN68ebh37x6OHDmCN2/eKJI3W1tbHDp0CADw7NkzfPr0CatWrQIATJo0CYcOHcL27dsRFhaGcuXKwd3dHd+/f1eKYfLkyVi8eDGePHmCqlWrqsS4atUqLF++HH/99Rfu378Pd3d3dOzYEf/991+2nh9CCCnIGGMIDAxU/E3S19fH6dOncejQIVhaWuo4OpJbKLHLotRuwrR+unbtqlTX0tISpqamKFWqFExNTZXqtmnTRqmunZ1dmvvMDn9/f/Tr1w8A0Lp1a8TExODixYtp1l20aBH69u2LsWPHwtHREQ0aNMDq1auxY8cOxYfCwIED0aZNGzg4OKBevXpYvXo1Tp06hfj4eHC5XJibmyvO19raGmZmZkhISMCGDRuwbNkytGnTBk5OTti8eTMEAgH8/f2VYpg7dy5atWqFsmXLKvb1q7/++gu+vr7o1asXKlSogCVLlqB69erw8/PL1vNDCCEF1YcPH9CmTRt4eHhg+vTpinJTU1Nw8sl4QKIZlNgVEM+ePcPNmzfRu3dvACnf1Hr27KmSTKW6d+8etm3bppRMuru7Qy6X4/Xr1wCAO3fuoEOHDihdujRMTEzg6uoKAIiIiEg3jpcvX0IikaBhw4aKMh6Phzp16uDJkydKdWvVqpXufmJjY/Hx40el/QBAw4YNVfZDCCGF2Z49e+Ds7IygoCAYGhqidOnSug6J6JDOb55Yt24dli1bhsjISFSrVg1r1qxBnTp10q3v5+eHDRs2ICIiAsWLF0e3bt2waNEirS9UHB8fn+5jXC5X6feoqCjI5XLExsbC1NRU6Zby328vf/PmjUbi8/f3h1QqVbpZgjEGAwMDrF27VqV+fHw8hg4ditGjR6s8Vrp0aSQkJMDd3R3u7u7YtWsXLCwsEBERAXd3d4jFYo3EbGREg6EJISS7vn37hpEjR2Lfvn0AUr4s79ixA5UqVdJxZESXdJrY7du3D+PGjcPGjRtRt25d+Pn5wd3dHc+ePUtzPMDu3bsxefJkBAQEoEGDBnj+/DkGDBgADoeDFStWaDVWdZIQIyMjyOVyyGQyGBkZZThXkCaSG6lUih07dmD58uVwc3NTeqxz587Ys2cPKlasqFReo0YNPH78GOXKlUtznw8ePMC3b9+wePFixULQt2/fVqrD5/MBADKZTFFWtmxZ8Pl8XL16FWXKlAGQMlbv1q1bGDt2bJbPydTUFCVKlMDVq1cVLYUAcPXq1QwTf0IIKQyuXbuGbt264dOnT+ByuZgxYwamTp0KHo+n69CIjum0K3bFihXw9vaGl5cXnJycsHHjRgiFQgQEBKRZ/9q1a2jYsCH69OkDOzs7uLm5oXfv3rh582YuR563HD9+HD9+/MCgQYPg7Oys9NO1a9c0u2N9fX1x7do1+Pj4IDw8HP/99x+OHj2quHmidOnS4PP5WLNmDV69eoVjx45h3rx5SvsoU6YMOBwOjh8/ji9fviA+Ph5GRkYYPnw4Jk6ciNOnT+Px48fw9vZGYmIiBg0apNZ5TZw4EUuWLMG+ffvw7NkzTJ48GeHh4RgzZkz2nyxCCCkASpUqhYSEBFSsWBHXr1/HrFmzKKkjAHTYYicWi3Hnzh1MmTJFUaanp4eWLVsiNDQ0zW0aNGiAnTt34ubNm6hTpw5evXqFkydPon///rkVdp7k7++Pli1bwszMTOWxrl27YunSpbh//75SedWqVXHx4kVMmzYNjRs3BmMMZcuWRc+ePQEAFhYW2LZtG6ZOnYrVq1ejRo0a+Ouvv9CxY0fFPkqWLIk5c+Zg8uTJ8PLygoeHB7Zt24bFixdDLpejf//+iIuLQ61atRAUFISiRYuqdV6jR49GTEwMxo8fj6ioKDg5OeHYsWNwdHTMxrNEChvGGEQSWeYVs0gk/bkvkUQGMKnG9p0diWLNnRvJH169eqX4f+nSpXHmzBlUrVoVAoFAh1GRvIbD0psPQ8s+fvyIkiVL4tq1a6hfv76ifNKkSbh48SJu3Eh7KZnVq1djwoQJYIxBKpVi2LBh2LBhQ7rHSU5ORnJysuL32NhY2Nra4uvXryozbyclJeHdu3ews7PL8Zg9xhji4uJgYmJCdyTlEXRNfkpKSsKbN29ga2ur9fGpmZFIJAgODkarVq001uLAGEOvLbcQFhGtkf0BADhimFRMWSw97ulcgPE1t+8cujejOYR8zX1P18Y1UZs4Abxl/x/OMfFtoZ6gODk5GXPmzMGKFSswY8YMTJo0iVrn8pDceL/ExsaiePHiiImJyXTVEJ3fPKGOkJAQLFy4EOvXr0fdunXx4sULjBkzBvPmzcOMGTPS3GbRokWYM2eOSvmZM2cgFCovUaOvrw9ra2vEx8dr7AaBuLg4jeyHaA5dk5QWc5FIhEuXLkEq1W3LU6rg4GCN7StZBoRF5KuPt2yzN2G4EHxGKytcafKaqIsrS0b7//8/KOgMZFwDncWiS69fv4afnx/evn0LALh//75OrwtJnzavS2JiYpbr6qzFTiwWQygU4uDBg+jcubOi3NPTE9HR0Th69KjKNo0bN0a9evWwbNkyRdnOnTsxZMgQxMfHp3mTArXYkVR0TX4q6C12iWIpqs07DwC47usKAZ+byRaZE0lFaHUk5Uae4M4XIdDPG91fAh5X469narHTPZlMhuXLl2POnDmKJcHWrFkDQ0ND3V4XooJa7P6Pz+ejZs2aOHfunCKxk8vlOHfunNLqB79KTExUSd5SpxpJLz81MDCAgYHqNz0ej6dyAWQyGTgcDvT09DK8kzUr5HI5ACj2R3SPrslPenp64HA4ab4PdEWTsfDYz0TH1MhQI92UPMnPzxhToSGEvLyR2GmTTl8f7OdxeTwekEdep7nh5cuX8PDwwLVr1wAAnTp1wqZNm1C0aFGcPHkyT71vyU/avC7q7FenfRXjxo2Dp6cnatWqhTp16sDPzw8JCQnw8vICAHh4eKBkyZJYtGgRAKBDhw5YsWIFXFxcFF2xM2bMQIcOHVTmkiOEEELyo7CwMFy7dg0mJiZYvXo1PD09weFwIJFIdB0ayQd0mtj17NkTX758wcyZMxEZGalY5N3KygpAygoHv7asTJ8+HRwOB9OnT8eHDx9gYWGBDh06YMGCBRqNS0e904TkGnqNE5K3yGQyRQNF9+7dsXjxYvTq1UsxHyghWaXz0cU+Pj7pdr2GhIQo/a6vr49Zs2Zh1qxZWokltakzMTGRbh8nBVrqQFzqziFE9/bv349Zs2bh4sWLisn5fX19dRwVya90ntjlJVwuF0WKFEFUVBQAQCgUZntQslwuh1gsRlJSUqEfz5VX0DVJaalLTExEVFQUihQpQkMYCNGh79+/w8fHB3v27AEA/PXXX1i6dKmOoyL5HSV2v7G2tgYARXKXXYwxiEQiCASCQn8HZl5B1+SnIkWKKF7rhJDcFxQUhIEDB+Ljx4/gcrmYNm0apk+fruuwSAFAid1vOBwObGxsYGlpmaOBqhKJBJcuXUKTJk2ouyuPoGuSgsfjUUsdITqSkJCAiRMnKibWL1++PAIDA2kNbKIxlNilg8vl5uiPH5fLhVQqhaGhYaFOIvISuiaEEF1bsGCBIqkbPXo0Fi1apDJZPiE5UTgHGhFCCCE6MGXKFDRp0gRnz57FqlWrKKkjGkeJHSGEEKIlDx48wNixYxVTDJmYmODixYto0aKFjiMjBRUldoQQQoiGyWQyLFu2DLVq1cKqVauwefNmXYdECgkaY0cIIYRo0KtXr+Dp6YkrV64ASFk1qWPHjjqOihQW1GJHCCGEaABjDJs3b0bVqlVx5coVGBsbw9/fH0ePHqXphUiuoRY7QgghRAPGjBmDNWvWAACaNGmCbdu2wd7eXsdRkcKGWuwIIYQQDejXrx+MjIzw119/4cKFC5TUEZ2gFjtCCCEkG378+IHQ0FC0bdsWAFCnTh28ffsWxYoV03FkpDCjxI4Qkq8wxiCSijKsI5LKAI74//8XAZycr7SR2TFJ4RIcHAwvLy98+fIFd+7cgbOzMwBQUkd0jhI7Qki+wRiDxykPhH8Jz7SuScWUf5semKndoEihkpCQAF9fX6xbtw4A4OjoCLFYrOOoCPmJxtgRQvINkVSUpaROm1wsXSDQF+g0BqIb169fh4uLiyKp8/HxQXh4OGrUqKHjyAj5iVrsCCmkGGMQSWS6DgMSiRTJMiBRLAWPcTKsK5L+jPdUl3PpJliJYhkaL7kAALgzoyUEvJx3xaYS6AvA4WQcJyl45s6dizlz5kAul6NkyZLYunUrWrVqpeuwCFFBiR0hhRBjDN02huLO2x+6DuX/9DHp5vnMq3HEii7WRouuAoyfQeWUxwT6Agh59FFHcobP50Mul6Nfv35YvXo1ihYtquuQCEkTfdoRUgiJJLI8lNRpT60yRTXaWkcKD5lMhqioKNjY2AAAJk6ciBo1asDNzU3HkRGSMUrsCCnkbk9vCSFfd8mPRCJBUNAZuLu7gcfjZVhXJBUpboa4M6NlpmPdBDwudZsStb1+/RoDBgxQ3PEqEAjA5XIpqSP5AiV2hBRyQj4XQr7uPgokHAYDLiDk64OXWZfpL9OWCHhc6mLVNMYASSIgkYArSwbECQDLONnWGnFirh+SMYaAgACMHTsW8fHxMDY2Rnh4OOrXr5/rsRCSXfSpSAghJCWpC3AH3t0AD0B7ALiv45hyUWRkJLy9vXH8+HEAQKNGjbB9+3Y4ODjoODJC1EPTnRBCCElpqXt3Q9dRqLKtB/CEWj3EoUOH4OzsjOPHj4PP52Pp0qUICQmhpI7kS9RiRwghRIlk7BMEnb+SpXGPWscTAlocJ8kYw/r16/Ht2zdUq1YNgYGBqFKlitaOR4i2UWJHCCFEGU8IGdcA4BsBuk7stIQxBg6HAw6Hg61bt8Lf3x/Tpk0Dn5/RFDqE5H3UFUsIIaTQSExMxOjRo+Hj46MoK126NObMmUNJHSkQqMWOEKI2xhhEUpFG9iWVSiFmYoikIkggybCupo5JCqebN2+if//+eP78OQBg5MiRcHJy0nFUhGgWJXaEELUwxuBxykPja7bO3T9Xo/sjJJVEIsH8+fOxYMECyGQylChRAgEBAZTUkQKJEjtCiFpEUpHGkzp1uVi6ZDo5MSEA8PjxY/Tv3x9hYWEAgN69e2Pt2rUwNzfXcWSEaAcldoSQbAvpEZLjBEsqlSIoKAju7u7Q18/aR5JAX0ArSpBMicViuLu74/379zA3N8f69evRs2dPXYdFiFZRYkcIyTaBvgDCHM4xJoEEfA4fAn2B7qfWIAUKn8/HypUrERAQgC1btqBEiRK6DokQraO7YgkhhBQIjDFs3boVx44dU5R169YNJ06coKSOFBrUYkcIISTf+/z5M4YMGYJjx46hePHiePz4MSwsLACAuu1JoUItdoQQQvK1f/75B1WqVMGxY8fA4/EwYcIEujmCFFrUYkcIISRfiomJwZgxY7B9+3YAQNWqVREYGIiqVavqODJCdIcSO0IIIflOdHQ0qlWrhoiICOjp6WHSpEmYPXs2DAwMdB0aITpFiR0hhJB8p0iRInBzc8OFCxewfft2NGzYUNchEZInUGJHCCEkX7h16xZsbGxQqlQpAMDKlSsBAMbGxroMi5A8JUc3TyQlJWkqDkIIISRNEokEs2fPRv369TFw4EAwxgCkJHSU1BGiTO0WO7lcjgULFmDjxo34/Pkznj9/DgcHB8yYMQN2dnYYNGiQNuIkhKSBMQaRVKT0e5JUnul2iWIZwBEDSFkiDBxulo/56/FIHscYIEnMWl1xFuvlsidPnqB///64c+cOAMDc3BwikQhCYc4mxiakoFI7sZs/fz62b9+OpUuXwtvbW1Hu7OwMPz8/SuwIySWMMXic8sj2uq0mFVP+bXpgpuaCInkHY0CAO/Duhq4jyRa5XI41a9Zg8uTJSEpKQtGiRbF+/Xr06tVL16ERkqep3RW7Y8cObNq0CX379gWX+/NbfrVq1fD06VONBkcISZ9IKsp2UqcJLpYuOV4nlmiRJDF7SZ1tPSCHy8Tl1OfPn9GyZUuMHTsWSUlJcHd3x4MHDyipIyQL1G6x+/DhA8qVK6dSLpfLIZFINBIUIUQ9IT1CAMZHzXlnAQCXfZtByM+8e9VQXy/bs/IL9AU0o39+MeEFwM9issYTAlKpduPJhImJCT5+/AihUIjly5dj6NCh9FojJIvUTuycnJxw+fJllClTRqn84MGDcHFx0VhghJCsE+gLAMZP+QFQTGgMIZ9ueif/xxcCfCNdR5Ghb9++oUiRIuByuRAKhdi3bx+MjIzSbEgghKRP7U/+mTNnwtPTEx8+fIBcLsfhw4fx7Nkz7NixA8ePH9dGjIQQQgqwo0ePYsiQIZg0aRLGjx8PIGV4DyFEfWqPsevUqRP+/fdfnD17FkZGRpg5cyaePHmCf//9F61atdJGjIQQQgqg2NhYDBw4EJ07d0ZUVBT27t0LmUym67AIydey1VfTuHFjBAcHazoWQgghhURISAgGDBiAt2/fgsPhYOLEiZg7d67STXmEEPWp3WLn4OCAb9++qZRHR0fDwcFBI0ERQggpmEQiEcaNG4dmzZrh7du3sLe3x6VLl7BkyRJa55UQDVA7sXvz5k2aTeXJycn48OGDRoIihBBSML18+RJr164FAAwZMgT37t1Do0aNdBwVIQVHlrtijx07pvh/UFAQzMzMFL/LZDKcO3cOdnZ2Gg2OEEJI/scYU0xX4uzsjNWrV6N06dJo27atjiMjpODJcmLXuXNnAACHw4Gnp6fSYzweD3Z2dli+fLlGgyOEEJK/PXv2DIMGDcKqVatQs2ZNAMCwYcN0HBUhBVeWu2LlcjnkcjlKly6NqKgoxe9yuRzJycl49uwZ2rdvr81YCSGE5BOpS4JVr14dV69exZgxY3QdEiGFgtp3xb5+/VobcRBCCCkg3r17By8vL5w7dw4A4ObmhoCAAB1HRUjhkK3pThISEnDx4kVERERALBYrPTZ69GiNBEYIISR/YYxh586d8PHxQWxsLAQCAf766y8MHz6clgQjJJeondjdvXsXbdu2RWJiIhISEmBubo6vX79CKBTC0tKSEjtCCCmkjh8/Dg8PDwBA3bp1sWPHDpQvX17HURFSuKg93cmff/6JDh064MePHxAIBLh+/Trevn2LmjVr4q+//tJGjIQQQvKBdu3aoU2bNpg/fz6uXLlCSR0hOqB2YhceHo7x48dDT08PXC4XycnJsLW1xdKlSzF16lRtxEgIISQPio2NxZQpUxAfHw8A0NPTw/HjxzFt2jTo62drpA8hJIfUTux4PB709FI2s7S0REREBADAzMwM796902x0hBBC8qSLFy+iWrVqWLx4MSZMmKAoT/37QAjRDbW/Urm4uODWrVtwdHSEq6srZs6cia9fvyIwMBDOzs7aiJEQQkgekZSUhOnTp2PFihVgjMHOzg59+vTRdViEkP9TO7FbuHAh4uLiAAALFiyAh4cHhg8fDkdHR/j7+2s8QEII0RnGAEmirqPIHrHm4w4LC0P//v3x+PFjAMDgwYOxYsUKmJiYaPxYhJDsUTuxq1WrluL/lpaWOH36dI4CWLduHZYtW4bIyEhUq1YNa9asQZ06ddKtHx0djWnTpuHw4cP4/v07ypQpAz8/P1qahhCiWYwBAe7Auxu6jiRPOHDgAPr06QOpVAorKyts2bKFJqUnJA/S2GCIsLAwtd/k+/btw7hx4zBr1iyEhYWhWrVqcHd3R1RUVJr1xWIxWrVqhTdv3uDgwYN49uwZNm/ejJIlS2riFAgh5CdJYsFI6mzrATxhjnfTuHFjmJmZoWvXrnj48CEldYTkUWq12AUFBSE4OBh8Ph+DBw+Gg4MDnj59ismTJ+Pff/+Fu7u7WgdfsWIFvL294eXlBQDYuHEjTpw4gYCAAEyePFmlfkBAAL5//45r166Bx+MBAOzs7NQ6JiGEqG3CC4Cf8+RIJ3hCIBuTA8vlcpw9exZt2rQBAFhbW+Pu3bsoVaoUTTZMSB6W5cTO398f3t7eMDc3x48fP7BlyxasWLECo0aNQs+ePfHw4UNUqlQpywcWi8W4c+cOpkyZoijT09NDy5YtERoamuY2x44dQ/369TFy5EgcPXoUFhYW6NOnD3x9fcHlcrN8bEIIUQtfCPCNdB1Frnn//j3mzJmDe/fu4dChQ/jjjz8AALa2tjqOjBCSmSwndqtWrcKSJUswceJEHDp0CN27d8f69evx4MEDlCpVSu0Df/36FTKZDFZWVkrlVlZWePr0aZrbvHr1CufPn0ffvn1x8uRJvHjxAiNGjIBEIsGsWbPS3CY5ORnJycmK32NjYwEAEokEEolE7bizKnXf2jwGUU9BuyZSqVTp/0z+sxVFIpFAwmG6CEttefa6SCTgKf4rATh5LD4tYIxhz549GDNmDGJiYiAQCPDt27e8d20KqTz7XinkcuO6qLPvLCd2L1++RPfu3QEAf/zxB/T19bFs2bJsJXXZJZfLYWlpiU2bNoHL5aJmzZr48OEDli1blm5it2jRIsyZM0el/MyZMxAKtd+1EhwcrPVjEPUUlGsiZj/XaQ4KCgKT85H6lg4KOgODfNaIndeuC1eWjNRRZEFBZyDjGug0Hm2LjY3Fxo0bce3aNQCAo6Mjxo4dC0tLS5w8eVLH0ZFf5bX3CkmhzeuSmJj1u9yznNiJRCJFIsThcGBgYAAbGxv1o/u/4sWLg8vl4vPnz0rlnz9/hrW1dZrb2NjYgMfjKXW7VqpUCZGRkRCLxeDz+SrbTJkyBePGjVP8HhsbC1tbW7i5ucHU1DTb8WdGIpEgODgYrVq1UowHJLpV0K6JSCrC3P1zAQDu7u5gch4m3Tz//9/dIOTnj5n/8+x1EScA91P+6+7uVqC7YoODgzFp0iRERkZCX18fU6dORbVq1dC6deu8dU0KuTz7XinkcuO6pPY2ZoVan/xbtmyBsbExgJSun23btqF48eJKdUaPHp2lffH5fNSsWRPnzp1D586dAaS0yJ07dw4+Pj5pbtOwYUPs3r0bcrlcMbv58+fPYWNjk2ZSBwAGBgYwMFD9ps3j8XLljZFbxyFZV1CuiQQ/m+b19fUB9vOcUs4xfyR2qfLcdfnt+UReik3DGGOIjIyEk5MTAgMDUaVKFZw8eTLvXRMCIA++VwgA7V4Xdfab5U/+0qVLY/PmzYrfra2tERgYqFSHw+FkObEDgHHjxsHT0xO1atVCnTp14Ofnh4SEBMVdsh4eHihZsiQWLVoEABg+fDjWrl2LMWPGYNSoUfjvv/+wcOFCtY5JCCEE+PHjB4oWLQoAaNeuHfbv348OHTrA0NCQxnARko9lObF78+aNxg/es2dPfPnyBTNnzkRkZCSqV6+O06dPK26oiIiIUFp30NbWFkFBQfjzzz9RtWpVlCxZEmPGjIGvr6/GYyOEkIIoKSkJM2fOhL+/P+7du6cYJ506hpoQkr/pvK/Gx8cn3a7XkJAQlbL69evj+vXrWo6KEEIKnvDwcPTv3x8PHz4EABw6dAhjxozRcVSEEE3S2MoThBBC8iapVIqFCxeiTp06ePjwISwtLXH06FFK6ggpgHTeYkcIIUR7/vvvP3h6eiomfu/SpQv+/vtvWFhY6DgyQog2UIsdIYQUYH///TdCQ0NhamqK7du349ChQ5TUEVKAUYsdIYQUYPPmzUNMTAxmzJiB0qVL6zocQoiWZavF7uXLl5g+fTp69+6NqKgoAMCpU6fw6NEjjQZHCCEk61KXBOvUqRNkMhkAQCAQYPPmzZTUEVJIqJ3YXbx4EVWqVMGNGzdw+PBhxMfHAwDu3buX7rJehBBCtOvbt2/o1asX+vTpg2PHjmHHjh26DokQogNqJ3aTJ0/G/PnzERwcrLTaQ/PmzWkaEkII0YGTJ0/C2dkZ+/fvB5fLxZw5c9CvXz9dh0UI0QG1x9g9ePAAu3fvVim3tLTE169fNRIUIYUFYwwiqShb22Z3O1JwxMfHY/z48di0aRMAoGLFiggMDEStWrV0HBkhRFfUTuyKFCmCT58+wd7eXqn87t27KFmypMYCI6SgY4zB45QHwr+E6zoUkk/1798fR44cAQCMHTsWCxcuhEAg0G1QhBCdUrsrtlevXvD19UVkZCQ4HA7kcjmuXr2KCRMmwMPDQxsxElIgiaQijSR1LpYuEOjTH/PCaM6cOXB0dMT58+excuVKSuoIIeq32C1cuBAjR46Era0tZDIZnJycIJPJ0KdPH0yfPl0bMRJS4IX0CMl2cibQF4DD4Wg4IpIX3bt3D7du3cLgwYMBAFWrVsWTJ0/A5XJ1HBkhJK9QO7Hj8/nYvHkzZsyYgYcPHyI+Ph4uLi5wdHTURnyEFAoCfQGEPKGuwyB5lEwmw7JlyzBz5kzI5XJUr15dMY6OkjpCyK/UTuyuXLmCRo0aoXTp0jQvEiGEaNmLFy/g6emJa9euAQA6depEn72EkHSpPcauefPmsLe3x9SpU/H48WNtxEQIIYUeYwwbN25EtWrVcO3aNZiYmGDr1q34559/YGlpqevwCCF5lNqJ3cePHzF+/HhcvHgRzs7OqF69OpYtW4b3799rIz5CCCl0GGPo3r07hg8fjsTERDRr1gwPHjzAgAEDaDwlISRDaid2xYsXh4+PD65evYqXL1+ie/fu2L59O+zs7NC8eXNtxEiITjDGkCiWau1HJJEpjiWSyDSwT1kGZ0PyEw6Hg6ZNm8LAwAArV67E2bNnUaZMGV2HRQjJB9QeY/cre3t7TJ48GdWqVcOMGTNw8eJFTcVFiE4xxtBtYyjuvP2hvYNwxDCpmPLfmvPOAoyfcX1SoH3//h0fP36Es7MzAGDEiBFo27YtHBwcdBwZISQ/UbvFLtXVq1cxYsQI2NjYoE+fPnB2dsaJEyc0GRshOiOSyLSb1GlRrTJFIeDRnZL5SVBQEKpUqYJOnTop1t/W09OjpI4Qoja1W+ymTJmCvXv34uPHj2jVqhVWrVqFTp06QSikqRpIwXR7eksI+ZpPlERSEZoemAkAuDOjpcYmGRbwuDQOK59ISEjAxIkTsWHDBgBAhQoV8OnTJ5o+ihCSbWondpcuXcLEiRPRo0cPFC9eXBsxEZKnCPlcCPk5GrWQNs7PZFHA40LI08IxSJ517do1eHh44OXLlwCAMWPGYOHChfQlmRCSI2r/Jbl69ao24iCEkEJBKpVi5syZWLJkCeRyOWxtbbFt2za6+YwQohFZSuyOHTuGNm3agMfj4dixYxnW7dixo0YCI4SQgojL5eLBgweQy+Xw8PDA6tWrYWZmpuuwCCEFRJYSu86dOyMyMhKWlpbo3LlzuvU4HA5kMppygRBCfiWTyZCcnAyhUAgOh4PNmzcjNDQUXbp00XVohJACJkt3xcrlcsVM53K5PN0fSuoIIUTZq1ev0LRpUwwbNkxRZm1tTUkdIUQr1J7uZMeOHUhOTlYpF4vF2LFjh0aCIoSQ/I4xhk2bNqFq1aq4cuUKjhw5gnfv3uk6LEJIAad2Yufl5YWYmBiV8ri4OHh5eWkkKEIIyc8+ffqE9u3bY+jQoUhISICrqyvu378PW1tbXYdGCCng1E7sGGNpzpH1/v17GgBMCCn0Dhw4AGdnZ5w8eRIGBgZYvnw5zp8/Dzs7O12HRggpBLI83YmLiws4HA44HA5atGgBff2fm8pkMrx+/RqtW7fWSpCEEJJjjAGSxKzXF6tR9//i4+MxevRofP/+HS4uLggMDETlypXV3g8hhGRXlhO71Lthw8PD4e7uDmNjY8VjfD4fdnZ26Nq1q8YDJISQHGMMCHAH3t3Q6mGMjY3h7++P0NBQzJgxA3w+rf9LCMldWU7sZs2aBQCws7NDz549YWhoqLWgCCFEoySJ2U/qbOsBvLRXg0hISICvry/q16+Pvn37AgDatm2Ltm3bZjdSQgjJEbVXnvD09NRGHIQQkjsmvAD4aizbxRMCaYwrDg0NhYeHB168eIHdu3ejQ4cOMDU11WCghBCiviwldubm5nj+/DmKFy+OokWLZrjA+Pfv3zUWHCGEaBxfCPCNsr25WCzGnDlzsHjxYsjlcpQqVQpbt26lpI4QkidkKbFbuXIlTExMFP/PKLEjhJCC6uHDh+jfvz/Cw8MBAP369cOaNWtQpEgRncZFCCGpspTY/dr9OmDAAG3FQki+xBiDSCpSe7vsbEN05+PHj6hduzaSkpJQrFgxbNy4Ed26ddN1WIQQokTtMXZhYWHg8XioUqUKAODo0aPYunUrnJycMHv2bLoLjBQqjDF4nPJA+JdwXYdCtKxEiRIYNmwY/vvvP2zevBk2Nja6DokQQlSoPUHx0KFD8fz5cwApayD27NkTQqEQBw4cwKRJkzQeICF5mUgqynFS52LpAoG+QDMBEY1hjMHf3x8vX75UlC1duhT//vsvJXWEkDxL7Ra758+fo3r16gBSZlh3dXXF7t27cfXqVfTq1Qt+fn4aDpGQ/CGkR0i2EjSBvoDGreYxkZGR8Pb2xvHjx9GwYUNcvHgRXC4XPB5P16ERQkiG1E7sGGOQy+UAgLNnz6J9+/YAAFtbW3z9+lWz0RGSjwj0BRCmM98ZyT8OHTqEoUOH4tu3b+Dz+YrJ2QkhJD9QO7GrVasW5s+fj5YtW+LixYvYsGEDAOD169ewsrLSeIAk9zDGIJLIdB2G1kgkUiTLgESxFDyWcQtZorjgPg8kbdHR0Rg1ahR27twJAKhevToCAwPh7Oys48gIISTr1E7s/Pz80LdvXxw5cgTTpk1DuXLlAAAHDx5EgwYNNB4gyR2MMXTbGIo7b3/oOhQt08ekm+d1HQTJY54/f44WLVrg/fv30NPTw5QpUzBz5ky6GYwQku+ondhVrVoVDx48UClftmwZuFyuRoIiuU8kkRWCpE59tcoUhYBHr+uCzs7ODsWKFYOhoSF27NiB+vXr6zokQgjJFrUTu1R37tzBkydPAABOTk6oUaOGxoIiunV7eksI+QUvmZFIJAgKOgN3d7csD4IX8Lh0Y0MBdffuXTg7O4PH44HP5+PIkSOwsLCAkVH2V6UghBBdUzuxi4qKQs+ePXHx4kXFbOvR0dFo1qwZ9u7dCwsLC03HSHKZkM+FkJ/tnD/PknAYDLiAkK8PHq/gnR/JGrFYjHnzFmPhwoWYOXMmZs2aBSCl1Y4QQvI7teexGzVqFOLj4/Ho0SN8//4d379/x8OHDxEbG4vRo0drI0ZCCNGIR1Ey1G/SHPPnz4dcLserV6/AGNN1WIQQojFqN1ucPn0aZ8+eRaVKlRRlTk5OWLduHdzc3DQaHCGEaIJcLodfaDKmnktGsiwc5ubm2LBhA3r06KHr0AghRKPUTuzkcnma45N4PJ5ifjtCCMkrIiIi4NG/Ly5eSgYAtHF3w5aArShRooSOIyOEEM1TO7Fr3rw5xowZgz179ig+GD98+IA///wTLVq00HiAhGgbYwwiqShb22Z3O6IBjAGSxEyriWK+4eatOzDiASvdDTH44CFwDIxzIUBCCMl9aid2a9euRceOHWFnZwdbW1sAwLt37+Ds7KyY2JOQ/IIxBo9THjle75XkMsaAAHfg3Y00HxZJGAS8lLuZKwDY1QGoamWMsuZ6AN3lTAgpwNRO7GxtbREWFoZz584ppjupVKkSWrZsqfHgCNE2kVSkkaTOxdIlW+vEkmySJKab1P3zRILhJ5JwsIcAjUqnfMR1qfT/4SO29QBa9o0QUoCpldjt27cPx44dg1gsRosWLTBq1ChtxUVIrgvpEZLt5EygL6D57nRlwguAL0RMTAxGj5uIHft3AwCWf2uORhv3KtflCanFjhBSoGU5sduwYQNGjhwJR0dHCAQCHD58GC9fvsSyZcu0GR8huUagL4CQWnPyH74Q5y5fh5eXF969ewc9PT34+vqmzE/HN9B1dIQQkquyPI/d2rVrMWvWLDx79gzh4eHYvn071q9fr83YCCEkQyIJw9jxk9CyZUu8e/cOZcuWxeXLl7Fw4UIYGFBSRwgpfLKc2L169Qqenp6K3/v06QOpVIpPnz5pJTBCCMnM0WdSrFqb8gVz+PDhCA8PR4MGDXQcFSGE6E6Wu2KTk5OV1lDU09MDn8+HSETTPRBCdKNnZX2cNxuAP7r3ROvWrXUdDiGE6JxaN0/MmDEDQuHPMUhisRgLFiyAmZmZomzFihWai44QQn7x5MkTTJ48Gds3r0cRABwOB5s2rAX4RpltSgghhUKWE7smTZrg2bNnSmUNGjTAq1evFL/TXYGEEG2Qy+VYvXo1Jk+ejOTkZEy2LI6NJXUdFSGE5D1ZTuxCQkK0GAYhhKTt7du3GDBggOIzqHXr1pg5bQqw7aBuAyOEkDwoyzdPEEJIbmKMYdu2bahSpQpCQkIgFAqxceNGnDx5EiVK2Og6PEIIyZPUXnmCEEJyw8qVKzF+/HgAKcM+tm/fjnLlyuk4KkIIydvyRIvdunXrYGdnB0NDQ9StWxc3b97M0nZ79+4Fh8NB586dtRsgyfMYY0iUJGb4I5KKIGZiiKQipTKSN3l6eqJMmTJYvHgxLl26REkdIYRkgc5b7Pbt24dx48Zh48aNqFu3Lvz8/ODu7o5nz57B0tIy3e3evHmDCRMmoHHjxrkYLcmLGGPwOOWR5TVf5+6fq92ASLbExMRg//79GD58ODgcDooVK4anT5/C0NBQ16ERQki+ofMWuxUrVsDb2xteXl5wcnLCxo0bIRQKERAQkO42MpkMffv2xZw5c+Dg4JCL0eY/jDEkiqVZ+JHpOtRsE0lFWU7q0uNi6ZLtdWJJzj148AA1a9bEyJEjsWvXLkU5JXWEEKKebLXYXb58GX///TdevnyJgwcPomTJkggMDIS9vT0aNWqU5f2IxWLcuXMHU6ZMUZTp6emhZcuWCA0NTXe7uXPnwtLSEoMGDcLly5czPEZycjKSk5MVv8fGxgIAJBIJJBJJlmNVV+q+tXmMzDDG0GvLLYRFRKu1nUQigYTDtBOUFkilUsX/z/5xNt0ETSKR4Pz582jevDl4PJ7SY4ZcQ6X9kNwhEokwdepUrFu3DgDg4OAAW1vbzN83Egl4iv9KAI7u3mcFUV74/CKq6LrkTblxXdTZt9qJ3aFDh9C/f3/07dsXd+/eVSRNMTExWLhwIU6ePJnlfX39+hUymQxWVlZK5VZWVnj69Gma21y5cgX+/v4IDw/P0jEWLVqEOXPmqJSfOXNGabJlbQkODtb6MdKTLAPCItS7xPYmDBeCzyA/TUkoZmLF/y+duwQ+h59uXT6HjysXruRGWCQTL168gJ+fH96/fw8AcHd3x4ABAxAdHZ3p5whXloz2//9/UNAZyLi0Lqw26PLzi6SPrkvepM3rkpiYmOW6aid28+fPx8aNG+Hh4YG9e/cqyhs2bIj58+eruzu1xMXFoX///ti8eTOKFy+epW2mTJmCcePGKX6PjY2Fra0t3NzcYGpqqq1QIZFIEBwcjFatWqm0DuWWRLEUk26eBwBc93WFgM/NdBsBj5vvJpoWSUWKcXPu7u4Zttjp+pqQFBs2bICvr6/ii523tzemTJmS9esiTgDup/zX3d2NVp7QMHqv5E10XfKm3Lguqb2NWaF2Yvfs2TM0adJEpdzMzAzR0dFq7at48eLgcrn4/PmzUvnnz59hbW2tUv/ly5d48+YNOnTooCiTy+UAAH19fTx79gxly5ZV2sbAwAAGBqrf5nk8Xq68MXLrOGkem/1M0EyNDCHk6/xeGa2Q4GcTtb6+fqbPty6vCUlRpUoVyGQydO/eHatXr8aNGzfA09cH75fW1wyxn9ecx+MBdD21gt4reRNdl7xJm9dFnf2q/Zfe2toaL168gJ2dnVL5lStX1L6Rgc/no2bNmjh37pxiyhK5XI5z587Bx8dHpX7FihXx4MEDpbLp06cjLi4Oq1atgq2trVrHJ4TkDrlcjsePH8PZ2RkA0KxZM9y5cwcuLi4pYxsZA3dHO+B91qY6IoQQkja1Eztvb2+MGTMGAQEB4HA4+PjxI0JDQzFhwgTMmDFD7QDGjRsHT09P1KpVC3Xq1IGfnx8SEhLg5eUFAPDw8EDJkiWxaNEiGBoaKv4wpCpSpAgAqJQTQvKGiIgIeHl54caNG7h3756iVb1GjRqKOly5GHrZSeps6wE87Y+VJYSQ/ELtxG7y5MmQy+Vo0aIFEhMT0aRJExgYGGDChAkYNWqU2gH07NkTX758wcyZMxEZGYnq1avj9OnTihsqIiIioKen81lZCCFqYoxh586d8PHxQWxsLAQCAe7fv68yXELFhBcAP4vJGk+IfHWnDyGEaJnaiR2Hw8G0adMwceJEvHjxAvHx8XBycoKxsXG2g/Dx8Umz6xWAYuHv9Gzbti3bxyWEaMeXL18wbNgwHD58GABQr1497NixA46OjplvzBfSzRCEEJJN2R5Nz+fz4eTkpMlYCCEFwL///ovBgwcjKioK+vr6mDNnDiZNmgR9/YJ58w4hhOQlan/SNmvWLMPpMM6fP5+jgAgh+dv169cRFRWFypUrIzAwEC4uLroOiRBCCg21E7vq1asr/S6RSBAeHo6HDx/C09NTU3ERHWGMQSQV6ToMteS3eAsisVgMPj9lYuhZs2bB3NwcI0eOpCXBCCEkl6md2K1cuTLN8tmzZyM+Pj7HARHdYYzB45RHjtddJYVHUlISpk2bhsuXL+Pq1avg8Xjg8/kYP368rkMjhJBCSWO3m/br1w8BAQGa2h3RAZFUlK+TOhdLl3RXnSCaFxYWhpo1a2LFihW4deuWWssJEkII0Q6NjWYODQ2lbpcCJKRHSL5LkgT6gny3HFp+JJVKsXjxYsyZMwdSqRRWVlbYsmUL2rdvn/nGhBBCtErtxO6PP/5Q+p0xhk+fPuH27dvZmqCY5E0CfQGENPEr+c2zZ8/g4eGBmzdTJhPu2rUrNm7cmOW1mwkhhGiX2omdmZmZ0u96enqoUKEC5s6dCzc3N40FRgjJe4YPH46bN2/CzMwM69atQ58+faiVlBBC8hC1EjuZTAYvLy9UqVIFRYsW1VZMhJA8auPGjZg4cSLWrl1LazMTQkgepNbNE1wuF25uboiOjtZSOISQvIIxhl27dmHevHmKsvLly+Po0aOU1BFCSB6ldless7MzXr16BXt7e23EQwjJA75+/Yrhw4fj4MGD4HA4aN26NWrXrq3rsAghhGRC7elO5s+fjwkTJuD48eP49OkTYmNjlX4IIfnb8ePH4ezsjIMHD0JfXx/z5s2j1SMIISSfyHKL3dy5czF+/Hi0bdsWANCxY0elQdOMMXA4HMhkMs1HSQjRuri4OIwbNw5btmwBADg5OSEwMBA1atTQcWSEEEKyKsuJ3Zw5czBs2DBcuHBBm/EQQnRALpejcePGuHfvHjgcDsaNG4f58+fT3JSEEJLPZDmxY4wBAFxdXbUWDCFEN/T09DB69GjMnTsX27dvp/c5IYTkU2rdPEHzVWkHYwwiiWa6sBljSJIlAQASxTKAIwaQslwYONwMtxVJRRqJgeQPd8PCEB/9FY0bNQQAePXtgZ5d2sPIyAgQJ+ReIBIJuPLk3DseIYQUYGolduXLl880ufv+/XuOAipsGGPotjEUd97+0MTeICyzEVzhW0WJScWUf5semKmB/ZOCQCqVYumSJZg9awYshcCD4cYoKuCAA8BIB/HwALTRwXEJIaQgUiuxmzNnjsrKEyRnRBKZhpI6AByJUlKXXS6WLvlunViSNf/99x88PDxw/fp1AECdkvqQMwYgj7TG29YDaCk7QgjJNrUSu169esHS0lJbsRR6t6e3hJCfcXdpRkRSkaJl7lSXc4rkzFBfT61udIG+gLrdCxjGGDZs2ICJEyciMTERpqamWNtcjH5VeeBMfAnwdZdMSSQSBAWdgbu7G3hCM4Bee4QQkm1ZTuzoD732CflcCPlqzxn90y9j6MwFxhBSywcBIBKJ0LlzZ5w5cwYA0Lx5c2z9ex1K76ybUoEvBPi66IT9P44EMq5BSgz0OUMIITmS5QmKU++KJYTkLwKBAEWLFoWhoSFWrVqF4OBglC5NS4IRQkhBlOXmIblcrs04CCEa9O3bNwBAsWLFAADr16/H7NmzUbFiRV2GRQghRMvUXlKMEJK3nThxAs7OzvD29la0tJubm1NSRwghhQAldoQUEPHx8Rg6dCjat2+PyMhIPHnyhKYfIoSQQoYSO0IKgCtXrqBatWrYtGkTAODPP/9EWFiYoiuWEEJI4UCJHSH5WHJyMnx9fdGkSRO8evUKpUuXxvnz57FixQoIBDQXISGEFDaU2BGSjyUnJ2Pfvn1gjGHAgAG4f/8+mjVrpuuwCCGE6EgOJk0jhOiCTCaDnl7KpNOmpqYIDAzEt2/f0LlzZ12HRgghRMcoscuDGGMQSUVqb5edbUj+8uLFC3h6esLDwwNDhw4FADRu3FjHURFCCMkrKLHLYxhj8DjlgfAv4boOheQhjDH8/fffGD9+PBITE/H69Wt4enrC0NBQ16ERQgjJQ2iMXR4jkopynNS5WLoo1okl+d/Hjx/Rtm1bDB8+HImJiWjWrBlCQ0MpqSOEEKKCWuzysJAeIdlK0AT6Alrbt4DYu3cvRowYgR8/fsDQ0BCLFy/GqFGjoKdH38kIIYSoosQuDxPoCyDkCXUdBtGR58+fo2/fvpDL5ahZsyYCAwNRqVIlXYdFCCEkD6PEjpA8qnz58pgxYwY4HA6mTp0KHo+n65AIIYTkcZTYEZJHxMfHY8qUKRg+fDicnJwAALNnz9ZtUIQQQvIVSuwIyQOuXbsGDw8PvHz5EtevX8eNGzdoHB0hhBC10V8OQnQoOTkZU6ZMQePGjfHy5UvY2tpiyZIllNQRQgjJFmqxI0RH7t+/j/79++P+/fsAAA8PD6xevRpmZmY6jowQQkh+RYmdljDGkCwDEsVS8Fj6U48kimW5GBXJK0JDQ+Hq6gqJRILixYvj77//xh9//KHrsAghhORzlNhpAWMMvbbcQliEPibdPK/rcEgeVLt2bdSsWRMWFhbYvHkzrKysdB0SIYSQAoASOy0QSWQIi4hWa5taZYpCwONCJNVOTES3GGPYs2cP/vjjDxgaGkJfXx+nT5+GqakpTSZNCCFEYyix07Lrvq4wNcp86ScBj0t/4AuoT58+YdCgQTh16hQmTpyIpUuXAgCNpSOEEKJxlNhpmYDPhZBPT3NhtX//fgwfPhzfv3+HgYEBSpQooeuQCCGEFGCUcRCiBd+/f4ePjw/27NkDAKhRowYCAwMVEw8TQggh2kCTZRGiYaGhoahSpQr27NkDLpeLGTNm4Pr165TUEUII0TpqsSNEw0qUKIG4uDiUL1/+f+3deVRTZ/4G8CeJWQDBpS6AotTdVpQiLriMU4tirdalFUY9SpGqo1I7MmrVWtFSFa1Sl3GpWtyGFtSpy88FBC1W1A5uaOuCVcEdXLqAsiQk7+8PazqpgIaS3BCezzmcY9689+a5fCflO+/NvcGmTZvQqVMnqSMREVEVwcaOqAJkZWXB09MTANC4cWMkJiaiXbt2cHR0lDYYERFVKTwVS/QnaLVafPjhh2jWrBn2799vHPfz82NTR0REVsfGjqicvv/+e3Ts2BHz5s2DXq83aeyIiIikwMaOyEx6vR6ffvopfH19cebMGbzwwgvYtm0bFi1aJHU0IiKq4vgZOyIzXL16FcHBwUhNTQUA9OvXD2vXroWrq6vEyYiIiLhiR2SW48ePIzU1FdWrV8e6deuwa9cuNnVERGQzuGJH9AwGgwFy+eP/DxQUFIQrV65g6NChePHFFyVORkREZIordkRl2LZtG7y8vHDv3j3j2IwZM9jUERGRTeKKHdETQgC6fADAzz//jPcmTUbsV/EAgIXz5+LTqLlSpqtY2nypExARkQWwsSMCHjd1MQHAjf8i6UoxQnYW4FaegFwGzOimwkdOMcC89VKnJCIiKhMbOyIA0OUj/+p3+CCpEP86rgMANK8tx6ZBGnRuaMdvE4/OgJI3UiYishd2/BeLyDyffFtkbOom/H0MFsyLhJOTk8SpLEzpCMhkUqcgIqIKwsaO6DfTuqnx7TU9Zq36Gr3feFPqOERERGaziatiV6xYAU9PT2g0GnTq1AlpaWmlzl27di26d++OWrVqoVatWvD39y9zPlFpzp07h/DwcAghAAAuahkOhziid6/XJE5GRERUPpI3dvHx8QgPD0dERAROnTqFdu3aISAgAHfv3i1xfkpKCoYOHYpvvvkGx44dg4eHB3r37o1bt25ZOTlVVnq9HosXL0b79u3x2WefYe3atcbnZDwtSURElZjkjV10dDRGjx6NkJAQvPTSS1i9ejUcHR0RExNT4vzY2FiMHz8e3t7eaNWqFdatWweDwYADBw5YOTlVRjk5OejduzcmT56MoqIi9O3bF/3795c6FhERUYWQ9DN2Wq0WJ0+exPTp041jcrkc/v7+OHbs2HPtIz8/HzqdDrVr1y7x+aKiIhQVFRkf5+bmAgB0Oh10Ot2fSF86na7Y5N/mvE5xcbHJv3WwTMaqRgiBL774AuHh4SgsLISTkxMWLVqEUaNGQSaTQad9BOVvc3U6HSDj791anrw/LPV+JPOxJraJdbFN1qiLOfuWtLG7f/8+9Ho96tevbzJev359XLx48bn28cEHH8Dd3R3+/v4lPj9//nzMmTPnqfH9+/fD0dEyt3ko0gNPfrUHDx6EWvH822qF1vjvxMREqGSqig1XRa1btw67d+8GALRu3Rrvv/8+XF1dsW/fPgCAQl+Efr/NTUzcD71CLVHSqispKUnqCPQHrIltYl1skyXrkp///DeVr9RXxUZFRSEuLg4pKSnQaDQlzpk+fTrCw8ONj3Nzc42fy3NxcbFIrnxtMaamHQQA9OzZEzWcSs5WkoLiAny85WMAQEBAAByqOVgkY1VTp04dHDx4EEOGDMHy5cuf/t+L9hFw9vE/AwJ6Ayo7v82JDdHpdEhKSkKvXr2gVCqfvQFZHGtim1gX22SNujw52/g8JG3s6tSpA4VCgZycHJPxnJwcuLq6lrntokWLEBUVheTkZLRt27bUeWq1Gmr106svSqXSYgVQit8/gK9UVjPrdf731Gu1auZtS7/75Zdf8N1336FPnz4AgK5du+Ly5ctIS0uDRqN5+vcqfn+sVCoB/t6tzpLvSSof1sQ2sS62yaJ9hRn7lfTiCZVKhfbt25tc+PDkQgg/P79St1u4cCEiIyORkJAAX19fa0SlSiQ5ORleXl4YOHAgzp8/bxyvU6eOhKmIiIgsT/KrYsPDw7F27Vps3LgRFy5cwLhx4/Do0SOEhIQAAEaOHGlyccWCBQvw0UcfISYmBp6ensjOzkZ2djYePnwo1SGQjcjPz8fEiRPRq1cv3Lx5Ew0bNkRBQYHUsYiIiKxG8s/YBQUF4d69e5g1axays7Ph7e2NhIQE4wUV169fh1z+e/+5atUqaLVavP322yb7iYiIwOzZs60ZnWxIWloaRo4ciYyMDADAuHHj8Omnn9r/V4IRERH9D8kbOwAICwtDWFhYic+lpKSYPM7KyrJ8IKpUPvnkE8yePRt6vR7u7u6IiYlBQECA1LGIiIisTvJTsUR/llwuh16vx9ChQ/H999+zqSMioirLJlbsiMxhMBhw9+5d45XTU6dOhY+Pj/EKWCIioqqKK3ZUqVy7dg2vvfYa/P39UVhYCODxbWHY1BEREbGxo0pCCIENGzbAy8sLKSkpyMrKwunTp6WORUREZFPY2JHNu3v3LgYNGoSQkBDk5eWha9euOHPmTJn3OiQiIqqK2NiRTdu+fTvatGmDnTt3QqlUIioqCocOHULTpk2ljkZERGRzePEE2SwhBJYvX4579+6hbdu22Lx5c5lfH0dERFTVccWObI4QAgAgk8mwfv16zJw5E2lpaWzqiIiInoGNHdmMgoICTJo0CRMnTjSONW7cGJGRkVCr1RImIyIiqhx4KpZswokTJzBixAhcvHgRwOOvBHvppZckTkVERFS5cMWOJKXT6TBnzhx07twZFy9ehJubG/bu3cumjoiIqBy4YkeSuXjxIkaMGIETJ04AAAIDA7Fy5Uq88MILEicjIiKqnNjYkSS0Wi38/f1x69Yt1KxZE6tWrcLf/vY3qWMRERFVajwVS5JQqVSIjo5G79698cMPP7CpIyIiqgBs7MgqhBDYtGkTdu/ebRwLDAxEQkICGjRoIGEyIiIi+8FTsWRx9+7dw9ixY7F9+3bUrVsX586dQ926dQE8vlcdERERVQw2dmRRu3btwujRo3H37l0olUpMmjQJtWrVkjoWERGRXWJjRxaRm5uLf/zjH1i/fj0AoE2bNti8eTO8vb2lDUZERGTH2NhRhfvll1/g7e2Na9euQSaTYcqUKfj444/57RFEREQWxosnqMLVrFkT/v7+ePHFF3Ho0CEsWLCATR0REZEVcMWOKsTJkyfh6upqvML1s88+AwA4OztLGYuIiKhK4Yod/SnFxcWIjIxE586dERoaCiEEgMcNHZs6IiIi6+KKncUIQKZDQXEBlDrx3FsVFBdYMJMZhAB0+WVOyci4hJGhY5B2/PFXgjk7OaDg1/twdHS0RkLz6XRQ6IsA7SNAKE2f05Z9rERERJUBGzsLEELAsfFqKByvodcOqdOUgxBATABw478lPm0QAivSdPgguRAFxUBNDbCirwOGtjkA2ZJmVg77/JQA+gHAWYmDEBERWQgbOwso1BdC4XjtT+3jlXqvwKGaQwUlMpMuv9Sm7u4jA4b9pwAHMvUAgF5NFIgZ4ICGLnZyVt+jM6C00RVHIiKiZ2BjZ2H/1y8B9VzMvyGvQzUH2/hWhsmXAdXvjU71/Hzc2NkVDg43sShqLsaNHW0bOZ+DTqdDYuJ+BAT0hlKpLHmS0hGoJMdDRET0R2zsLExTzQGOlXkFSOWIB3mFqFWrFuRyORxVTojfsgWOjo5o0aKF1OnMI9NBr1ADKiegtMaOiIioErOT82dkKf+3ey9efvllLFmyxDjm7e1d+Zo6IiKiKoCNHZUot0jg3V0FePOtQOTk5ODLL7+EXq+XOhYRERGVgY0dPeXbw6lot/ohvjitg0wmw+TJk5GamgqFQiF1NCIiIioDP2NHRoWFhZg5cyaio6MhhIBnTRk2btuHv7wWIHU0IiIieg5s7Mjoxx9/xLJlyyCEQOgrSkQHaODSvZvUsYiIiOg5sbGr4oQQxtuVeHl5YcmSJfBwrYv+Z9+VOBkRERGZi5+xq8IuXbqEv/zlLzh16pRxbPz48ejfr6+EqYiIiKi82NhVQUIIrFixAt7e3khNTcV7770HIZ7/+2yJiIjINvFUbBVz8+ZNjBo1CklJSQCA1157DevXr6803x5BREREpeOKXRUhhMCXX34JLy8vJCUlQaPRYNmyZdi/fz88PDykjkdEREQVgCt2VcSePXswfPhwAECHDh2wadMmtGrVSuJUREREVJHY2FURffv2Re/evdGtWzdMnz4d1aqx9ERERPaGf93tVF5eHqKiojB9+nRUr14dcrkc+/btg1zOs+9ERET2io2dHTp8+DCCg4ORmZmJn3/+GStXrgQANnVERER2jn/p7UhRURGmTp2KHj16IDMzE40aNUJgYKDUsYiIiMhKuGJnK4QAdPnl3jz9zFmMCHkXP5w7DwAICR6BJYsWwMXFBdA+Mm9n2vLnICIiIumwsbMFQgAxAcCN/5Zr823ndRj2nwLoDEA9JxnW9NNggOdO4F87KzgoERER2TI2drZAl1/upg4Aunoo4KyWoUdjBT7vp0Fdpwo6w+7RGVA6Vsy+iIiIyOLY2NmayZcBVdnNlBAC36QcQs9X/woAcANw6u/X0aiRR8V+g4TSEeA3UhAREVUabOxsjcoRUDmV+vStW7cQGhqKxMREbN++HQMHDgQANG7e2koBiYiIyFbxqthKJC4uDl5eXkhMTIRGo8H9+/eljkREREQ2hCt2lcCDBw8wYcIExMfHAwB8fX2xadMmtG7NVToiIiL6HVfsbFxycjK8vLwQHx8PhUKB2bNn4+jRo2zqiIiI6ClcsbNxhYWFuHPnDlq1aoXNmzfD19dX6khERERko7hiZ4N++eUX47/79euHuLg4nDp1ik0dERERlYmNnQ0pKhaYPjMCzZo1w61bt4zjQUFBcHBwkDAZERERVQZs7GzE2Rw9Oq57hKhPF+PBgwfYunWr1JGIiIiokuFn7CSm1+uxaFE0PlrzCDoDUKfOC1izZi0GDRokdTQiIiKqZNjYSejKlSsYOXIkjh49CgB4s2U1rElKQ32PJhInIyIiosqIjZ2EVq5ciaNHj8LZ2RlLX9XhHW8lZPXrSx2LiIiIKik2dhKKjIzEzz//jFnTJsPzSz+p4xAREVElx4snrGjLli0YPHgwDAYDAMDR0RExMTHw9GwscTIiIiKyBzbR2K1YsQKenp7QaDTo1KkT0tLSypy/detWtGrVChqNBl5eXti7d6+VkpbPTz/9hGHDhiEoKAjbt2/Hpk2bpI5EREREdkjyxi4+Ph7h4eGIiIjAqVOn0K5dOwQEBODu3bslzj969CiGDh2K0NBQnD59GgMHDsTAgQPxww8/WDn58/nmwEF4eXnhq6++gkKhQEREBIYPHy51LCIiIrJDkjd20dHRGD16NEJCQvDSSy9h9erVxlOUJVm6dCn69OmDKVOmoHXr1oiMjISPjw/+9a9/WTl5GYSAociA2xtvY9hbQ3D79m20aN4cRw8dwOwZU6AUWkD76H9+8qVOTERERHZA0osntFotTp48ienTpxvH5HI5/P39cezYsRK3OXbsGMLDw03GAgICsGPHjhLnFxUVoaioyPg4NzcXAKDT6aDT6f7kEZRMl/8rbnx+A3mn8gAAEzuqMN8/G45JbwJJz9hWpwNklslV1T2pt6XqTuXDutge1sQ2sS62yRp1MWffkjZ29+/fh16vR/0/3OKjfv36uHjxYonbZGdnlzg/Ozu7xPnz58/HnDlznhrfv38/HB0dy5m8bPnaPNQbWA9FN4vwnwAl+jVRPNd2D5yaIzUpBZDJLJKLHktKekZ3TZJgXWwPa2KbWBfbZMm65Oc//5k9u7/dyfTp001W+HJzc+Hh4YHevXvDxcXFIq9p0OvRrVs3HGp+CH/t/Tp0atVzbeeidERfNnUWo9PpkJSUhF69ekGpVEodh37Dutge1sQ2sS62yRp1eXK28XlI2tjVqVMHCoUCOTk5JuM5OTlwdXUtcRtXV1ez5qvVaqjV6qfGlUql5d4YSiVc6zSAs0NNqJ1r8Q1oYyxaeyo31sX2sCa2iXWxTZasizn7lfTiCZVKhfbt2+PAgQPGMYPBgAMHDsDPr+Qb9vr5+ZnMBx4vf5Y2n4iIiKiqkPxUbHh4OIKDg+Hr64uOHTtiyZIlePToEUJCQgAAI0eORIMGDTB//nwAwPvvv48ePXpg8eLFeOONNxAXF4cTJ05gzZo1Uh4GERERkeQkb+yCgoJw7949zJo1C9nZ2fD29kZCQoLxAonr169DLv99YbFLly748ssvMXPmTMyYMQPNmzfHjh070KZNG6kOgYiIiMgmSN7YAUBYWBjCwsJKfC4lJeWpsSFDhmDIkCEWTkVERERUuUh+g2IiIiIiqhhs7IiIiIjsBBs7IiIiIjvBxo6IiIjITrCxIyIiIrITbOyIiIiI7AQbOyIiIiI7wcaOiIiIyE6wsSMiIiKyE2zsiIiIiOyETXylmDUJIQAAubm5Fn0dnU6H/Px85ObmQqlUWvS16PmwJraJdbE9rIltYl1skzXq8qRnedLDlKXKNXZ5eXkAAA8PD4mTEBERET2/vLw81KhRo8w5MvE87Z8dMRgMuH37NpydnSGTySz2Orm5ufDw8MCNGzfg4uJisdeh58ea2CbWxfawJraJdbFN1qiLEAJ5eXlwd3eHXF72p+iq3IqdXC5Hw4YNrfZ6Li4ufAPaGNbENrEutoc1sU2si22ydF2etVL3BC+eICIiIrITbOyIiIiI7AQbOwtRq9WIiIiAWq2WOgr9hjWxTayL7WFNbBPrYptsrS5V7uIJIiIiInvFFTsiIiIiO8HGjoiIiMhOsLEjIiIishNs7P6EFStWwNPTExqNBp06dUJaWlqZ87du3YpWrVpBo9HAy8sLe/futVLSqsOcmqxduxbdu3dHrVq1UKtWLfj7+z+zhlQ+5r5XnoiLi4NMJsPAgQMtG7AKMrcmv/zyCyZMmAA3Nzeo1Wq0aNGC/w2zAHPrsmTJErRs2RIODg7w8PDApEmTUFhYaKW09u/bb79F//794e7uDplMhh07djxzm5SUFPj4+ECtVqNZs2bYsGGDxXOaEFQucXFxQqVSiZiYGHHu3DkxevRoUbNmTZGTk1Pi/CNHjgiFQiEWLlwozp8/L2bOnCmUSqX4/vvvrZzcfplbk2HDhokVK1aI06dPiwsXLoh33nlH1KhRQ9y8edPKye2buXV5IjMzUzRo0EB0795dDBgwwDphqwhza1JUVCR8fX1F3759RWpqqsjMzBQpKSkiPT3dysntm7l1iY2NFWq1WsTGxorMzEyRmJgo3NzcxKRJk6yc3H7t3btXfPjhh+Lrr78WAMT27dvLnH/16lXh6OgowsPDxfnz58Xy5cuFQqEQCQkJ1gkshGBjV04dO3YUEyZMMD7W6/XC3d1dzJ8/v8T5gYGB4o033jAZ69Spkxg7dqxFc1Yl5tbkj4qLi4Wzs7PYuHGjpSJWSeWpS3FxsejSpYtYt26dCA4OZmNXwcytyapVq0STJk2EVqu1VsQqydy6TJgwQfTs2dNkLDw8XHTt2tWiOauq52nspk6dKl5++WWTsaCgIBEQEGDBZKZ4KrYctFotTp48CX9/f+OYXC6Hv78/jh07VuI2x44dM5kPAAEBAaXOJ/OUpyZ/lJ+fD51Oh9q1a1sqZpVT3rp8/PHHqFevHkJDQ60Rs0opT0127doFPz8/TJgwAfXr10ebNm0wb9486PV6a8W2e+WpS5cuXXDy5Enj6dqrV69i79696Nu3r1Uy09Ns4W99lfuu2Ipw//596PV61K9f32S8fv36uHjxYonbZGdnlzg/OzvbYjmrkvLU5I8++OADuLu7P/WmpPIrT11SU1PxxRdfID093QoJq57y1OTq1as4ePAghg8fjr179+Ly5csYP348dDodIiIirBHb7pWnLsOGDcP9+/fRrVs3CCFQXFyMv//975gxY4Y1IlMJSvtbn5ubi4KCAjg4OFg8A1fsiABERUUhLi4O27dvh0ajkTpOlZWXl4cRI0Zg7dq1qFOnjtRx6DcGgwH16tXDmjVr0L59ewQFBeHDDz/E6tWrpY5WpaWkpGDevHlYuXIlTp06ha+//hp79uxBZGSk1NFIQlyxK4c6depAoVAgJyfHZDwnJweurq4lbuPq6mrWfDJPeWryxKJFixAVFYXk5GS0bdvWkjGrHHPrcuXKFWRlZaF///7GMYPBAACoVq0aMjIy0LRpU8uGtnPlea+4ublBqVRCoVAYx1q3bo3s7GxotVqoVCqLZq4KylOXjz76CCNGjMC7774LAPDy8sKjR48wZswYfPjhh5DLuXZjbaX9rXdxcbHKah3AFbtyUalUaN++PQ4cOGAcMxgMOHDgAPz8/Ercxs/Pz2Q+ACQlJZU6n8xTnpoAwMKFCxEZGYmEhAT4+vpaI2qVYm5dWrVqhe+//x7p6enGnzfffBOvvvoq0tPT4eHhYc34dqk875WuXbvi8uXLxiYbAC5dugQ3Nzc2dRWkPHXJz89/qnl70nwLfluoJGzib73VLtOwM3FxcUKtVosNGzaI8+fPizFjxoiaNWuK7OxsIYQQI0aMENOmTTPOP3LkiKhWrZpYtGiRuHDhgoiIiODtTiqYuTWJiooSKpVKbNu2Tdy5c8f4k5eXJ9Uh2CVz6/JHvCq24plbk+vXrwtnZ2cRFhYmMjIyxO7du0W9evXEJ598ItUh2CVz6xIRESGcnZ3FV199Ja5evSr2798vmjZtKgIDA6U6BLuTl5cnTp8+LU6fPi0AiOjoaHH69Glx7do1IYQQ06ZNEyNGjDDOf3K7kylTpogLFy6IFStW8HYnlcny5ctFo0aNhEqlEh07dhTfffed8bkePXqI4OBgk/lbtmwRLVq0ECqVSrz88stiz549Vk5s/8ypSePGjQWAp34iIiKsH9zOmfte+V9s7CzD3JocPXpUdOrUSajVatGkSRMxd+5cUVxcbOXU9s+cuuh0OjF79mzRtGlTodFohIeHhxg/frz4+eefrR/cTn3zzTcl/p14Uofg4GDRo0ePp7bx9vYWKpVKNGnSRKxfv96qmWVCcL2WiIiIyB7wM3ZEREREdoKNHREREZGdYGNHREREZCfY2BERERHZCTZ2RERERHaCjR0RERGRnWBjR0RERGQn2NgRERER2Qk2dkRkMzZs2ICaNWtKHaPcZDIZduzYUeacd955BwMHDrRKHiKqetjYEVGFeueddyCTyZ76uXz5stTRsGHDBmMeuVyOhg0bIiQkBHfv3q2Q/d+5cwevv/46ACArKwsymQzp6ekmc5YuXYoNGzZUyOuVZvbs2cbjVCgU8PDwwJgxY/DTTz+ZtR82oUSVTzWpAxCR/enTpw/Wr19vMla3bl2J0phycXFBRkYGDAYDzpw5g5CQENy+fRuJiYl/et+urq7PnFOjRo0//TrP4+WXX0ZycjL0ej0uXLiAUaNG4ddff0V8fLxVXp+IpMEVOyKqcGq1Gq6uriY/CoUC0dHR8PLygpOTEzw8PDB+/Hg8fPiw1P2cOXMGr776KpydneHi4oL27dvjxIkTxudTU1PRvXt3ODg4wMPDAxMnTsSjR4/KzCaTyeDq6gp3d3e8/vrrmDhxIpKTk1FQUACDwYCPP/4YDRs2hFqthre3NxISEozbarVahIWFwc3NDRqNBo0bN8b8+fNN9v3kVOyLL74IAHjllVcgk8nw17/+FYDpKtiaNWvg7u4Og8FgknHAgAEYNWqU8fHOnTvh4+MDjUaDJk2aYM6cOSguLi7zOKtVqwZXV1c0aNAA/v7+GDJkCJKSkozP6/V6hIaG4sUXX4SDgwNatmyJpUuXGp+fPXs2Nm7ciJ07dxpX/1JSUgAAN27cQGBgIGrWrInatWtjwIAByMrKKjMPEVkHGzsishq5XI5ly5bh3Llz2LhxIw4ePIipU6eWOn/48OFo2LAhjh8/jpMnT2LatGlQKpUAgCtXrqBPnz546623cPbsWcTHxyM1NRVhYWFmZXJwcIDBYEBxcTGWLl2KxYsXY9GiRTh79iwCAgLw5ptv4scffwQALFu2DLt27cKWLVuQkZGB2NhYeHp6lrjftLQ0AEBycjLu3LmDr7/++qk5Q4YMwYMHD/DNN98Yx3766SckJCRg+PDhAIDDhw9j5MiReP/993H+/Hl8/vnn2LBhA+bOnfvcx5iVlYXExESoVCrjmMFgQMOGDbF161acP38es2bNwowZM7BlyxYAwOTJkxEYGIg+ffrgzp07uHPnDrp06QKdToeAgAA4Ozvj8OHDOHLkCKpXr44+ffpAq9U+dyYishBBRFSBgoODhUKhEE5OTsaft99+u8S5W7duFS+88ILx8fr160WNGjWMj52dncWGDRtK3DY0NFSMGTPGZOzw4cNCLpeLgoKCErf54/4vXbokWrRoIXx9fYUQQri7u4u5c+eabNOhQwcxfvx4IYQQ7733nujZs6cwGAwl7h+A2L59uxBCiMzMTAFAnD592mROcHCwGDBggPHxgAEDxKhRo4yPP//8c+Hu7i70er0QQojXXntNzJs3z2QfmzdvFm5ubiVmEEKIiIgIIZfLhZOTk9BoNAKAACCio6NL3UYIISZMmCDeeuutUrM+ee2WLVua/A6KioqEg4ODSExMLHP/RGR5/IwdEVW4V199FatWrTI+dnJyAvB49Wr+/Pm4ePEicnNzUVxcjMLCQuTn58PR0fGp/YSHh+Pdd9/F5s2bjacTmzZtCuDxadqzZ88iNjbWOF8IAYPBgMzMTLRu3brEbL/++iuqV68Og8GAwsJCdOvWDevWrUNubi5u376Nrl27mszv2rUrzpw5A+DxadRevXqhZcuW6NOnD/r164fevXv/qd/V8OHDMXr0aKxcuRJqtRqxsbH429/+BrlcbjzOI0eOmKzQ6fX6Mn9vANCyZUvs2rULhYWF+Pe//4309HS89957JnNWrFiBmJgYXL9+HQUFBdBqtfD29i4z75kzZ3D58mU4OzubjBcWFuLKlSvl+A0QUUViY0dEFc7JyQnNmjUzGcvKykK/fv0wbtw4zJ07F7Vr10ZqaipCQ0Oh1WpLbFBmz56NYcOGYc+ePdi3bx8iIiIQFxeHQYMG4eHDhxg7diwmTpz41HaNGjUqNZuzszNOnToFuVwONzc3ODg4AAByc3OfeVw+Pj7IzMzEvn37kJycjMDAQPj7+2Pbtm3P3LY0/fv3hxACe/bsQYcOHXD48GF89tlnxucfPnyIOXPmYPDgwU9tq9FoSt2vSqUy1iAqKgpvvPEG5syZg8jISABAXFwcJk+ejMWLF8PPzw/Ozs749NNP8d///rfMvA8fPkT79u1NGuonbOUCGaKqjI0dEVnFyZMnYTAYsHjxYuNq1JPPc5WlRYsWaNGiBSZNmoShQ4di/fr1GDRoEHx8fHD+/PmnGshnkcvlJW7j4uICd3d3HDlyBD169DCOHzlyBB07djSZFxQUhKCgILz99tvo06cPfvrpJ9SuXdtkf08+z6bX68vMo9FoMHjwYMTGxuLy5cto2bIlfHx8jM/7+PggIyPD7OP8o5kzZ6Jnz54YN26c8Ti7dOmC8ePHG+f8ccVNpVI9ld/Hxwfx8fGoV68eXFxc/lQmIqp4vHiCiKyiWbNm0Ol0WL58Oa5evYrNmzdj9erVpc4vKChAWFgYUlJScO3aNRw5cgTHjx83nmL94IMPcPToUYSFhSE9PR0//vgjdu7cafbFE/9rypQpWLBgAeLj45GRkYFp06YhPT0d77//PgAgOjoaX331FS5evIhLly5h69atcHV1LfGmyvXq1YODgwMSEhKQk5ODX3/9tdTXHT58OPbs2YOYmBjjRRNPzJo1C5s2bcKcOXNw7tw5XLhwAXFxcZg5c6ZZx+bn54e2bdti3rx5AIDmzZvjxIkTSExMxKVLl/DRRx/h+PHjJtt4enri7NmzyMjIwP3796HT6TB8+HDUqVMHAwYMwOHDh5GZmYmUlBRMnDgRN2/eNCsTEVU8NnZEZBXt2rVDdHQ0FixYgDZt2iA2NtbkViF/pFAo8ODBA4wcORItWrRAYGAgXn/9dcyZMwcA0LZtWxw6dAiXLl1C9+7d8corr2DWrFlwd3cvd8aJEyciPDwc//znP+Hl5YWEhATs2rULzZs3B/D4NO7ChQvh6+uLDh06ICsrC3v37jWuQP6vatWqYdmyZfj888/h7u6OAQMGlPq6PXv2RO3atZGRkYFhw4aZPBcQEIDdu3dj//796NChAzp37ozPPvsMjRs3Nvv4Jk2ahHXr1uHGjRsYO3YsBg8ejKCgIHTq1AkPHjwwWb0DgNGjR6Nly5bw9fVF3bp1ceTIETg6OuLbb79Fo0aNMHjwYLRu3RqhoaEoLCzkCh6RDZAJIYTUIYiIiIjoz+OKHREREZGdYGNHREREZCfY2BERERHZCTZ2RERERHaCjR0RERGRnWBjR0RERGQn2NgRERER2Qk2dkRERER2go0dERERkZ1gY0dERERkJ9jYEREREdkJNnZEREREduL/AeWQ452GSHI9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUC macro: 0.673\n",
            "AUC weighted: 0.679\n"
          ]
        }
      ],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "plot_multiclass_roc(df, model, scaler, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nx6x3AUKKEk"
      },
      "source": [
        "## **BENEFICIOS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9RYAfU_pvMz"
      },
      "source": [
        "Por último, pero no por ello menos importante vamos a estudiar la última métrica: El **ROI (Return on Investment)**.\n",
        "\n",
        "$$\n",
        "ROI = \\frac{\\text{Beneficio}}{\\text{Inversión}}\n",
        "$$\n",
        "\n",
        "Con el código siguiente lo que estoy haciendo es simular una apuesta de un euro al resultado que predice mi modelo, en todos los partidos que hay en test. Si se acierta sumamos la cuota que ofrece Bet365 pero si falla se resta la unidad apostada. Con esto calculamos el beneficio neto y el ROI."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ROI por temporada (sin df_old) - Celda única\n",
        "# ============================================\n",
        "\n",
        "# --- Rutas (fallback si no existen variables del proyecto) ---\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "try:\n",
        "    DATA\n",
        "except NameError:\n",
        "    DATA = ROOT / \"data\"\n",
        "\n",
        "FEAT = DATA / \"03_features\"\n",
        "\n",
        "# --- Carga base: df_final ya incluye nombres de equipos ---\n",
        "df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# --- Constantes útiles ---\n",
        "CLASS2TXT = {0: \"A\", 1: \"D\", 2: \"H\"}   # 0=Away, 1=Draw, 2=Home\n",
        "TXT2IDX   = {'A':0, 'D':1, 'H':2}\n",
        "\n",
        "# ---------- Split de TEST con índices ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Importante: excluir variables de nombre de equipos de X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'  # <- evita fuga de info\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]  # <- AÑADIDO: devolver índices\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Alinear columnas al fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Meta alineada (nombres + cuotas + jornada) desde df ----------\n",
        "def attach_names_and_odds(df: pd.DataFrame, idx: pd.Index) -> pd.DataFrame:\n",
        "    # AÑADIDO 'Wk' para llevar la jornada en el resultado\n",
        "    need = [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"Wk\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Faltan columnas en df: {missing}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "    meta[\"Date\"] = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    return meta\n",
        "\n",
        "# ---------- Utilidades de reporting ----------\n",
        "def _max_drawdown(equity: pd.Series):\n",
        "    \"\"\"Devuelve drawdown máximo: (mdd_abs, mdd_pct, peak_idx, trough_idx).\"\"\"\n",
        "    if equity.empty:\n",
        "        return 0.0, 0.0, None, None\n",
        "    running_max = equity.cummax()\n",
        "    drawdown = running_max - equity\n",
        "    trough_idx = drawdown.idxmax()\n",
        "    peak_idx = equity.loc[:trough_idx].idxmax() if trough_idx is not None else None\n",
        "    mdd_abs = float(drawdown.max())\n",
        "    peak_val = float(equity.loc[peak_idx]) if peak_idx is not None else 1.0\n",
        "    mdd_pct = float(mdd_abs / peak_val) if peak_val > 0 else 0.0\n",
        "    return mdd_abs, mdd_pct, peak_idx, trough_idx\n",
        "\n",
        "def _edge_bins(edge: pd.Series, bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Discretiza edge (EV de la PREDICCIÓN) en tramos para analizar ROI.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "# ---------- Simulación ROI (con columnas de \"valor\" EV por clase) ----------\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,     # filtro por EV mínimo de la PREDICCIÓN\n",
        "):\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs     = scaler.transform(X_test)\n",
        "    proba  = model.predict_proba(Xs)\n",
        "    y_pred = model.predict(Xs)\n",
        "\n",
        "    # 3) Meta (nombres/fechas/cuotas/jornada) desde df\n",
        "    res = attach_names_and_odds(df, idx_test)\n",
        "    res['true_result']      = y_test.loc[res.index].values\n",
        "    res['predicted_result'] = pd.Series(y_pred, index=idx_test).loc[res.index].values\n",
        "\n",
        "    # 4) Probs/odds/edge de la predicción y \"value\" EV por clase\n",
        "    name_map  = {0:'A',1:'D',2:'H'}\n",
        "    classes   = list(model.classes_)  # típicamente [0,1,2]\n",
        "    proba_df  = pd.DataFrame(proba, index=idx_test, columns=[name_map.get(c, str(c)) for c in classes]).loc[res.index]\n",
        "    proba_fix = proba_df.reindex(columns=['A','D','H'])\n",
        "    odds_fix  = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})[['A','D','H']]\n",
        "\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(name_map).loc[res.index]\n",
        "    pred_idx = pred_txt.map(TXT2IDX).to_numpy()\n",
        "\n",
        "    P, O = proba_fix.to_numpy(), odds_fix.to_numpy()\n",
        "\n",
        "    res['Pred']           = pred_txt\n",
        "    res['predicted_prob'] = P[np.arange(len(res)), pred_idx]\n",
        "    res['predicted_odds'] = O[np.arange(len(res)), pred_idx]\n",
        "    res['edge']           = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "    # Value betting (mejor EV entre H/D/A, informativo)\n",
        "    EV = proba_fix * odds_fix - 1.0\n",
        "    best_idx = EV.to_numpy().argmax(axis=1)\n",
        "    labels = np.array(['A','D','H'])\n",
        "    res['value_pick'] = labels[best_idx]\n",
        "    res['value_ev']   = EV.to_numpy()[np.arange(len(EV)), best_idx]\n",
        "    res['value_prob'] = P[np.arange(len(P)), best_idx]\n",
        "    res['value_odds'] = O[np.arange(len(O)), best_idx]\n",
        "\n",
        "    # 5) Filtros\n",
        "    mask_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_odds].copy()\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación (apuesto SIEMPRE a la predicción)\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # Fechas amigables\n",
        "    res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets    = int(len(res))\n",
        "    roi       = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "    return res, roi, total_net\n",
        "\n",
        "# ===== Refit por temporada (BASE y SMOTE) =====\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "except Exception:\n",
        "    SMOTE = None\n",
        "\n",
        "def _prep_train_test_with_features(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int,\n",
        "    with_odds: bool = True\n",
        "):\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns: valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] == test_until_season\n",
        "\n",
        "    features = [c for c in X_all.columns if c != 'Season']\n",
        "    X_train, y_train = X_all.loc[train_mask, features], y_all.loc[train_mask]\n",
        "    X_test,  y_test  = X_all.loc[test_mask,  features], y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "    return X_train, y_train, X_test, y_test, idx_test, features\n",
        "\n",
        "def _refit_base_model_for_season(\n",
        "    df: pd.DataFrame,\n",
        "    train_until: int,\n",
        "    test_season: int,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    X_tr, y_tr, X_te, y_te, idx_te, feat = _prep_train_test_with_features(\n",
        "        df, train_until_season=train_until, test_until_season=test_season, with_odds=with_odds\n",
        "    )\n",
        "    if len(X_te) == 0:\n",
        "        return None, None\n",
        "    scaler_local = StandardScaler()\n",
        "    X_tr_s = scaler_local.fit_transform(X_tr)\n",
        "    mdl = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, random_state=random_state)\n",
        "    mdl.fit(X_tr_s, y_tr)\n",
        "    setattr(scaler_local, \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    setattr(mdl,          \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    return mdl, scaler_local\n",
        "\n",
        "def _refit_smote_model_for_season(\n",
        "    df: pd.DataFrame,\n",
        "    train_until: int,\n",
        "    test_season: int,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    if SMOTE is None:\n",
        "        raise ImportError(\"Para SMOTE necesitas 'imbalanced-learn'.\")\n",
        "    X_tr, y_tr, X_te, y_te, idx_te, feat = _prep_train_test_with_features(\n",
        "        df, train_until_season=train_until, test_until_season=test_season, with_odds=with_odds\n",
        "    )\n",
        "    if len(X_te) == 0:\n",
        "        return None, None\n",
        "    scaler_local = StandardScaler()\n",
        "    X_tr_s = scaler_local.fit_transform(X_tr)\n",
        "\n",
        "    _, counts = np.unique(y_tr, return_counts=True)\n",
        "    min_count = int(counts.min()) if len(counts) else 0\n",
        "    if min_count <= 1:\n",
        "        X_res, y_res = X_tr_s, y_tr\n",
        "    else:\n",
        "        k = max(1, min(5, min_count - 1))\n",
        "        try:\n",
        "            sm = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "            X_res, y_res = sm.fit_resample(X_tr_s, y_tr)\n",
        "        except Exception:\n",
        "            X_res, y_res = X_tr_s, y_tr\n",
        "\n",
        "    mdl = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, random_state=random_state)\n",
        "    mdl.fit(X_res, y_res)\n",
        "    setattr(scaler_local, \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    setattr(mdl,          \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    return mdl, scaler_local\n",
        "\n",
        "# ---------- Rejilla ROI por temporada ----------\n",
        "def build_roi_grid(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "    model_name: str = \"base\",\n",
        "    out_dir: Path | None = None\n",
        "):\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    OUT = (out_dir or (ROOT / \"outputs\"))\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rows = []\n",
        "    flat_for_csv = []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        # === REFIT CONSISTENTE POR TEMPORADA PARA AMBOS MODELOS ===\n",
        "        if str(model_name).lower() == \"smote\":\n",
        "            use_model, use_scaler = _refit_smote_model_for_season(\n",
        "                df, train_until=train_until, test_season=test_season, with_odds=with_odds, random_state=42\n",
        "            )\n",
        "        else:  # \"base\"\n",
        "            use_model, use_scaler = _refit_base_model_for_season(\n",
        "                df, train_until=train_until, test_season=test_season, with_odds=with_odds, random_state=42\n",
        "            )\n",
        "        if (use_model is None) or (use_scaler is None):\n",
        "            continue\n",
        "\n",
        "        res, roi, total_net = simulate_bet365_roi(\n",
        "            df, use_model, use_scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=with_odds, stake=stake,\n",
        "            feature_names=None, min_edge=min_edge\n",
        "        )\n",
        "        if res is None or len(res) == 0:\n",
        "            continue\n",
        "\n",
        "        # Orden por fecha para equity\n",
        "        tmp = res.copy()\n",
        "        tmp['_Date'] = pd.to_datetime(tmp['Date'], errors='coerce')\n",
        "        tmp = tmp.sort_values('_Date').drop(columns=['_Date'])\n",
        "\n",
        "        equity = tmp['net_profit'].cumsum()\n",
        "        mdd_abs, mdd_pct, *_ = _max_drawdown(equity)\n",
        "\n",
        "        hit_rate = float((tmp['predicted_result'] == tmp['true_result']).mean())\n",
        "        avg_odds = float(tmp['predicted_odds'].mean())\n",
        "        avg_edge = float(tmp['edge'].mean())\n",
        "        avg_value_ev = float(tmp['value_ev'].mean())\n",
        "\n",
        "        by_class = tmp.groupby(tmp['predicted_result']).agg(\n",
        "            profit=('net_profit','sum'), n=('net_profit','size')\n",
        "        )\n",
        "        profit_by_class = {CLASS2TXT.get(int(k), str(k)): float(v) for k, v in by_class['profit'].items()}\n",
        "\n",
        "        # --- rango de jornadas en el test ---\n",
        "        wk_min = wk_max = None\n",
        "        if 'Wk' in tmp.columns and len(tmp):\n",
        "            wks = pd.to_numeric(tmp['Wk'], errors='coerce').dropna().astype(int)\n",
        "            if len(wks):\n",
        "                wk_min = int(wks.min())\n",
        "                wk_max = int(wks.max())\n",
        "\n",
        "        bins = _edge_bins(tmp['edge'])\n",
        "        by_bin = tmp.groupby(bins, observed=True).agg(\n",
        "            n=('net_profit','size'),\n",
        "            profit=('net_profit','sum'),\n",
        "            avg_prob=('predicted_prob','mean'),\n",
        "            avg_odds=('predicted_odds','mean'),\n",
        "            avg_edge=('edge','mean')\n",
        "        ).reset_index(names='edge_bin')\n",
        "        by_bin['roi'] = by_bin.apply(lambda r: (r['profit']/(stake*r['n'])) if r['n']>0 else np.nan, axis=1)\n",
        "        roi_by_edge_bins = [\n",
        "            {\n",
        "                \"bin\": str(row['edge_bin']),\n",
        "                \"n\": int(row['n']),\n",
        "                \"roi\": float(row['roi']),\n",
        "                \"profit_total\": float(row['profit']),\n",
        "                \"avg_prob\": float(row['avg_prob']),\n",
        "                \"avg_odds\": float(row['avg_odds']),\n",
        "                \"avg_edge\": float(row['avg_edge']),\n",
        "            }\n",
        "            for _, row in by_bin.iterrows()\n",
        "        ]\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"roi\": float(roi),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"profit_by_class\": profit_by_class,\n",
        "            \"equity\": [float(x) for x in equity.tolist()],\n",
        "            \"max_drawdown_abs\": float(mdd_abs),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"roi_by_edge_bins\": roi_by_edge_bins,\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "        flat_for_csv.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_season\": int(test_season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"roi\": float(roi),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "    tag = f\"{model_name}\".replace(\" \", \"_\")\n",
        "    (OUT / f\"roi_by_season_{tag}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    if flat_for_csv:\n",
        "        pd.DataFrame(flat_for_csv).sort_values(\"test_season\").to_csv(OUT / f\"roi_by_season_{tag}.csv\", index=False)\n",
        "\n",
        "    print(f\"Guardados:\\n- {OUT/f'roi_by_season_{tag}.json'}\\n- {OUT/f'roi_by_season_{tag}.csv'}\")\n",
        "    return rows\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO (comenta/ajusta)\n",
        "# =========================\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=None, scaler=None,   # ignorados (ahora se refitea dentro)\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"base\"\n",
        ")\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=None, scaler=None,   # ignorados (ahora se refitea dentro)\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"smote\"\n",
        ")"
      ],
      "metadata": {
        "id": "j-qmrHnS7aiP",
        "outputId": "f37e9421-e04e-4890-e3d7-bee205f6292e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardados:\n",
            "- outputs/roi_by_season_base.json\n",
            "- outputs/roi_by_season_base.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardados:\n",
            "- outputs/roi_by_season_smote.json\n",
            "- outputs/roi_by_season_smote.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ROI por temporada (sin df_old) - Celda única\n",
        "# ============================================\n",
        "\n",
        "# --- Rutas (fallback si no existen variables del proyecto) ---\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    from pathlib import Path\n",
        "    ROOT = Path(\".\")\n",
        "try:\n",
        "    DATA\n",
        "except NameError:\n",
        "    DATA = ROOT / \"data\"\n",
        "\n",
        "import json, numpy as np, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "FEAT = DATA / \"03_features\"\n",
        "\n",
        "# --- Carga base: df_final ya incluye nombres de equipos ---\n",
        "df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# --- Constantes útiles ---\n",
        "CLASS2TXT = {0: \"A\", 1: \"D\", 2: \"H\"}   # 0=Away, 1=Draw, 2=Home\n",
        "TXT2IDX   = {'A':0, 'D':1, 'H':2}\n",
        "\n",
        "# ---------- Split de TEST con índices ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Importante: excluir variables de nombre de equipos de X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]  # <- devolvemos índices\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Alinear columnas al fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Meta alineada (nombres + cuotas + jornada) desde df ----------\n",
        "def attach_names_and_odds(df: pd.DataFrame, idx: pd.Index) -> pd.DataFrame:\n",
        "    # Incluimos 'Wk' para llevar la jornada\n",
        "    need = [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"Wk\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Faltan columnas en df: {missing}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "    meta[\"Date\"] = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    return meta\n",
        "\n",
        "# ---------- Utilidades de reporting ----------\n",
        "def _max_drawdown(equity: pd.Series):\n",
        "    \"\"\"Devuelve drawdown máximo: (mdd_abs, mdd_pct, peak_idx, trough_idx).\"\"\"\n",
        "    if equity.empty:\n",
        "        return 0.0, 0.0, None, None\n",
        "    running_max = equity.cummax()\n",
        "    drawdown = running_max - equity\n",
        "    trough_idx = drawdown.idxmax()\n",
        "    peak_idx = equity.loc[:trough_idx].idxmax() if trough_idx is not None else None\n",
        "    mdd_abs = float(drawdown.max())\n",
        "    peak_val = float(equity.loc[peak_idx]) if peak_idx is not None else 1.0\n",
        "    mdd_pct = float(mdd_abs / peak_val) if peak_val > 0 else 0.0\n",
        "    return mdd_abs, mdd_pct, peak_idx, trough_idx\n",
        "\n",
        "def _edge_bins(edge: pd.Series, bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Discretiza edge (EV de la PREDICCIÓN) en tramos para analizar ROI.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "# ---------- Simulación ROI (con columnas de \"valor\" EV por clase) ----------\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,     # filtro por EV mínimo de la PREDICCIÓN\n",
        "):\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir (evita warnings de feature names)\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs = scaler.transform(X_test)\n",
        "    feat_in = getattr(model, \"feature_names_in_\", None)\n",
        "    if feat_in is not None and not isinstance(Xs, pd.DataFrame):\n",
        "        Xs_for_model = pd.DataFrame(Xs, index=X_test.index, columns=list(feat_in))\n",
        "    else:\n",
        "        Xs_for_model = Xs\n",
        "\n",
        "    proba  = model.predict_proba(Xs_for_model)\n",
        "    y_pred = model.predict(Xs_for_model)\n",
        "\n",
        "    # 3) Meta (nombres/fechas/cuotas/jornada) desde df\n",
        "    res = attach_names_and_odds(df, idx_test)\n",
        "    res['true_result']      = y_test.loc[res.index].values\n",
        "    res['predicted_result'] = pd.Series(y_pred, index=idx_test).loc[res.index].values\n",
        "\n",
        "    # 4) Probs/odds/edge de la predicción y \"value\" EV por clase\n",
        "    name_map  = {0:'A',1:'D',2:'H'}\n",
        "    classes   = list(getattr(model, \"classes_\", [0,1,2]))\n",
        "    proba_df  = pd.DataFrame(proba, index=idx_test, columns=[name_map.get(int(c), str(c)) for c in classes]).loc[res.index]\n",
        "    proba_fix = proba_df.reindex(columns=['A','D','H'])\n",
        "    odds_fix  = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})[['A','D','H']]\n",
        "\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(name_map).loc[res.index]\n",
        "    pred_idx = pred_txt.map(TXT2IDX).to_numpy()\n",
        "\n",
        "    P, O = proba_fix.to_numpy(), odds_fix.to_numpy()\n",
        "\n",
        "    res['Pred']           = pred_txt\n",
        "    res['predicted_prob'] = P[np.arange(len(res)), pred_idx]\n",
        "    res['predicted_odds'] = O[np.arange(len(res)), pred_idx]\n",
        "    res['edge']           = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "    # Value betting (mejor EV entre H/D/A, informativo)\n",
        "    EV = proba_fix * odds_fix - 1.0\n",
        "    best_idx = EV.to_numpy().argmax(axis=1)\n",
        "    labels = np.array(['A','D','H'])\n",
        "    res['value_pick'] = labels[best_idx]\n",
        "    res['value_ev']   = EV.to_numpy()[np.arange(len(EV)), best_idx]\n",
        "    res['value_prob'] = P[np.arange(len(P)), best_idx]\n",
        "    res['value_odds'] = O[np.arange(len(O)), best_idx]\n",
        "\n",
        "    # 5) Filtros\n",
        "    mask_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_odds].copy()\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación (apuesto SIEMPRE a la predicción)\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # Fechas amigables\n",
        "    res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets    = int(len(res))\n",
        "    roi       = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "    return res, roi, total_net\n",
        "\n",
        "# ===== Refit SMOTE por temporada dentro del grid (para que NO sea igual que base) =====\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "except Exception:\n",
        "    SMOTE = None  # si no está imblearn, se avisará\n",
        "\n",
        "def _prep_train_test_with_features(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int,\n",
        "    with_odds: bool = True\n",
        "):\n",
        "    # Misma lógica de exclusiones\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns: valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] == test_until_season\n",
        "\n",
        "    features = [c for c in X_all.columns if c != 'Season']\n",
        "    X_train, y_train = X_all.loc[train_mask, features], y_all.loc[train_mask]\n",
        "    X_test,  y_test  = X_all.loc[test_mask,  features], y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "    return X_train, y_train, X_test, y_test, idx_test, features\n",
        "\n",
        "def _refit_smote_model_for_season(\n",
        "    df: pd.DataFrame,\n",
        "    train_until: int,\n",
        "    test_season: int,\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    if SMOTE is None:\n",
        "        raise ImportError(\"Para SMOTE necesitas 'imbalanced-learn'.\")\n",
        "    X_tr, y_tr, X_te, y_te, idx_te, feat = _prep_train_test_with_features(\n",
        "        df, train_until_season=train_until, test_until_season=test_season, with_odds=with_odds\n",
        "    )\n",
        "    if len(X_te) == 0:\n",
        "        return None, None  # sin test en esa season\n",
        "\n",
        "    scaler_local = StandardScaler()\n",
        "    # fit con DataFrame para que garde feature_names_in_\n",
        "    X_tr_s = scaler_local.fit_transform(X_tr)\n",
        "\n",
        "    # k robusto según la clase minoritaria\n",
        "    _, counts = np.unique(y_tr, return_counts=True)\n",
        "    min_count = int(counts.min()) if len(counts) else 0\n",
        "    if min_count <= 1:\n",
        "        X_res, y_res = X_tr_s, y_tr\n",
        "    else:\n",
        "        k = max(1, min(5, min_count - 1))\n",
        "        try:\n",
        "            sm = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "            X_res, y_res = sm.fit_resample(X_tr_s, y_tr)\n",
        "        except Exception:\n",
        "            X_res, y_res = X_tr_s, y_tr\n",
        "\n",
        "    mdl = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, random_state=random_state)\n",
        "    mdl.fit(X_res, y_res)\n",
        "\n",
        "    # Guardamos nombres de columnas usados\n",
        "    setattr(scaler_local, \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    setattr(mdl,          \"feature_names_in_\", np.array(feat, dtype=object))\n",
        "    return mdl, scaler_local\n",
        "\n",
        "# ---------- Rejilla ROI por temporada ----------\n",
        "def build_roi_grid(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "    model_name: str = \"base\",\n",
        "    out_dir: Path | None = None\n",
        "):\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    OUT = (out_dir or (ROOT / \"outputs\"))\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rows = []\n",
        "    flat_for_csv = []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        # Si es SMOTE, se reentrena por temporada (para que NO coincida con base)\n",
        "        if str(model_name).lower() == \"smote\":\n",
        "            local_mdl, local_scaler = _refit_smote_model_for_season(\n",
        "                df, train_until=train_until, test_season=test_season, with_odds=with_odds, random_state=42\n",
        "            )\n",
        "            if (local_mdl is None) or (local_scaler is None):\n",
        "                continue\n",
        "            use_model, use_scaler = local_mdl, local_scaler\n",
        "            feat_names = None  # el modelo/escalares llevan feature_names_in_\n",
        "        else:\n",
        "            use_model, use_scaler = model, scaler\n",
        "            feat_names = feature_names\n",
        "\n",
        "        res, roi, total_net = simulate_bet365_roi(\n",
        "            df, use_model, use_scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=test_season,\n",
        "            with_odds=with_odds, stake=stake,\n",
        "            feature_names=feat_names, min_edge=min_edge\n",
        "        )\n",
        "        if res is None or len(res) == 0:\n",
        "            continue\n",
        "\n",
        "        # Orden por fecha para equity\n",
        "        tmp = res.copy()\n",
        "        tmp['_Date'] = pd.to_datetime(tmp['Date'], errors='coerce')\n",
        "        tmp = tmp.sort_values('_Date').drop(columns=['_Date'])\n",
        "\n",
        "        equity = tmp['net_profit'].cumsum()\n",
        "        mdd_abs, mdd_pct, *_ = _max_drawdown(equity)\n",
        "\n",
        "        hit_rate = float((tmp['predicted_result'] == tmp['true_result']).mean())\n",
        "        avg_odds = float(tmp['predicted_odds'].mean())\n",
        "        avg_edge = float(tmp['edge'].mean())\n",
        "        avg_value_ev = float(tmp['value_ev'].mean())\n",
        "\n",
        "        by_class = tmp.groupby(tmp['predicted_result']).agg(\n",
        "            profit=('net_profit','sum'), n=('net_profit','size')\n",
        "        )\n",
        "        profit_by_class = {CLASS2TXT.get(int(k), str(k)): float(v) for k, v in by_class['profit'].items()}\n",
        "\n",
        "        # rango de jornadas en el test\n",
        "        wk_min = wk_max = None\n",
        "        if 'Wk' in tmp.columns and len(tmp):\n",
        "            wks = pd.to_numeric(tmp['Wk'], errors='coerce').dropna().astype(int)\n",
        "            if len(wks):\n",
        "                wk_min = int(wks.min())\n",
        "                wk_max = int(wks.max())\n",
        "\n",
        "        bins = _edge_bins(tmp['edge'])\n",
        "        by_bin = tmp.groupby(bins, observed=True).agg(\n",
        "            n=('net_profit','size'),\n",
        "            profit=('net_profit','sum'),\n",
        "            avg_prob=('predicted_prob','mean'),\n",
        "            avg_odds=('predicted_odds','mean'),\n",
        "            avg_edge=('edge','mean')\n",
        "        ).reset_index(names='edge_bin')\n",
        "        by_bin['roi'] = by_bin.apply(lambda r: (r['profit']/(stake*r['n'])) if r['n']>0 else np.nan, axis=1)\n",
        "        roi_by_edge_bins = [\n",
        "            {\n",
        "                \"bin\": str(row['edge_bin']),\n",
        "                \"n\": int(row['n']),\n",
        "                \"roi\": float(row['roi']),\n",
        "                \"profit_total\": float(row['profit']),\n",
        "                \"avg_prob\": float(row['avg_prob']),\n",
        "                \"avg_odds\": float(row['avg_odds']),\n",
        "                \"avg_edge\": float(row['avg_edge']),\n",
        "            }\n",
        "            for _, row in by_bin.iterrows()\n",
        "        ]\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"roi\": float(roi),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"profit_by_class\": profit_by_class,\n",
        "            \"equity\": [float(x) for x in equity.tolist()],\n",
        "            \"max_drawdown_abs\": float(mdd_abs),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"roi_by_edge_bins\": roi_by_edge_bins,\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "        flat_for_csv.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_season\": int(test_season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_bets\": int(len(tmp)),\n",
        "            \"roi\": float(roi),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "    tag = f\"{model_name}\".replace(\" \", \"_\")\n",
        "    (OUT / f\"roi_by_season_{tag}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    if flat_for_csv:\n",
        "        pd.DataFrame(flat_for_csv).sort_values(\"test_season\").to_csv(OUT / f\"roi_by_season_{tag}.csv\", index=False)\n",
        "\n",
        "    print(f\"Guardados:\\n- {OUT/f'roi_by_season_{tag}.json'}\\n- {OUT/f'roi_by_season_{tag}.csv'}\")\n",
        "    return rows\n",
        "\n",
        "# =========================\n",
        "# EJECUCIÓN (solo métricas a outputs)\n",
        "# =========================\n",
        "# Nota: 'model' y 'scaler' deben estar ya entrenados (baseline SIN SMOTE).\n",
        "# Para SMOTE, el reentrenado por temporada se hace dentro de build_roi_grid.\n",
        "OUT = ROOT / \"outputs\"; OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model, scaler=scaler,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"base\", out_dir=OUT\n",
        ")\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model, scaler=scaler,  # se ignoran y se reentrena SMOTE por temporada\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"smote\", out_dir=OUT\n",
        ")"
      ],
      "metadata": {
        "id": "LEynUfnv2LIQ",
        "outputId": "444e0999-449f-4af3-e4c8-bf9cdefb32ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardados:\n",
            "- outputs/roi_by_season_base.json\n",
            "- outputs/roi_by_season_base.csv\n",
            "Guardados:\n",
            "- outputs/roi_by_season_smote.json\n",
            "- outputs/roi_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# ROI por temporada (sin df_old) - Celda única\n",
        "# ============================================\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "except Exception as _e:\n",
        "    SMOTE = None  # si no está instalado, daremos error solo al pedir \"smote\"\n",
        "\n",
        "# --- Rutas (fallback si no existen variables del proyecto) ---\n",
        "try:\n",
        "    ROOT\n",
        "except NameError:\n",
        "    ROOT = Path(\".\")\n",
        "try:\n",
        "    DATA\n",
        "except NameError:\n",
        "    DATA = ROOT / \"data\"\n",
        "\n",
        "FEAT = DATA / \"03_features\"\n",
        "\n",
        "# --- Carga base: df_final ya incluye nombres de equipos ---\n",
        "df = pd.read_parquet(FEAT / \"df_final.parquet\").reset_index(drop=True)\n",
        "\n",
        "# --- Constantes útiles ---\n",
        "CLASS2TXT = {0: \"A\", 1: \"D\", 2: \"H\"}   # 0=Away, 1=Draw, 2=Home\n",
        "TXT2IDX   = {'A':0, 'D':1, 'H':2}\n",
        "\n",
        "# ---------- Split de TEST con índices ----------\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    # Importante: excluir variables de nombre de equipos de X\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'  # <- evita fuga de info\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]  # <- AÑADIDO: devolver índices\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "# ---------- Split TRAIN/TEST con features (para refit SMOTE por temporada) ----------\n",
        "def _prep_train_test_with_features(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True\n",
        "):\n",
        "    drop_common = [\n",
        "        'FTR','target','Date','has_xg_data',\n",
        "        'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6',\n",
        "        'HomeTeam_norm','AwayTeam_norm','row_id'\n",
        "    ]\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    train_mask = X_all['Season'] <= train_until_season\n",
        "    test_mask  = X_all['Season'] >  train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    feature_cols = [c for c in X_all.columns if c != 'Season']\n",
        "\n",
        "    X_train = X_all.loc[train_mask, feature_cols]\n",
        "    y_train = y_all.loc[train_mask]\n",
        "\n",
        "    X_test  = X_all.loc[test_mask, feature_cols]\n",
        "    y_test  = y_all.loc[test_mask]\n",
        "    idx_test = X_all.loc[test_mask].index\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, idx_test, feature_cols\n",
        "\n",
        "# ---------- Alinear columnas al fit ----------\n",
        "def _align_to_fit_columns(X: pd.DataFrame, fitter, feature_names: list[str] | None = None) -> pd.DataFrame:\n",
        "    cols_fit = feature_names if feature_names is not None else getattr(fitter, \"feature_names_in_\", None)\n",
        "    if cols_fit is None:\n",
        "        return X\n",
        "    cols_fit = list(cols_fit)\n",
        "    missing = [c for c in cols_fit if c not in X.columns]\n",
        "    extra   = [c for c in X.columns   if c not in cols_fit]\n",
        "    if extra:\n",
        "        X = X.drop(columns=extra)\n",
        "    if missing:\n",
        "        raise ValueError(\n",
        "            \"X_test no contiene columnas usadas al entrenar:\\n\"\n",
        "            f\"- Faltan: {missing}\\n\"\n",
        "            \"Usa el mismo esquema (with_odds/drop_cols) que en el fit, \"\n",
        "            \"o pasa 'feature_names' con la lista exacta del entrenamiento.\"\n",
        "        )\n",
        "    return X[cols_fit]\n",
        "\n",
        "# ---------- Meta alineada (nombres + cuotas + jornada) desde df ----------\n",
        "def attach_names_and_odds(df: pd.DataFrame, idx: pd.Index) -> pd.DataFrame:\n",
        "    # incluye 'Wk' para llevar la jornada\n",
        "    need = [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"Wk\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Faltan columnas en df: {missing}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "    meta[\"Date\"] = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    return meta\n",
        "\n",
        "# ---------- Utilidades de reporting ----------\n",
        "def _max_drawdown(equity: pd.Series):\n",
        "    if equity.empty:\n",
        "        return 0.0, 0.0, None, None\n",
        "    running_max = equity.cummax()\n",
        "    drawdown = running_max - equity\n",
        "    trough_idx = drawdown.idxmax()\n",
        "    peak_idx = equity.loc[:trough_idx].idxmax() if trough_idx is not None else None\n",
        "    mdd_abs = float(drawdown.max())\n",
        "    peak_val = float(equity.loc[peak_idx]) if peak_idx is not None else 1.0\n",
        "    mdd_pct = float(mdd_abs / peak_val) if peak_val > 0 else 0.0\n",
        "    return mdd_abs, mdd_pct, peak_idx, trough_idx\n",
        "\n",
        "def _edge_bins(edge: pd.Series, bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "# ---------- Simulación ROI (con columnas de \"valor\" EV por clase) ----------\n",
        "def simulate_bet365_roi(\n",
        "    df: pd.DataFrame,\n",
        "    model,\n",
        "    scaler,\n",
        "    train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "):\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx_test = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 2) Alinear columnas y predecir\n",
        "    X_test = _align_to_fit_columns(X_test, scaler, feature_names=feature_names)\n",
        "    Xs     = scaler.transform(X_test)\n",
        "    proba  = model.predict_proba(Xs)\n",
        "    y_pred = model.predict(Xs)\n",
        "\n",
        "    # 3) Meta (nombres/fechas/cuotas/jornada) desde df\n",
        "    res = attach_names_and_odds(df, idx_test)\n",
        "    res['true_result']      = y_test.loc[res.index].values\n",
        "    res['predicted_result'] = pd.Series(y_pred, index=idx_test).loc[res.index].values\n",
        "\n",
        "    # 4) Probs/odds/edge de la predicción y \"value\" EV por clase\n",
        "    name_map  = {0:'A',1:'D',2:'H'}\n",
        "    classes   = list(model.classes_)  # típicamente [0,1,2]\n",
        "    proba_df  = pd.DataFrame(proba, index=idx_test, columns=[name_map.get(c, str(c)) for c in classes]).loc[res.index]\n",
        "    proba_fix = proba_df.reindex(columns=['A','D','H'])\n",
        "    odds_fix  = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})[['A','D','H']]\n",
        "\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(name_map).loc[res.index]\n",
        "    pred_idx = pred_txt.map(TXT2IDX).to_numpy()\n",
        "\n",
        "    P, O = proba_fix.to_numpy(), odds_fix.to_numpy()\n",
        "\n",
        "    res['Pred']           = pred_txt\n",
        "    res['predicted_prob'] = P[np.arange(len(res)), pred_idx]\n",
        "    res['predicted_odds'] = O[np.arange(len(res)), pred_idx]\n",
        "    res['edge']           = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "    # Value betting\n",
        "    EV = proba_fix * odds_fix - 1.0\n",
        "    best_idx = EV.to_numpy().argmax(axis=1)\n",
        "    labels = np.array(['A','D','H'])\n",
        "    res['value_pick'] = labels[best_idx]\n",
        "    res['value_ev']   = EV.to_numpy()[np.arange(len(EV)), best_idx]\n",
        "    res['value_prob'] = P[np.arange(len(P)), best_idx]\n",
        "    res['value_odds'] = O[np.arange(len(O)), best_idx]\n",
        "\n",
        "    # 5) Filtros\n",
        "    mask_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "    res = res.loc[mask_odds].copy()\n",
        "    if min_edge > 0:\n",
        "        res = res.loc[res['edge'] >= min_edge].copy()\n",
        "    if res.empty:\n",
        "        return None, np.nan, np.nan\n",
        "\n",
        "    # 6) Simulación (apuesto SIEMPRE a la predicción)\n",
        "    res['bet_outcome'] = np.where(\n",
        "        res['predicted_result'] == res['true_result'],\n",
        "        res['predicted_odds'] * stake, 0.0\n",
        "    )\n",
        "    res['net_profit'] = res['bet_outcome'] - stake\n",
        "\n",
        "    # Fechas amigables\n",
        "    res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "    total_net = float(res['net_profit'].sum())\n",
        "    n_bets    = int(len(res))\n",
        "    roi       = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "    return res, roi, total_net\n",
        "\n",
        "# ---------- ROI por temporada con refit SMOTE interno cuando model_name == \"smote\" ----------\n",
        "def build_roi_grid(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    feature_names: list[str] | None = None,\n",
        "    min_edge: float = 0.00,\n",
        "    model_name: str = \"base\",\n",
        "    out_dir: Path | None = None,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    OUT = (out_dir or (ROOT / \"outputs\"))\n",
        "    OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    rows = []\n",
        "    flat_for_csv = []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        if model_name == \"smote\":\n",
        "            # ==== Refit SMOTE por temporada (garantiza diferencia real respecto a baseline) ====\n",
        "            if SMOTE is None:\n",
        "                raise ImportError(\"imblearn no disponible: instala 'imbalanced-learn' para usar SMOTE.\")\n",
        "            X_tr, y_tr, X_te, y_te, idx_te, feat_cols = _prep_train_test_with_features(\n",
        "                df, train_until_season=train_until, test_until_season=test_season, with_odds=with_odds\n",
        "            )\n",
        "            if len(X_te) == 0:\n",
        "                continue\n",
        "\n",
        "            scaler_local = StandardScaler()\n",
        "            X_tr_s = scaler_local.fit_transform(X_tr)\n",
        "            # k_neighbors robusto al mínimo soporte\n",
        "            _, counts = np.unique(y_tr, return_counts=True)\n",
        "            min_count = int(counts.min()) if len(counts) else 0\n",
        "            if min_count <= 1:\n",
        "                X_res, y_res = X_tr_s, y_tr\n",
        "            else:\n",
        "                k = max(1, min(5, min_count - 1))\n",
        "                try:\n",
        "                    sm = SMOTE(random_state=random_state, k_neighbors=k)\n",
        "                    X_res, y_res = sm.fit_resample(X_tr_s, y_tr)\n",
        "                except Exception:\n",
        "                    X_res, y_res = X_tr_s, y_tr\n",
        "\n",
        "            mdl_local = LogisticRegression(solver='saga', penalty='l2', max_iter=1000, random_state=random_state)\n",
        "            mdl_local.fit(X_res, y_res)\n",
        "\n",
        "            # --- ROI con el modelo SMOTE local ---\n",
        "            # Reutilizamos la lógica de simulate_bet365_roi pero con splits y modelo locales\n",
        "            # 1) predicciones sobre test\n",
        "            X_te_s = scaler_local.transform(X_te)\n",
        "            proba  = mdl_local.predict_proba(X_te_s)\n",
        "            y_pred = mdl_local.predict(X_te_s)\n",
        "\n",
        "            # 2) meta + métricas ROI (idéntico a simulate_bet365_roi a partir de aquí)\n",
        "            res = attach_names_and_odds(df, idx_te)\n",
        "            res['true_result']      = y_te.loc[res.index].values\n",
        "            res['predicted_result'] = pd.Series(y_pred, index=idx_te).loc[res.index].values\n",
        "\n",
        "            name_map = {0:'A',1:'D',2:'H'}\n",
        "            classes  = list(mdl_local.classes_)\n",
        "            proba_df = pd.DataFrame(proba, index=idx_te, columns=[name_map.get(c, str(c)) for c in classes]).loc[res.index]\n",
        "            proba_fix = proba_df.reindex(columns=['A','D','H'])\n",
        "            odds_fix  = res[['B365A','B365D','B365H']].rename(columns={'B365A':'A','B365D':'D','B365H':'H'})[['A','D','H']]\n",
        "\n",
        "            pred_txt = pd.Series(y_pred, index=idx_te).map(name_map).loc[res.index]\n",
        "            pred_idx = pred_txt.map(TXT2IDX).to_numpy()\n",
        "            P, O = proba_fix.to_numpy(), odds_fix.to_numpy()\n",
        "\n",
        "            res['Pred']           = pred_txt\n",
        "            res['predicted_prob'] = P[np.arange(len(res)), pred_idx]\n",
        "            res['predicted_odds'] = O[np.arange(len(res)), pred_idx]\n",
        "            res['edge']           = res['predicted_prob'] * res['predicted_odds'] - 1.0\n",
        "\n",
        "            EV = proba_fix * odds_fix - 1.0\n",
        "            best_idx = EV.to_numpy().argmax(axis=1)\n",
        "            labels = np.array(['A','D','H'])\n",
        "            res['value_pick'] = labels[best_idx]\n",
        "            res['value_ev']   = EV.to_numpy()[np.arange(len(EV)), best_idx]\n",
        "            res['value_prob'] = P[np.arange(len(P)), best_idx]\n",
        "            res['value_odds'] = O[np.arange(len(O)), best_idx]\n",
        "\n",
        "            mask_odds = res[['B365H','B365D','B365A']].notna().all(axis=1)\n",
        "            res = res.loc[mask_odds].copy()\n",
        "            if min_edge > 0:\n",
        "                res = res.loc[res['edge'] >= min_edge].copy()\n",
        "            if res.empty:\n",
        "                continue\n",
        "\n",
        "            res['bet_outcome'] = np.where(\n",
        "                res['predicted_result'] == res['true_result'],\n",
        "                res['predicted_odds'] * stake, 0.0\n",
        "            )\n",
        "            res['net_profit'] = res['bet_outcome'] - stake\n",
        "            res['Date'] = pd.to_datetime(res['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "            tmp = res.copy()\n",
        "\n",
        "        else:\n",
        "            # ==== Baseline: usa TUS model/scaler ya entrenados ====\n",
        "            out = simulate_bet365_roi(\n",
        "                df, model, scaler,\n",
        "                train_until_season=train_until,\n",
        "                test_until_season=test_season,\n",
        "                with_odds=with_odds, stake=stake,\n",
        "                feature_names=feature_names, min_edge=min_edge\n",
        "            )\n",
        "            if out[0] is None or len(out[0]) == 0:\n",
        "                continue\n",
        "            tmp = out[0].copy()\n",
        "\n",
        "        # ----- métrica y agregaciones comunes -----\n",
        "        tmp['_Date'] = pd.to_datetime(tmp['Date'], errors='coerce')\n",
        "        tmp = tmp.sort_values('_Date').drop(columns=['_Date'])\n",
        "\n",
        "        equity = tmp['net_profit'].cumsum()\n",
        "        mdd_abs, mdd_pct, *_ = _max_drawdown(equity)\n",
        "\n",
        "        hit_rate = float((tmp['predicted_result'] == tmp['true_result']).mean())\n",
        "        avg_odds = float(tmp['predicted_odds'].mean())\n",
        "        avg_edge = float(tmp['edge'].mean())\n",
        "        avg_value_ev = float(tmp['value_ev'].mean())\n",
        "        total_net = float(tmp['net_profit'].sum())\n",
        "        n_bets = int(len(tmp))\n",
        "        roi = total_net / (stake * n_bets) if n_bets > 0 else np.nan\n",
        "\n",
        "        by_class = tmp.groupby(tmp['predicted_result']).agg(\n",
        "            profit=('net_profit','sum'), n=('net_profit','size')\n",
        "        )\n",
        "        profit_by_class = {CLASS2TXT.get(int(k), str(k)): float(v) for k, v in by_class['profit'].items()}\n",
        "\n",
        "        # --- rango de jornadas del test ---\n",
        "        wk_min = wk_max = None\n",
        "        if 'Wk' in tmp.columns and len(tmp):\n",
        "            wks = pd.to_numeric(tmp['Wk'], errors='coerce').dropna().astype(int)\n",
        "            if len(wks):\n",
        "                wk_min = int(wks.min())\n",
        "                wk_max = int(wks.max())\n",
        "\n",
        "        bins = _edge_bins(tmp['edge'])\n",
        "        by_bin = tmp.groupby(bins, observed=True).agg(\n",
        "            n=('net_profit','size'),\n",
        "            profit=('net_profit','sum'),\n",
        "            avg_prob=('predicted_prob','mean'),\n",
        "            avg_odds=('predicted_odds','mean'),\n",
        "            avg_edge=('edge','mean')\n",
        "        ).reset_index(names='edge_bin')\n",
        "        by_bin['roi'] = by_bin.apply(lambda r: (r['profit']/(stake*r['n'])) if r['n']>0 else np.nan, axis=1)\n",
        "        roi_by_edge_bins = [\n",
        "            {\n",
        "                \"bin\": str(row['edge_bin']),\n",
        "                \"n\": int(row['n']),\n",
        "                \"roi\": float(row['roi']),\n",
        "                \"profit_total\": float(row['profit']),\n",
        "                \"avg_prob\": float(row['avg_prob']),\n",
        "                \"avg_odds\": float(row['avg_odds']),\n",
        "                \"avg_edge\": float(row['avg_edge']),\n",
        "            }\n",
        "            for _, row in by_bin.iterrows()\n",
        "        ]\n",
        "\n",
        "        rows.append({\n",
        "            \"model\": model_name,\n",
        "            \"train_until\": int(train_until),\n",
        "            \"test_season\": int(test_season),\n",
        "            \"n_bets\": int(n_bets),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"roi\": float(roi),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"profit_by_class\": profit_by_class,\n",
        "            \"equity\": [float(x) for x in equity.tolist()],\n",
        "            \"max_drawdown_abs\": float(mdd_abs),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"roi_by_edge_bins\": roi_by_edge_bins,\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "        flat_for_csv.append({\n",
        "            \"model\": model_name,\n",
        "            \"test_season\": int(test_season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_bets\": int(n_bets),\n",
        "            \"roi\": float(roi),\n",
        "            \"profit_total\": float(total_net),\n",
        "            \"hit_rate\": float(hit_rate),\n",
        "            \"avg_odds\": float(avg_odds),\n",
        "            \"avg_edge\": float(avg_edge),\n",
        "            \"avg_value_ev\": float(avg_value_ev),\n",
        "            \"max_drawdown_pct\": float(mdd_pct),\n",
        "            \"stake\": float(stake),\n",
        "            \"min_edge\": float(min_edge),\n",
        "            \"wk_min\": wk_min,\n",
        "            \"wk_max\": wk_max,\n",
        "        })\n",
        "\n",
        "    tag = f\"{model_name}\".replace(\" \", \"_\")\n",
        "    (OUT / f\"roi_by_season_{tag}.json\").write_text(json.dumps(rows, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    if flat_for_csv:\n",
        "        pd.DataFrame(flat_for_csv).sort_values(\"test_season\").to_csv(OUT / f\"roi_by_season_{tag}.csv\", index=False)\n",
        "\n",
        "    print(f\"Guardados:\\n- {OUT/f'roi_by_season_{tag}.json'}\\n- {OUT/f'roi_by_season_{tag}.csv'}\")\n",
        "    return rows\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO (comenta/ajusta)\n",
        "# =========================\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model, scaler=scaler,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"base\"\n",
        ")\n",
        "_ = build_roi_grid(\n",
        "    df=df, model=model_sm, scaler=scaler_sm,\n",
        "    seasons=None, with_odds=True, stake=1.0,\n",
        "    min_edge=0.00, model_name=\"smote\"\n",
        ")"
      ],
      "metadata": {
        "id": "ySIvacWEvEk1",
        "outputId": "c63de8b7-584d-425d-896a-5d01733a2132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardados:\n",
            "- outputs/roi_by_season_base.json\n",
            "- outputs/roi_by_season_base.csv\n",
            "Guardados:\n",
            "- outputs/roi_by_season_smote.json\n",
            "- outputs/roi_by_season_smote.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ca_qtV0Iqu9z",
        "outputId": "58cdea28-ded3-4c46-f0a6-fd2e765e3293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.07750000000000004\n",
            "-4.650000000000002\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Season        Date HomeTeam_norm AwayTeam_norm  Wk  B365H  B365D  B365A  \\\n",
              "7220    2025  2025-08-15        girona     vallecano   0   2.25   3.25   3.30   \n",
              "7221    2025  2025-08-15    villarreal   real oviedo   0   1.40   4.75   8.00   \n",
              "7222    2025  2025-08-16      mallorca     barcelona   0   7.00   5.00   1.40   \n",
              "7223    2025  2025-08-16        alaves       levante   0   2.15   3.00   3.80   \n",
              "7224    2025  2025-08-16      valencia      sociedad   0   2.60   2.90   3.10   \n",
              "7225    2025  2025-08-17    ath bilbao       sevilla   0   1.57   3.90   6.00   \n",
              "7226    2025  2025-08-17       espanol    ath madrid   0   6.00   3.90   1.57   \n",
              "7227    2025  2025-08-17         celta        getafe   0   1.73   3.50   5.25   \n",
              "7228    2025  2025-08-18         elche         betis   0   3.40   3.30   2.20   \n",
              "7229    2025  2025-08-19   real madrid       osasuna   0   1.22   6.25  13.00   \n",
              "7230    2025  2025-08-22         betis        alaves   0   1.91   3.40   4.20   \n",
              "7231    2025  2025-08-23    ath madrid         elche   0   1.25   5.25  15.00   \n",
              "7232    2025  2025-08-23       levante     barcelona   0  11.00   6.00   1.25   \n",
              "7233    2025  2025-08-23      mallorca         celta   0   3.00   3.10   2.55   \n",
              "7234    2025  2025-08-24       osasuna      valencia   0   2.40   3.20   3.10   \n",
              "7235    2025  2025-08-24      sociedad       espanol   0   1.80   3.40   5.00   \n",
              "7236    2025  2025-08-24    villarreal        girona   0   1.53   4.33   6.00   \n",
              "7237    2025  2025-08-24   real oviedo   real madrid   0   9.50   5.50   1.30   \n",
              "7238    2025  2025-08-25    ath bilbao     vallecano   0   1.70   3.50   5.50   \n",
              "7239    2025  2025-08-25       sevilla        getafe   0   2.25   3.00   3.60   \n",
              "7240    2025  2025-08-27         celta         betis   0   2.20   3.40   3.25   \n",
              "7241    2025  2025-08-29         elche       levante   0   2.15   3.25   3.50   \n",
              "7242    2025  2025-08-29      valencia        getafe   0   2.30   2.90   3.60   \n",
              "7243    2025  2025-08-30        alaves    ath madrid   0   4.75   3.50   1.80   \n",
              "7244    2025  2025-08-30   real oviedo      sociedad   0   3.50   3.10   2.25   \n",
              "7245    2025  2025-08-30        girona       sevilla   0   2.40   3.30   3.00   \n",
              "7246    2025  2025-08-30   real madrid      mallorca   0   1.18   7.00  15.00   \n",
              "7247    2025  2025-08-31         celta    villarreal   0   2.75   3.50   2.50   \n",
              "7248    2025  2025-08-31         betis    ath bilbao   0   3.00   3.10   2.55   \n",
              "7249    2025  2025-08-31       espanol       osasuna   0   2.38   3.20   3.10   \n",
              "7250    2025  2025-08-31     vallecano     barcelona   0   6.25   5.50   1.40   \n",
              "7251    2025  2025-09-12       sevilla         elche   0   1.85   3.40   4.50   \n",
              "7252    2025  2025-09-13    ath bilbao        alaves   0   1.60   3.90   5.75   \n",
              "7253    2025  2025-09-13    ath madrid    villarreal   0   1.80   3.70   4.33   \n",
              "7254    2025  2025-09-13        getafe   real oviedo   0   1.95   3.10   4.50   \n",
              "7255    2025  2025-09-13      sociedad   real madrid   0   5.00   4.33   1.60   \n",
              "7256    2025  2025-09-14         celta        girona   0   1.73   3.90   4.75   \n",
              "7257    2025  2025-09-14       levante         betis   0   3.25   3.25   2.30   \n",
              "7258    2025  2025-09-14       osasuna     vallecano   0   2.55   3.20   2.90   \n",
              "7259    2025  2025-09-14     barcelona      valencia   0   1.22   7.00  11.00   \n",
              "7260    2025  2025-09-15       espanol      mallorca   0   2.10   3.40   3.50   \n",
              "7261    2025  2025-09-19         betis      sociedad   0   1.91   3.60   3.75   \n",
              "7262    2025  2025-09-20    villarreal       osasuna   0   1.55   4.33   5.50   \n",
              "7263    2025  2025-09-20      valencia    ath bilbao   0   3.00   3.00   2.55   \n",
              "7264    2025  2025-09-20        girona       levante   0   1.91   3.60   4.00   \n",
              "7265    2025  2025-09-20   real madrid       espanol   0   1.20   7.00  13.00   \n",
              "7266    2025  2025-09-20        alaves       sevilla   0   2.25   3.10   3.50   \n",
              "7267    2025  2025-09-21     vallecano         celta   0   2.30   3.30   3.20   \n",
              "7268    2025  2025-09-21      mallorca    ath madrid   0   5.00   3.60   1.75   \n",
              "7269    2025  2025-09-21         elche   real oviedo   0   1.91   3.20   4.50   \n",
              "7270    2025  2025-09-21     barcelona        getafe   0   1.22   6.50  12.00   \n",
              "7271    2025  2025-09-23    ath bilbao        girona   0   1.45   4.33   7.00   \n",
              "7272    2025  2025-09-23       levante   real madrid   0   7.50   5.75   1.33   \n",
              "7273    2025  2025-09-23       sevilla    villarreal   0   3.10   3.40   2.30   \n",
              "7274    2025  2025-09-23       espanol      valencia   0   2.25   3.10   3.40   \n",
              "7275    2025  2025-09-24        getafe        alaves   0   2.30   2.90   3.60   \n",
              "7276    2025  2025-09-24    ath madrid     vallecano   0   1.50   4.50   6.00   \n",
              "7277    2025  2025-09-24      sociedad      mallorca   0   1.80   3.40   4.75   \n",
              "7278    2025  2025-09-25       osasuna         elche   0   1.95   3.25   4.33   \n",
              "7279    2025  2025-09-25   real oviedo     barcelona   0  10.00   5.75   1.25   \n",
              "\n",
              "      true_result  predicted_result Pred  predicted_prob  predicted_odds  \\\n",
              "7220            0                 1    D        0.499332            3.25   \n",
              "7221            2                 2    H        0.618078            1.40   \n",
              "7222            0                 0    A        0.720919            1.40   \n",
              "7223            2                 1    D        0.433790            3.00   \n",
              "7224            1                 1    D        0.536792            2.90   \n",
              "7225            2                 1    D        0.533934            3.90   \n",
              "7226            2                 0    A        0.664891            1.57   \n",
              "7227            0                 1    D        0.453777            3.50   \n",
              "7228            1                 0    A        0.477952            2.20   \n",
              "7229            2                 2    H        0.640304            1.22   \n",
              "7230            2                 1    D        0.424825            3.40   \n",
              "7231            1                 2    H        0.714517            1.25   \n",
              "7232            0                 0    A        0.808501            1.25   \n",
              "7233            1                 0    A        0.449563            2.55   \n",
              "7234            2                 1    D        0.509532            3.20   \n",
              "7235            1                 1    D        0.463201            3.40   \n",
              "7236            2                 2    H        0.471611            1.53   \n",
              "7237            0                 0    A        0.851155            1.30   \n",
              "7238            2                 1    D        0.424063            3.50   \n",
              "7239            0                 1    D        0.378957            3.00   \n",
              "7240            1                 1    D        0.424511            3.40   \n",
              "7241            2                 0    A        0.413137            3.50   \n",
              "7242            2                 1    D        0.479199            2.90   \n",
              "7243            1                 0    A        0.616990            1.80   \n",
              "7244            2                 0    A        0.505867            2.25   \n",
              "7245            0                 1    D        0.509368            3.30   \n",
              "7246            2                 2    H        0.620533            1.18   \n",
              "7247            1                 1    D        0.401221            3.50   \n",
              "7248            0                 1    D        0.454704            3.10   \n",
              "7249            2                 1    D        0.412159            3.20   \n",
              "7250            1                 0    A        0.714970            1.40   \n",
              "7251            1                 2    H        0.407582            1.85   \n",
              "7252            0                 1    D        0.479434            3.90   \n",
              "7253            2                 1    D        0.504755            3.70   \n",
              "7254            2                 1    D        0.409638            3.10   \n",
              "7255            0                 0    A        0.519164            1.60   \n",
              "7256            1                 1    D        0.464944            3.90   \n",
              "7257            1                 1    D        0.414994            3.25   \n",
              "7258            2                 1    D        0.480631            3.20   \n",
              "7259            2                 2    H        0.733602            1.22   \n",
              "7260            2                 1    D        0.502985            3.40   \n",
              "7261            2                 1    D        0.465303            3.60   \n",
              "7262            2                 2    H        0.448389            1.55   \n",
              "7263            2                 1    D        0.518942            3.00   \n",
              "7264            0                 1    D        0.468176            3.60   \n",
              "7265            2                 2    H        0.715256            1.20   \n",
              "7266            0                 1    D        0.550144            3.10   \n",
              "7267            1                 1    D        0.447120            3.30   \n",
              "7268            1                 0    A        0.519620            1.75   \n",
              "7269            2                 1    D        0.453678            3.20   \n",
              "7270            2                 2    H        0.716947            1.22   \n",
              "7271            1                 2    H        0.439062            1.45   \n",
              "7272            0                 0    A        0.684573            1.33   \n",
              "7273            0                 0    A        0.521546            2.30   \n",
              "7274            1                 1    D        0.487573            3.10   \n",
              "7275            1                 1    D        0.483462            2.90   \n",
              "7276            2                 2    H        0.420559            1.50   \n",
              "7277            2                 1    D        0.528770            3.40   \n",
              "7278            1                 1    D        0.511589            3.25   \n",
              "7279            0                 0    A        0.764048            1.25   \n",
              "\n",
              "          edge value_pick  value_ev  value_prob  value_odds  bet_outcome  \\\n",
              "7220  0.622829          D  0.622829    0.499332        3.25         0.00   \n",
              "7221 -0.134690          A  0.749049    0.218631        8.00         1.40   \n",
              "7222  0.009287          D  0.142345    0.228469        5.00         1.40   \n",
              "7223  0.301370          A  0.432825    0.377059        3.80         0.00   \n",
              "7224  0.556698          D  0.556698    0.536792        2.90         2.90   \n",
              "7225  1.082342          D  1.082342    0.533934        3.90         0.00   \n",
              "7226  0.043878          A  0.043878    0.664891        1.57         0.00   \n",
              "7227  0.588220          D  0.588220    0.453777        3.50         0.00   \n",
              "7228  0.051494          D  0.282234    0.388556        3.30         0.00   \n",
              "7229 -0.218829          D  0.793283    0.286925        6.25         1.22   \n",
              "7230  0.444406          D  0.444406    0.424825        3.40         0.00   \n",
              "7231 -0.106853          D  0.152093    0.219446        5.25         0.00   \n",
              "7232  0.010626          A  0.010626    0.808501        1.25         1.25   \n",
              "7233  0.146385          D  0.289629    0.416009        3.10         0.00   \n",
              "7234  0.630501          D  0.630501    0.509532        3.20         0.00   \n",
              "7235  0.574882          D  0.574882    0.463201        3.40         3.40   \n",
              "7236 -0.278435          D  0.747327    0.403540        4.33         1.53   \n",
              "7237  0.106501          A  0.106501    0.851155        1.30         1.30   \n",
              "7238  0.484222          D  0.484222    0.424063        3.50         0.00   \n",
              "7239  0.136872          A  0.137821    0.316061        3.60         0.00   \n",
              "7240  0.443337          D  0.443337    0.424511        3.40         3.40   \n",
              "7241  0.445979          A  0.445979    0.413137        3.50         0.00   \n",
              "7242  0.389677          D  0.389677    0.479199        2.90         0.00   \n",
              "7243  0.110582          A  0.110582    0.616990        1.80         0.00   \n",
              "7244  0.138200          A  0.138200    0.505867        2.25         0.00   \n",
              "7245  0.680916          D  0.680916    0.509368        3.30         0.00   \n",
              "7246 -0.267771          D  1.229495    0.318499        7.00         1.18   \n",
              "7247  0.404275          D  0.404275    0.401221        3.50         3.50   \n",
              "7248  0.409581          D  0.409581    0.454704        3.10         0.00   \n",
              "7249  0.318909          D  0.318909    0.412159        3.20         0.00   \n",
              "7250  0.000959          D  0.203704    0.218855        5.50         0.00   \n",
              "7251 -0.245974          D  0.279451    0.376309        3.40         0.00   \n",
              "7252  0.869793          D  0.869793    0.479434        3.90         0.00   \n",
              "7253  0.867595          D  0.867595    0.504755        3.70         0.00   \n",
              "7254  0.269878          D  0.269878    0.409638        3.10         0.00   \n",
              "7255 -0.169337          D  0.700041    0.392619        4.33         1.60   \n",
              "7256  0.813282          D  0.813282    0.464944        3.90         3.90   \n",
              "7257  0.348731          D  0.348731    0.414994        3.25         3.25   \n",
              "7258  0.538020          D  0.538020    0.480631        3.20         0.00   \n",
              "7259 -0.105005          D  0.452067    0.207438        7.00         1.22   \n",
              "7260  0.710147          D  0.710147    0.502985        3.40         0.00   \n",
              "7261  0.675092          D  0.675092    0.465303        3.60         0.00   \n",
              "7262 -0.304997          D  0.677169    0.387337        4.33         1.55   \n",
              "7263  0.556825          D  0.556825    0.518942        3.00         0.00   \n",
              "7264  0.685434          D  0.685434    0.468176        3.60         0.00   \n",
              "7265 -0.141693          D  0.500929    0.214418        7.00         1.20   \n",
              "7266  0.705448          D  0.705448    0.550144        3.10         0.00   \n",
              "7267  0.475497          D  0.475497    0.447120        3.30         3.30   \n",
              "7268 -0.090666          D  0.264591    0.351275        3.60         0.00   \n",
              "7269  0.451768          D  0.451768    0.453678        3.20         0.00   \n",
              "7270 -0.125324          D  0.440430    0.221605        6.50         1.22   \n",
              "7271 -0.363360          D  0.872859    0.432531        4.33         0.00   \n",
              "7272 -0.089517          D  0.394250    0.242478        5.75         1.33   \n",
              "7273  0.199556          A  0.199556    0.521546        2.30         2.30   \n",
              "7274  0.511477          D  0.511477    0.487573        3.10         3.10   \n",
              "7275  0.402040          D  0.402040    0.483462        2.90         2.90   \n",
              "7276 -0.369162          D  0.829132    0.406474        4.50         1.50   \n",
              "7277  0.797817          D  0.797817    0.528770        3.40         0.00   \n",
              "7278  0.662666          D  0.662666    0.511589        3.25         3.25   \n",
              "7279 -0.044940          D  0.094706    0.190384        5.75         1.25   \n",
              "\n",
              "      net_profit  \n",
              "7220       -1.00  \n",
              "7221        0.40  \n",
              "7222        0.40  \n",
              "7223       -1.00  \n",
              "7224        1.90  \n",
              "7225       -1.00  \n",
              "7226       -1.00  \n",
              "7227       -1.00  \n",
              "7228       -1.00  \n",
              "7229        0.22  \n",
              "7230       -1.00  \n",
              "7231       -1.00  \n",
              "7232        0.25  \n",
              "7233       -1.00  \n",
              "7234       -1.00  \n",
              "7235        2.40  \n",
              "7236        0.53  \n",
              "7237        0.30  \n",
              "7238       -1.00  \n",
              "7239       -1.00  \n",
              "7240        2.40  \n",
              "7241       -1.00  \n",
              "7242       -1.00  \n",
              "7243       -1.00  \n",
              "7244       -1.00  \n",
              "7245       -1.00  \n",
              "7246        0.18  \n",
              "7247        2.50  \n",
              "7248       -1.00  \n",
              "7249       -1.00  \n",
              "7250       -1.00  \n",
              "7251       -1.00  \n",
              "7252       -1.00  \n",
              "7253       -1.00  \n",
              "7254       -1.00  \n",
              "7255        0.60  \n",
              "7256        2.90  \n",
              "7257        2.25  \n",
              "7258       -1.00  \n",
              "7259        0.22  \n",
              "7260       -1.00  \n",
              "7261       -1.00  \n",
              "7262        0.55  \n",
              "7263       -1.00  \n",
              "7264       -1.00  \n",
              "7265        0.20  \n",
              "7266       -1.00  \n",
              "7267        2.30  \n",
              "7268       -1.00  \n",
              "7269       -1.00  \n",
              "7270        0.22  \n",
              "7271       -1.00  \n",
              "7272        0.33  \n",
              "7273        1.30  \n",
              "7274        2.10  \n",
              "7275        1.90  \n",
              "7276        0.50  \n",
              "7277       -1.00  \n",
              "7278        2.25  \n",
              "7279        0.25  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-336d0fcf-db3b-4405-8147-8a337e84da79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Season</th>\n",
              "      <th>Date</th>\n",
              "      <th>HomeTeam_norm</th>\n",
              "      <th>AwayTeam_norm</th>\n",
              "      <th>Wk</th>\n",
              "      <th>B365H</th>\n",
              "      <th>B365D</th>\n",
              "      <th>B365A</th>\n",
              "      <th>true_result</th>\n",
              "      <th>predicted_result</th>\n",
              "      <th>Pred</th>\n",
              "      <th>predicted_prob</th>\n",
              "      <th>predicted_odds</th>\n",
              "      <th>edge</th>\n",
              "      <th>value_pick</th>\n",
              "      <th>value_ev</th>\n",
              "      <th>value_prob</th>\n",
              "      <th>value_odds</th>\n",
              "      <th>bet_outcome</th>\n",
              "      <th>net_profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7220</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>girona</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.499332</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.622829</td>\n",
              "      <td>D</td>\n",
              "      <td>0.622829</td>\n",
              "      <td>0.499332</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7221</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-15</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>0</td>\n",
              "      <td>1.40</td>\n",
              "      <td>4.75</td>\n",
              "      <td>8.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.618078</td>\n",
              "      <td>1.40</td>\n",
              "      <td>-0.134690</td>\n",
              "      <td>A</td>\n",
              "      <td>0.749049</td>\n",
              "      <td>0.218631</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>0</td>\n",
              "      <td>7.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.720919</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.009287</td>\n",
              "      <td>D</td>\n",
              "      <td>0.142345</td>\n",
              "      <td>0.228469</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>alaves</td>\n",
              "      <td>levante</td>\n",
              "      <td>0</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.433790</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.301370</td>\n",
              "      <td>A</td>\n",
              "      <td>0.432825</td>\n",
              "      <td>0.377059</td>\n",
              "      <td>3.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-16</td>\n",
              "      <td>valencia</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.536792</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.556698</td>\n",
              "      <td>D</td>\n",
              "      <td>0.556698</td>\n",
              "      <td>0.536792</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7225</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>0</td>\n",
              "      <td>1.57</td>\n",
              "      <td>3.90</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.533934</td>\n",
              "      <td>3.90</td>\n",
              "      <td>1.082342</td>\n",
              "      <td>D</td>\n",
              "      <td>1.082342</td>\n",
              "      <td>0.533934</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7226</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>espanol</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>6.00</td>\n",
              "      <td>3.90</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.664891</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.043878</td>\n",
              "      <td>A</td>\n",
              "      <td>0.043878</td>\n",
              "      <td>0.664891</td>\n",
              "      <td>1.57</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7227</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-17</td>\n",
              "      <td>celta</td>\n",
              "      <td>getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.453777</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.588220</td>\n",
              "      <td>D</td>\n",
              "      <td>0.588220</td>\n",
              "      <td>0.453777</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7228</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-18</td>\n",
              "      <td>elche</td>\n",
              "      <td>betis</td>\n",
              "      <td>0</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.477952</td>\n",
              "      <td>2.20</td>\n",
              "      <td>0.051494</td>\n",
              "      <td>D</td>\n",
              "      <td>0.282234</td>\n",
              "      <td>0.388556</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7229</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-19</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>0</td>\n",
              "      <td>1.22</td>\n",
              "      <td>6.25</td>\n",
              "      <td>13.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.640304</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.218829</td>\n",
              "      <td>D</td>\n",
              "      <td>0.793283</td>\n",
              "      <td>0.286925</td>\n",
              "      <td>6.25</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7230</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-22</td>\n",
              "      <td>betis</td>\n",
              "      <td>alaves</td>\n",
              "      <td>0</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.20</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.424825</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.444406</td>\n",
              "      <td>D</td>\n",
              "      <td>0.444406</td>\n",
              "      <td>0.424825</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7231</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>elche</td>\n",
              "      <td>0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>5.25</td>\n",
              "      <td>15.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.714517</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-0.106853</td>\n",
              "      <td>D</td>\n",
              "      <td>0.152093</td>\n",
              "      <td>0.219446</td>\n",
              "      <td>5.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7232</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>levante</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>0</td>\n",
              "      <td>11.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.808501</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.010626</td>\n",
              "      <td>A</td>\n",
              "      <td>0.010626</td>\n",
              "      <td>0.808501</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7233</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-23</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>celta</td>\n",
              "      <td>0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.449563</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0.146385</td>\n",
              "      <td>D</td>\n",
              "      <td>0.289629</td>\n",
              "      <td>0.416009</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7234</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>valencia</td>\n",
              "      <td>0</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.509532</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.630501</td>\n",
              "      <td>D</td>\n",
              "      <td>0.630501</td>\n",
              "      <td>0.509532</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7235</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>espanol</td>\n",
              "      <td>0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.40</td>\n",
              "      <td>5.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.463201</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.574882</td>\n",
              "      <td>D</td>\n",
              "      <td>0.574882</td>\n",
              "      <td>0.463201</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7236</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>girona</td>\n",
              "      <td>0</td>\n",
              "      <td>1.53</td>\n",
              "      <td>4.33</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.471611</td>\n",
              "      <td>1.53</td>\n",
              "      <td>-0.278435</td>\n",
              "      <td>D</td>\n",
              "      <td>0.747327</td>\n",
              "      <td>0.403540</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.53</td>\n",
              "      <td>0.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7237</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-24</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>9.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.851155</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.106501</td>\n",
              "      <td>A</td>\n",
              "      <td>0.106501</td>\n",
              "      <td>0.851155</td>\n",
              "      <td>1.30</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7238</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>0</td>\n",
              "      <td>1.70</td>\n",
              "      <td>3.50</td>\n",
              "      <td>5.50</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.424063</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.484222</td>\n",
              "      <td>D</td>\n",
              "      <td>0.484222</td>\n",
              "      <td>0.424063</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7239</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-25</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.378957</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.136872</td>\n",
              "      <td>A</td>\n",
              "      <td>0.137821</td>\n",
              "      <td>0.316061</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7240</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-27</td>\n",
              "      <td>celta</td>\n",
              "      <td>betis</td>\n",
              "      <td>0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.25</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.424511</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.443337</td>\n",
              "      <td>D</td>\n",
              "      <td>0.443337</td>\n",
              "      <td>0.424511</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7241</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>elche</td>\n",
              "      <td>levante</td>\n",
              "      <td>0</td>\n",
              "      <td>2.15</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.413137</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.445979</td>\n",
              "      <td>A</td>\n",
              "      <td>0.445979</td>\n",
              "      <td>0.413137</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7242</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>valencia</td>\n",
              "      <td>getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.479199</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.389677</td>\n",
              "      <td>D</td>\n",
              "      <td>0.389677</td>\n",
              "      <td>0.479199</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7243</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>alaves</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>4.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>1.80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.110582</td>\n",
              "      <td>A</td>\n",
              "      <td>0.110582</td>\n",
              "      <td>0.616990</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7244</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>0</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.25</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.505867</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.138200</td>\n",
              "      <td>A</td>\n",
              "      <td>0.138200</td>\n",
              "      <td>0.505867</td>\n",
              "      <td>2.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7245</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>girona</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>0</td>\n",
              "      <td>2.40</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.509368</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.680916</td>\n",
              "      <td>D</td>\n",
              "      <td>0.680916</td>\n",
              "      <td>0.509368</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7246</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-30</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>0</td>\n",
              "      <td>1.18</td>\n",
              "      <td>7.00</td>\n",
              "      <td>15.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.620533</td>\n",
              "      <td>1.18</td>\n",
              "      <td>-0.267771</td>\n",
              "      <td>D</td>\n",
              "      <td>1.229495</td>\n",
              "      <td>0.318499</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.18</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7247</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>celta</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>0</td>\n",
              "      <td>2.75</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.401221</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0.404275</td>\n",
              "      <td>D</td>\n",
              "      <td>0.404275</td>\n",
              "      <td>0.401221</td>\n",
              "      <td>3.50</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7248</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>betis</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.55</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.454704</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.409581</td>\n",
              "      <td>D</td>\n",
              "      <td>0.409581</td>\n",
              "      <td>0.454704</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7249</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>espanol</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>0</td>\n",
              "      <td>2.38</td>\n",
              "      <td>3.20</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.412159</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.318909</td>\n",
              "      <td>D</td>\n",
              "      <td>0.318909</td>\n",
              "      <td>0.412159</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7250</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-08-31</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>0</td>\n",
              "      <td>6.25</td>\n",
              "      <td>5.50</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.714970</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.000959</td>\n",
              "      <td>D</td>\n",
              "      <td>0.203704</td>\n",
              "      <td>0.218855</td>\n",
              "      <td>5.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7251</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-12</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>elche</td>\n",
              "      <td>0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.407582</td>\n",
              "      <td>1.85</td>\n",
              "      <td>-0.245974</td>\n",
              "      <td>D</td>\n",
              "      <td>0.279451</td>\n",
              "      <td>0.376309</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7252</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>alaves</td>\n",
              "      <td>0</td>\n",
              "      <td>1.60</td>\n",
              "      <td>3.90</td>\n",
              "      <td>5.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.479434</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.869793</td>\n",
              "      <td>D</td>\n",
              "      <td>0.869793</td>\n",
              "      <td>0.479434</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7253</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.70</td>\n",
              "      <td>4.33</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.504755</td>\n",
              "      <td>3.70</td>\n",
              "      <td>0.867595</td>\n",
              "      <td>D</td>\n",
              "      <td>0.867595</td>\n",
              "      <td>0.504755</td>\n",
              "      <td>3.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7254</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>getafe</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>3.10</td>\n",
              "      <td>4.50</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.409638</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.269878</td>\n",
              "      <td>D</td>\n",
              "      <td>0.269878</td>\n",
              "      <td>0.409638</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7255</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-13</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.519164</td>\n",
              "      <td>1.60</td>\n",
              "      <td>-0.169337</td>\n",
              "      <td>D</td>\n",
              "      <td>0.700041</td>\n",
              "      <td>0.392619</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7256</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>celta</td>\n",
              "      <td>girona</td>\n",
              "      <td>0</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.90</td>\n",
              "      <td>4.75</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.464944</td>\n",
              "      <td>3.90</td>\n",
              "      <td>0.813282</td>\n",
              "      <td>D</td>\n",
              "      <td>0.813282</td>\n",
              "      <td>0.464944</td>\n",
              "      <td>3.90</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7257</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>levante</td>\n",
              "      <td>betis</td>\n",
              "      <td>0</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.414994</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.348731</td>\n",
              "      <td>D</td>\n",
              "      <td>0.348731</td>\n",
              "      <td>0.414994</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7258</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>0</td>\n",
              "      <td>2.55</td>\n",
              "      <td>3.20</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.480631</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.538020</td>\n",
              "      <td>D</td>\n",
              "      <td>0.538020</td>\n",
              "      <td>0.480631</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7259</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-14</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>valencia</td>\n",
              "      <td>0</td>\n",
              "      <td>1.22</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.733602</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.105005</td>\n",
              "      <td>D</td>\n",
              "      <td>0.452067</td>\n",
              "      <td>0.207438</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7260</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-15</td>\n",
              "      <td>espanol</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>0</td>\n",
              "      <td>2.10</td>\n",
              "      <td>3.40</td>\n",
              "      <td>3.50</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.502985</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.710147</td>\n",
              "      <td>D</td>\n",
              "      <td>0.710147</td>\n",
              "      <td>0.502985</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7261</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-19</td>\n",
              "      <td>betis</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>0</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.60</td>\n",
              "      <td>3.75</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.465303</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.675092</td>\n",
              "      <td>D</td>\n",
              "      <td>0.675092</td>\n",
              "      <td>0.465303</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7262</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>0</td>\n",
              "      <td>1.55</td>\n",
              "      <td>4.33</td>\n",
              "      <td>5.50</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.448389</td>\n",
              "      <td>1.55</td>\n",
              "      <td>-0.304997</td>\n",
              "      <td>D</td>\n",
              "      <td>0.677169</td>\n",
              "      <td>0.387337</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7263</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>valencia</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.55</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.518942</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.556825</td>\n",
              "      <td>D</td>\n",
              "      <td>0.556825</td>\n",
              "      <td>0.518942</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7264</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>girona</td>\n",
              "      <td>levante</td>\n",
              "      <td>0</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.60</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.468176</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.685434</td>\n",
              "      <td>D</td>\n",
              "      <td>0.685434</td>\n",
              "      <td>0.468176</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7265</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>espanol</td>\n",
              "      <td>0</td>\n",
              "      <td>1.20</td>\n",
              "      <td>7.00</td>\n",
              "      <td>13.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.715256</td>\n",
              "      <td>1.20</td>\n",
              "      <td>-0.141693</td>\n",
              "      <td>D</td>\n",
              "      <td>0.500929</td>\n",
              "      <td>0.214418</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7266</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-20</td>\n",
              "      <td>alaves</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.50</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.550144</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.705448</td>\n",
              "      <td>D</td>\n",
              "      <td>0.705448</td>\n",
              "      <td>0.550144</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7267</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>celta</td>\n",
              "      <td>0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.447120</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.475497</td>\n",
              "      <td>D</td>\n",
              "      <td>0.475497</td>\n",
              "      <td>0.447120</td>\n",
              "      <td>3.30</td>\n",
              "      <td>3.30</td>\n",
              "      <td>2.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7268</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.519620</td>\n",
              "      <td>1.75</td>\n",
              "      <td>-0.090666</td>\n",
              "      <td>D</td>\n",
              "      <td>0.264591</td>\n",
              "      <td>0.351275</td>\n",
              "      <td>3.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>elche</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>0</td>\n",
              "      <td>1.91</td>\n",
              "      <td>3.20</td>\n",
              "      <td>4.50</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.453678</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.451768</td>\n",
              "      <td>D</td>\n",
              "      <td>0.451768</td>\n",
              "      <td>0.453678</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-21</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>getafe</td>\n",
              "      <td>0</td>\n",
              "      <td>1.22</td>\n",
              "      <td>6.50</td>\n",
              "      <td>12.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.716947</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.125324</td>\n",
              "      <td>D</td>\n",
              "      <td>0.440430</td>\n",
              "      <td>0.221605</td>\n",
              "      <td>6.50</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7271</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-23</td>\n",
              "      <td>ath bilbao</td>\n",
              "      <td>girona</td>\n",
              "      <td>0</td>\n",
              "      <td>1.45</td>\n",
              "      <td>4.33</td>\n",
              "      <td>7.00</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.439062</td>\n",
              "      <td>1.45</td>\n",
              "      <td>-0.363360</td>\n",
              "      <td>D</td>\n",
              "      <td>0.872859</td>\n",
              "      <td>0.432531</td>\n",
              "      <td>4.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7272</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-23</td>\n",
              "      <td>levante</td>\n",
              "      <td>real madrid</td>\n",
              "      <td>0</td>\n",
              "      <td>7.50</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.33</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.684573</td>\n",
              "      <td>1.33</td>\n",
              "      <td>-0.089517</td>\n",
              "      <td>D</td>\n",
              "      <td>0.394250</td>\n",
              "      <td>0.242478</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.33</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7273</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-23</td>\n",
              "      <td>sevilla</td>\n",
              "      <td>villarreal</td>\n",
              "      <td>0</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.40</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.521546</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.199556</td>\n",
              "      <td>A</td>\n",
              "      <td>0.199556</td>\n",
              "      <td>0.521546</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.30</td>\n",
              "      <td>1.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7274</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-23</td>\n",
              "      <td>espanol</td>\n",
              "      <td>valencia</td>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.487573</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.511477</td>\n",
              "      <td>D</td>\n",
              "      <td>0.511477</td>\n",
              "      <td>0.487573</td>\n",
              "      <td>3.10</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7275</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-24</td>\n",
              "      <td>getafe</td>\n",
              "      <td>alaves</td>\n",
              "      <td>0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>2.90</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.483462</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.402040</td>\n",
              "      <td>D</td>\n",
              "      <td>0.402040</td>\n",
              "      <td>0.483462</td>\n",
              "      <td>2.90</td>\n",
              "      <td>2.90</td>\n",
              "      <td>1.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7276</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-24</td>\n",
              "      <td>ath madrid</td>\n",
              "      <td>vallecano</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>4.50</td>\n",
              "      <td>6.00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>H</td>\n",
              "      <td>0.420559</td>\n",
              "      <td>1.50</td>\n",
              "      <td>-0.369162</td>\n",
              "      <td>D</td>\n",
              "      <td>0.829132</td>\n",
              "      <td>0.406474</td>\n",
              "      <td>4.50</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7277</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-24</td>\n",
              "      <td>sociedad</td>\n",
              "      <td>mallorca</td>\n",
              "      <td>0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>3.40</td>\n",
              "      <td>4.75</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.528770</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.797817</td>\n",
              "      <td>D</td>\n",
              "      <td>0.797817</td>\n",
              "      <td>0.528770</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7278</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-25</td>\n",
              "      <td>osasuna</td>\n",
              "      <td>elche</td>\n",
              "      <td>0</td>\n",
              "      <td>1.95</td>\n",
              "      <td>3.25</td>\n",
              "      <td>4.33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.511589</td>\n",
              "      <td>3.25</td>\n",
              "      <td>0.662666</td>\n",
              "      <td>D</td>\n",
              "      <td>0.662666</td>\n",
              "      <td>0.511589</td>\n",
              "      <td>3.25</td>\n",
              "      <td>3.25</td>\n",
              "      <td>2.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7279</th>\n",
              "      <td>2025</td>\n",
              "      <td>2025-09-25</td>\n",
              "      <td>real oviedo</td>\n",
              "      <td>barcelona</td>\n",
              "      <td>0</td>\n",
              "      <td>10.00</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>0.764048</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-0.044940</td>\n",
              "      <td>D</td>\n",
              "      <td>0.094706</td>\n",
              "      <td>0.190384</td>\n",
              "      <td>5.75</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-336d0fcf-db3b-4405-8147-8a337e84da79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-336d0fcf-db3b-4405-8147-8a337e84da79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-336d0fcf-db3b-4405-8147-8a337e84da79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3eccd69a-bc3d-4da1-8a89-4ad0e4a77fbc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3eccd69a-bc3d-4da1-8a89-4ad0e4a77fbc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3eccd69a-bc3d-4da1-8a89-4ad0e4a77fbc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# EJECUTAR EN LOCAL\n",
        "results_df, roi, total_profit = simulate_bet365_roi(df, model= model_sm, scaler= scaler_sm, train_until_season=2024, test_until_season=2025, with_odds=True, stake=1.0)\n",
        "print(roi)\n",
        "print(total_profit)\n",
        "results_df.tail(60)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# MATCH-LOG por temporada (predicción vs valor) + export\n",
        "# =========================\n",
        "\n",
        "# --- Mapas y utilidades ---\n",
        "CLASS2TXT = {0:\"A\", 1:\"D\", 2:\"H\"}   # 0=Away,1=Draw,2=Home\n",
        "TXT2CLASS = {\"A\":0, \"D\":1, \"H\":2}\n",
        "\n",
        "def _edge_bins(edge: pd.Series,\n",
        "               bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Tramos discretos para facilitar filtros por 'valor esperado' en la app.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "def _ensure_probs_adh(y_proba: np.ndarray, classes_model: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve DataFrame de probabilidades con columnas A/D/H,\n",
        "    completando columnas ausentes con NaN si el modelo no las tuvo en train.\n",
        "    \"\"\"\n",
        "    name_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "    cols = [name_map.get(int(c), str(c)) for c in classes_model]\n",
        "    proba_df = pd.DataFrame(y_proba, columns=cols)\n",
        "    for c in [\"A\",\"D\",\"H\"]:\n",
        "        if c not in proba_df.columns:\n",
        "            proba_df[c] = np.nan\n",
        "    return proba_df[[\"A\",\"D\",\"H\"]]\n",
        "\n",
        "def _inject_jornada(meta: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Añade/rehace la columna 'jornada' en meta:\n",
        "      - Prioriza meta['Wk'] si existe y > 0\n",
        "      - Si no, intenta mergear con los parquets de jornadas en PROC\n",
        "    \"\"\"\n",
        "    meta = meta.copy()\n",
        "    # 1) Punto de partida: Wk del propio meta, si existe y > 0\n",
        "    if \"Wk\" in meta.columns:\n",
        "        j = pd.to_numeric(meta[\"Wk\"], errors=\"coerce\")\n",
        "        j = j.where(j > 0)  # descarta 0/negativos\n",
        "        meta[\"jornada\"] = j\n",
        "    else:\n",
        "        meta[\"jornada\"] = pd.NA\n",
        "\n",
        "    # 2) Si falta o es todo NA/0, intenta completar desde parquet(s)\n",
        "    if meta[\"jornada\"].isna().all():\n",
        "        PROC_ = Path(PROC) if \"PROC\" in globals() else Path(\"./data/02_processed\")\n",
        "        for wk_name in [\"wk_actualizado_2005_2025.parquet\", \"wk_2005_2025.parquet\"]:\n",
        "            wk_path = PROC_ / wk_name\n",
        "            if wk_path.exists():\n",
        "                wk = pd.read_parquet(wk_path)\n",
        "                wk[\"Date\"] = pd.to_datetime(wk[\"Date\"], errors=\"coerce\")\n",
        "                # merge rico: Season+Date+Home+Away si están disponibles\n",
        "                merge_cols = [c for c in [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\"]\n",
        "                              if c in wk.columns and c in meta.columns]\n",
        "                if \"Wk\" in wk.columns and merge_cols:\n",
        "                    meta = meta.merge(\n",
        "                        wk[merge_cols+[\"Wk\"]].rename(columns={\"Wk\":\"Wk_src\"}),\n",
        "                        on=merge_cols, how=\"left\"\n",
        "                    )\n",
        "                    meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n",
        "                        pd.to_numeric(meta[\"Wk_src\"], errors=\"coerce\")\n",
        "                    )\n",
        "                    meta.drop(columns=[\"Wk_src\"], inplace=True, errors=\"ignore\")\n",
        "                # fallback: Season+Date\n",
        "                elif set([\"Season\",\"Date\",\"Wk\"]).issubset(wk.columns):\n",
        "                    meta = meta.merge(\n",
        "                        wk[[\"Season\",\"Date\",\"Wk\"]].drop_duplicates()\n",
        "                          .rename(columns={\"Wk\":\"Wk_src\"}),\n",
        "                        on=[\"Season\",\"Date\"], how=\"left\"\n",
        "                    )\n",
        "                    meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n",
        "                        pd.to_numeric(meta[\"Wk_src\"], errors=\"coerce\")\n",
        "                    )\n",
        "                    meta.drop(columns=[\"Wk_src\"], inplace=True, errors=\"ignore\")\n",
        "                break\n",
        "\n",
        "    meta[\"jornada\"] = pd.to_numeric(meta[\"jornada\"], errors=\"coerce\").astype(\"Int64\")\n",
        "    return meta\n",
        "\n",
        "def _make_matchlog_from_eval(\n",
        "    df: pd.DataFrame,\n",
        "    y_test: pd.Series,\n",
        "    y_pred: np.ndarray,\n",
        "    y_proba: np.ndarray,\n",
        "    idx_test: pd.Index,\n",
        "    *,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Construye el match-log (una fila por partido del TEST de esa temporada),\n",
        "    ahora con 'jornada' fiable (Wk o parquet de jornadas).\n",
        "    \"\"\"\n",
        "    # 1) Meta-información alineada por índice\n",
        "    need = [\"Season\",\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    if \"Wk\" in df.columns:  # si existe la traemos para intentar usarla\n",
        "        need.append(\"Wk\")\n",
        "\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"df necesita columnas {missing} para construir el match-log.\")\n",
        "\n",
        "    meta = df.loc[idx_test, need].copy()\n",
        "    meta[\"Date\"] = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "\n",
        "    # --- Jornada robusta ---\n",
        "    meta = _inject_jornada(meta)\n",
        "\n",
        "    # 2) Probabilidades A/D/H y odds en mismo orden (A,D,H)\n",
        "    proba_df = _ensure_probs_adh(y_proba, classes_model=np.array([0,1,2][:y_proba.shape[1]]))\n",
        "    proba_df.index = idx_test\n",
        "    odds_df = meta[[\"B365A\",\"B365D\",\"B365H\"]].rename(columns={\"B365A\":\"A\",\"B365D\":\"D\",\"B365H\":\"H\"})\n",
        "\n",
        "    # 3) Predicción del modelo + EV de la predicción\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(CLASS2TXT)\n",
        "    idx_of   = {\"A\":0,\"D\":1,\"H\":2}\n",
        "    pred_idx = pred_txt.map(idx_of).to_numpy()\n",
        "\n",
        "    P = proba_df.to_numpy()\n",
        "    O = odds_df[[\"A\",\"D\",\"H\"]].to_numpy()\n",
        "\n",
        "    out = meta.copy()\n",
        "    out[\"true_result\"]      = pd.Series(y_test, index=idx_test).values\n",
        "    out[\"predicted_result\"] = pd.Series(y_pred, index=idx_test).values\n",
        "    out[\"Pred\"]             = pred_txt.values\n",
        "\n",
        "    out[\"predicted_prob\"] = P[np.arange(len(out)), pred_idx]\n",
        "    out[\"predicted_odds\"] = O[np.arange(len(out)), pred_idx]\n",
        "    out[\"edge\"] = out[\"predicted_prob\"] * out[\"predicted_odds\"] - 1.0\n",
        "\n",
        "    # 4) Estrategia de VALOR\n",
        "    ev_df = proba_df * odds_df - 1.0\n",
        "    best_idx = ev_df[[\"A\",\"D\",\"H\"]].to_numpy().argmax(axis=1)\n",
        "    labels  = np.array([\"A\",\"D\",\"H\"])\n",
        "    out[\"value_pick\"] = labels[best_idx]\n",
        "    out[\"value_ev\"]   = ev_df.to_numpy()[np.arange(len(out)), best_idx]\n",
        "    out[\"value_prob\"] = P[np.arange(len(out)), best_idx]\n",
        "    out[\"value_odds\"] = O[np.arange(len(out)), best_idx]\n",
        "\n",
        "    # 5) Requisitos + filtros\n",
        "    mask_ok_odds = out[[\"B365H\",\"B365D\",\"B365A\"]].notna().all(axis=1)\n",
        "    out = out.loc[mask_ok_odds].copy()\n",
        "    if min_edge_pred > 0:\n",
        "        out = out.loc[out[\"edge\"] >= min_edge_pred].copy()\n",
        "    if out.empty:\n",
        "        return out\n",
        "\n",
        "    if min_edge_value is None:\n",
        "        min_edge_value = min_edge_pred\n",
        "    out[\"use_value\"] = (out[\"value_ev\"] >= min_edge_value) if (min_edge_value and min_edge_value > 0) else True\n",
        "\n",
        "    # 6) Beneficios\n",
        "    out[\"bet_return\"] = np.where(out[\"predicted_result\"] == out[\"true_result\"], out[\"predicted_odds\"] * stake, 0.0)\n",
        "    out[\"net_profit\"] = out[\"bet_return\"] - stake\n",
        "\n",
        "    idx_of = {\"A\":0,\"D\":1,\"H\":2}\n",
        "    value_idx = out[\"value_pick\"].map(idx_of).to_numpy()\n",
        "    value_hit = (value_idx == out[\"true_result\"])\n",
        "    value_ret = np.where(value_hit, out[\"value_odds\"] * stake, 0.0)\n",
        "    out[\"value_bet_return\"] = np.where(out[\"use_value\"], value_ret, 0.0)\n",
        "    out[\"value_net_profit\"] = np.where(out[\"use_value\"], out[\"value_bet_return\"] - stake, 0.0)\n",
        "\n",
        "    # 7) Apoyo app\n",
        "    out[\"Correct\"]       = np.where(out[\"predicted_result\"] == out[\"true_result\"], \"✓\", \"✗\")\n",
        "    out[\"value_correct\"] = np.where(value_hit, \"✓\", \"✗\")\n",
        "    out[\"edge_bin\"]      = _edge_bins(out[\"edge\"])\n",
        "    out[\"value_bin\"]     = _edge_bins(out[\"value_ev\"])\n",
        "\n",
        "    # 8) Orden y formato\n",
        "    out[\"Date\"] = pd.to_datetime(out[\"Date\"], errors=\"coerce\")\n",
        "    out = out.sort_values([\"Season\",\"jornada\",\"Date\"]).reset_index(drop=True)\n",
        "    out[\"Date\"] = out[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    return out\n",
        "\n",
        "def build_matchlog_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    *,\n",
        "    model: str = \"base\",          # \"base\" | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Para cada temporada S (train ≤ S-1, test = S) entrena/evalúa el modelo escogido,\n",
        "    construye el match-log (partido a partido) con columnas de Predicción y Valor,\n",
        "    y exporta CSV/JSON por temporada + un resumen por temporada con ROI de ambas estrategias.\n",
        "    >>> Los match-logs por temporada incluyen 'jornada'.\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    per_season_dir = out_dir / f\"matchlogs_{model}\"\n",
        "    per_season_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    season_summary = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval_no_smote(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Match-log con 'jornada'\n",
        "            ml = _make_matchlog_from_eval(\n",
        "                df, y_test, y_pred, y_proba, idx_test,\n",
        "                stake=stake, min_edge_pred=min_edge_pred, min_edge_value=min_edge_value\n",
        "            )\n",
        "            if ml.empty:\n",
        "                continue\n",
        "\n",
        "            # ROI/beneficio por temporada (igual que antes)\n",
        "            n_pred = len(ml)\n",
        "            roi_pred = float(ml[\"net_profit\"].sum() / (stake * n_pred))\n",
        "            n_val = int(ml[\"use_value\"].sum())\n",
        "            roi_val = float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() / (stake * n_val)) if n_val > 0 else np.nan\n",
        "\n",
        "            # Guardados por temporada (incluyen 'jornada')\n",
        "            csv_path  = per_season_dir / f\"matchlog_{test_season}.csv\"\n",
        "            json_path = per_season_dir / f\"matchlog_{test_season}.json\"\n",
        "            ml.to_csv(csv_path, index=False)\n",
        "            ml.to_json(json_path, orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "            season_summary.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"n_pred_bets\": int(n_pred),\n",
        "                \"roi_pred\": roi_pred,\n",
        "                \"profit_pred\": float(ml[\"net_profit\"].sum()),\n",
        "                \"n_value_bets\": int(n_val),\n",
        "                \"roi_value\": roi_val,\n",
        "                \"profit_value\": float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() if n_val > 0 else 0.0),\n",
        "                \"min_edge_pred\": float(min_edge_pred),\n",
        "                \"min_edge_value\": float(min_edge_value if (min_edge_value is not None) else min_edge_pred),\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            })\n",
        "            print(f\"[{model}] Season {test_season}: guardado match-log ({len(ml)} filas)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[MATCHLOG {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    # Resumen por temporada (sin jornada, como antes)\n",
        "    if season_summary:\n",
        "        df_sum = pd.DataFrame(season_summary).sort_values(\"test_season\")\n",
        "        df_sum.to_csv(out_dir / f\"matchlog_season_summary_{model}.csv\", index=False)\n",
        "        (out_dir / f\"matchlog_season_summary_{model}.json\").write_text(\n",
        "            json.dumps(season_summary, ensure_ascii=False, indent=2),\n",
        "            encoding=\"utf-8\"\n",
        "        )\n",
        "        print(f\"Guardados:\\n- {out_dir/f'matchlog_season_summary_{model}.csv'}\\n- {out_dir/f'matchlog_season_summary_{model}.json'}\")\n",
        "    else:\n",
        "        print(\"Sin temporadas válidas para exportar matchlogs.\")\n",
        "\n",
        "# =========================\n",
        "# EJECUCIÓN (igual que tenías)\n",
        "# =========================\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"base\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,\n",
        "    min_edge_value=None\n",
        ")\n",
        "\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"smote\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,\n",
        "    min_edge_value=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkHHzvKck-Gm",
        "outputId": "d81f7e26-c400-46a2-ffae-bbd8177af3ad"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6, 'log_loss': 0.8503040399360499, 'brier': 0.5104307269727479, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4263157894736842, 'log_loss': 1.234912538739745, 'brier': 0.7084656252008951, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[MATCHLOG BASE SKIP] test=2007 → Length of values (380) does not match length of index (2520)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5565789473684211, 'log_loss': 0.9214888832439952, 'brier': 0.552017798278286, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.0946781196370998, 'brier': 0.6514989943768685, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[MATCHLOG BASE SKIP] test=2008 → Length of values (380) does not match length of index (2372)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5482456140350878, 'log_loss': 0.9341333936534477, 'brier': 0.5582402681906519, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.531578947368421, 'log_loss': 0.9731693801920157, 'brier': 0.5740858195095201, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[MATCHLOG BASE SKIP] test=2009 → Length of values (380) does not match length of index (2034)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5486842105263158, 'log_loss': 0.9279406338478252, 'brier': 0.5543308157141086, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5842105263157895, 'log_loss': 0.9611714000747812, 'brier': 0.5600985795015131, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[MATCHLOG BASE SKIP] test=2010 → Length of values (380) does not match length of index (1900)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5673684210526316, 'log_loss': 0.92567347721971, 'brier': 0.5503509561104474, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9618637854826375, 'brier': 0.569337462696509, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[MATCHLOG BASE SKIP] test=2011 → Length of values (380) does not match length of index (1805)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5649122807017544, 'log_loss': 0.9258206035623451, 'brier': 0.5508649323751328, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5263157894736842, 'log_loss': 0.9812522610577148, 'brier': 0.5741574692017298, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[MATCHLOG BASE SKIP] test=2012 → Length of values (380) does not match length of index (1544)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5620300751879699, 'log_loss': 0.9300982185449254, 'brier': 0.5525997571886312, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9816107988614631, 'brier': 0.5792206499536022, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[MATCHLOG BASE SKIP] test=2013 → Length of values (380) does not match length of index (1368)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5588815789473685, 'log_loss': 0.932953241748893, 'brier': 0.5539945012156289, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5578947368421052, 'log_loss': 0.9533905266381169, 'brier': 0.5579255333473289, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[MATCHLOG BASE SKIP] test=2014 → Length of values (380) does not match length of index (1516)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5590643274853802, 'log_loss': 0.9302045400187785, 'brier': 0.551695173347987, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9554489087510584, 'brier': 0.5668172018067045, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[MATCHLOG BASE SKIP] test=2015 → Length of values (380) does not match length of index (1628)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.56, 'log_loss': 0.9296168555376824, 'brier': 0.5512567599140625, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9424364646555845, 'brier': 0.5572641920758349, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[MATCHLOG BASE SKIP] test=2016 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.562200956937799, 'log_loss': 0.9280061580011343, 'brier': 0.5499175362118004, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5368421052631579, 'log_loss': 0.9718768790598807, 'brier': 0.5759491180403586, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[MATCHLOG BASE SKIP] test=2017 → Length of values (380) does not match length of index (1388)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5622807017543859, 'log_loss': 0.9302030199327271, 'brier': 0.551172040254874, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.48947368421052634, 'log_loss': 1.0447989195979444, 'brier': 0.6239512631509635, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[MATCHLOG BASE SKIP] test=2018 → Length of values (380) does not match length of index (1488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5562753036437247, 'log_loss': 0.9373991477942386, 'brier': 0.5558697065701285, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.4710526315789474, 'log_loss': 1.0046309623103469, 'brier': 0.60042492501783, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[MATCHLOG BASE SKIP] test=2019 → Length of values (380) does not match length of index (1584)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5513157894736842, 'log_loss': 0.941053099742395, 'brier': 0.5583159465810769, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5131578947368421, 'log_loss': 1.0027102003334487, 'brier': 0.5957333636955684, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[MATCHLOG BASE SKIP] test=2020 → Length of values (380) does not match length of index (1500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503508771929825, 'log_loss': 0.9443762569444348, 'brier': 0.5603350753522194, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5078947368421053, 'log_loss': 1.000834198335483, 'brier': 0.5976131120685585, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[MATCHLOG BASE SKIP] test=2021 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.9470694509392333, 'brier': 0.561971765511791, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9845858767265123, 'brier': 0.5857510525064844, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[MATCHLOG BASE SKIP] test=2022 → Length of values (380) does not match length of index (1404)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5503095975232198, 'log_loss': 0.9487672055459645, 'brier': 0.56301460337696, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9526624544514743, 'brier': 0.5671253491342783, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[MATCHLOG BASE SKIP] test=2023 → Length of values (380) does not match length of index (1340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5497076023391813, 'log_loss': 0.9484854524823103, 'brier': 0.562807791558073, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9582196819419253, 'brier': 0.5659048337474383, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[MATCHLOG BASE SKIP] test=2024 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5520775623268698, 'log_loss': 0.9485428490794315, 'brier': 0.5627369524063253, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.4666666666666667, 'log_loss': 0.9598671705854682, 'brier': 0.5768538551458187, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "[MATCHLOG BASE SKIP] test=2025 → Length of values (60) does not match length of index (196)\n",
            "Sin temporadas válidas para exportar matchlogs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6052631578947368, 'log_loss': 0.8793798310218244, 'brier': 0.523692392112868, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.3494414120417446, 'brier': 0.7661194141297701, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[MATCHLOG SMOTE SKIP] test=2007 → Length of values (380) does not match length of index (2520)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9647718217284392, 'brier': 0.582134391362193, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.3973684210526316, 'log_loss': 1.1495529048749027, 'brier': 0.6940270060264039, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[MATCHLOG SMOTE SKIP] test=2008 → Length of values (380) does not match length of index (2372)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5140350877192983, 'log_loss': 0.9766692149791395, 'brier': 0.5859414553822485, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.5052631578947369, 'log_loss': 1.0103624493077452, 'brier': 0.6020827559761309, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[MATCHLOG SMOTE SKIP] test=2009 → Length of values (380) does not match length of index (2034)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5125, 'log_loss': 0.9730329277874553, 'brier': 0.5841841986950229, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.009044728224987, 'brier': 0.5971040145487275, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[MATCHLOG SMOTE SKIP] test=2010 → Length of values (380) does not match length of index (1900)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9749564386011589, 'brier': 0.583167368232321, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9783782347468017, 'brier': 0.5781124855784574, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[MATCHLOG SMOTE SKIP] test=2011 → Length of values (380) does not match length of index (1805)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5083333333333333, 'log_loss': 0.9751847278974717, 'brier': 0.583967377715168, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0464407705340646, 'brier': 0.6219848123946629, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[MATCHLOG SMOTE SKIP] test=2012 → Length of values (380) does not match length of index (1544)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9794976746216008, 'brier': 0.5860324279278233, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9971228486477329, 'brier': 0.5859234635771664, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[MATCHLOG SMOTE SKIP] test=2013 → Length of values (380) does not match length of index (1368)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5039473684210526, 'log_loss': 0.9818700755710192, 'brier': 0.5863903224411537, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.970422002513115, 'brier': 0.575921200422478, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[MATCHLOG SMOTE SKIP] test=2014 → Length of values (380) does not match length of index (1516)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5093567251461988, 'log_loss': 0.9760204302029908, 'brier': 0.5816600917198619, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45526315789473687, 'log_loss': 1.019408267791883, 'brier': 0.609072054083051, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[MATCHLOG SMOTE SKIP] test=2015 → Length of values (380) does not match length of index (1628)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5097368421052632, 'log_loss': 0.975206772217476, 'brier': 0.5810247836174002, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 0.9914886966591454, 'brier': 0.5921446674474815, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[MATCHLOG SMOTE SKIP] test=2016 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5016746411483254, 'log_loss': 0.9743201540209397, 'brier': 0.5803731120209206, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46578947368421053, 'log_loss': 1.0429158819689923, 'brier': 0.6242820468852509, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[MATCHLOG SMOTE SKIP] test=2017 → Length of values (380) does not match length of index (1388)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5037280701754386, 'log_loss': 0.975879904764943, 'brier': 0.5809013223010673, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4, 'log_loss': 1.1046583767479627, 'brier': 0.6662653937337163, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[MATCHLOG SMOTE SKIP] test=2018 → Length of values (380) does not match length of index (1488)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49858299595141703, 'log_loss': 0.9809997608146642, 'brier': 0.5842892778988256, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.40789473684210525, 'log_loss': 1.0845882086972118, 'brier': 0.6517951035378253, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[MATCHLOG SMOTE SKIP] test=2019 → Length of values (380) does not match length of index (1584)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4956766917293233, 'log_loss': 0.9835393399987066, 'brier': 0.5860707151517507, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0321666629094723, 'brier': 0.6176940774374018, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[MATCHLOG SMOTE SKIP] test=2020 → Length of values (380) does not match length of index (1500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4982456140350877, 'log_loss': 0.9843751271079832, 'brier': 0.5866373891050684, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.4631578947368421, 'log_loss': 1.039191504416154, 'brier': 0.6260655399038726, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[MATCHLOG SMOTE SKIP] test=2021 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5034539473684211, 'log_loss': 0.9851200116883061, 'brier': 0.5869814703331031, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0435399236306386, 'brier': 0.6209486504875658, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[MATCHLOG SMOTE SKIP] test=2022 → Length of values (380) does not match length of index (1404)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5012383900928793, 'log_loss': 0.9872113846895132, 'brier': 0.5881998144023869, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9792553905618867, 'brier': 0.5901580888676006, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[MATCHLOG SMOTE SKIP] test=2023 → Length of values (380) does not match length of index (1340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5001461988304093, 'log_loss': 0.9851707791657534, 'brier': 0.5868437108477133, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9906024146619237, 'brier': 0.5895007033026378, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[MATCHLOG SMOTE SKIP] test=2024 → Length of values (380) does not match length of index (1400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5013850415512465, 'log_loss': 0.9841414945443792, 'brier': 0.5860157980797667, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43333333333333335, 'log_loss': 1.0173246489644299, 'brier': 0.6160581127766295, 'n_test': 60, 'season_min': 2025, 'season_max': 2025}\n",
            "[MATCHLOG SMOTE SKIP] test=2025 → Length of values (60) does not match length of index (196)\n",
            "Sin temporadas válidas para exportar matchlogs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1907800712.py:59: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
            "  meta[\"jornada\"] = meta[\"jornada\"].combine_first(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBffDLHUX1nw",
        "outputId": "e4c41aa1-a0b3-4728-909e-34fe8b88c67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.6105263157894737, 'log_loss': 0.8529715015512208, 'brier': 0.5126050979185605, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.4131578947368421, 'log_loss': 1.2357788018071167, 'brier': 0.7108253532823114, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[base] Season 2007: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.92320990288169, 'brier': 0.5525509324329174, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4789473684210526, 'log_loss': 1.0902924033829702, 'brier': 0.6481976863657879, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[base] Season 2008: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491228070175439, 'log_loss': 0.9354323737003613, 'brier': 0.5585766915416096, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.55, 'log_loss': 0.969389177295256, 'brier': 0.5716061373746928, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[base] Season 2009: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9281050599048366, 'brier': 0.5541952556364464, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.5815789473684211, 'log_loss': 0.9613777147331831, 'brier': 0.5600725878605084, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[base] Season 2010: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5657894736842105, 'log_loss': 0.9259413530737372, 'brier': 0.550425284238913, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5552631578947368, 'log_loss': 0.9626927361922272, 'brier': 0.5700421398423358, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[base] Season 2011: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5614035087719298, 'log_loss': 0.9260253669981706, 'brier': 0.5509174991694796, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.5342105263157895, 'log_loss': 0.9837610784586179, 'brier': 0.5754646771774361, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[base] Season 2012: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5616541353383459, 'log_loss': 0.930651791058408, 'brier': 0.5528769289719954, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5157894736842106, 'log_loss': 0.9789921899499369, 'brier': 0.5776351740840047, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[base] Season 2013: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5539473684210526, 'log_loss': 0.9332126369410085, 'brier': 0.5540683809872751, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.5526315789473685, 'log_loss': 0.9547365367146811, 'brier': 0.5581608136977739, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[base] Season 2014: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5584795321637427, 'log_loss': 0.9307926530679872, 'brier': 0.5519840926115098, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.5394736842105263, 'log_loss': 0.9550131554865927, 'brier': 0.566703461184422, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[base] Season 2015: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5592105263157895, 'log_loss': 0.9301650065581946, 'brier': 0.5515367865625297, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9416078724708906, 'brier': 0.5571429004830827, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[base] Season 2016: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.560287081339713, 'log_loss': 0.928423065200916, 'brier': 0.5501825512580892, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.5447368421052632, 'log_loss': 0.9748070688006484, 'brier': 0.5772136527618866, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[base] Season 2017: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5583333333333333, 'log_loss': 0.9308633479349231, 'brier': 0.551566898158561, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.49473684210526314, 'log_loss': 1.043043652722232, 'brier': 0.6230177006279513, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[base] Season 2018: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5538461538461539, 'log_loss': 0.9379067812945628, 'brier': 0.5562161638853764, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0050068167451771, 'brier': 0.6008429905731066, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[base] Season 2019: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5515037593984963, 'log_loss': 0.9415574209760027, 'brier': 0.5586831042638591, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 1.000671560752277, 'brier': 0.5941650895420585, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[base] Season 2020: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5492982456140351, 'log_loss': 0.9447901612575184, 'brier': 0.5605850035167729, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 1.004030735977631, 'brier': 0.599547604047388, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[base] Season 2021: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5491776315789474, 'log_loss': 0.9476468202496819, 'brier': 0.5623093566137487, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.5421052631578948, 'log_loss': 0.9829618308683384, 'brier': 0.5851148182115604, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[base] Season 2022: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5498452012383901, 'log_loss': 0.9492284153583881, 'brier': 0.5632888298669392, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5473684210526316, 'log_loss': 0.9489298920407643, 'brier': 0.5648907351774347, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[base] Season 2023: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5489766081871345, 'log_loss': 0.9487394010473583, 'brier': 0.5629520762618124, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5736842105263158, 'log_loss': 0.9558871484638822, 'brier': 0.5646711693258986, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[base] Season 2024: guardado match-log (380 filas)\n",
            "Logistic Regression (sin SMOTE) (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5505540166204986, 'log_loss': 0.9486674567479428, 'brier': 0.5628076108091079, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.43902439024390244, 'log_loss': 1.0075545802337558, 'brier': 0.6086376739260356, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "[base] Season 2025: guardado match-log (41 filas)\n",
            "Guardados:\n",
            "- outputs/matchlog_season_summary_base.csv\n",
            "- outputs/matchlog_season_summary_base.json\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5894736842105263, 'log_loss': 0.8832490658508221, 'brier': 0.5275427649252558, 'n_train': 380}\n",
            "\n",
            "=== Test (Seasons 2007..2007) ===\n",
            "{'accuracy': 0.39473684210526316, 'log_loss': 1.346089386911231, 'brier': 0.7669058200418584, 'n_test': 380, 'season_min': 2007, 'season_max': 2007}\n",
            "[smote] Season 2007: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5236842105263158, 'log_loss': 0.9678056846957641, 'brier': 0.583388627171342, 'n_train': 760}\n",
            "\n",
            "=== Test (Seasons 2008..2008) ===\n",
            "{'accuracy': 0.4105263157894737, 'log_loss': 1.152795781932829, 'brier': 0.6946941510676069, 'n_test': 380, 'season_min': 2008, 'season_max': 2008}\n",
            "[smote] Season 2008: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.9774496807318865, 'brier': 0.5863852093317935, 'n_train': 1140}\n",
            "\n",
            "=== Test (Seasons 2009..2009) ===\n",
            "{'accuracy': 0.49736842105263157, 'log_loss': 1.0093613866181081, 'brier': 0.5996975343000819, 'n_test': 380, 'season_min': 2009, 'season_max': 2009}\n",
            "[smote] Season 2009: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4934210526315789, 'log_loss': 0.973002112063022, 'brier': 0.5842609255416295, 'n_train': 1520}\n",
            "\n",
            "=== Test (Seasons 2010..2010) ===\n",
            "{'accuracy': 0.4868421052631579, 'log_loss': 1.0092896813950816, 'brier': 0.597136540982765, 'n_test': 380, 'season_min': 2010, 'season_max': 2010}\n",
            "[smote] Season 2010: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5205263157894737, 'log_loss': 0.9743083404187528, 'brier': 0.5823728938296975, 'n_train': 1900}\n",
            "\n",
            "=== Test (Seasons 2011..2011) ===\n",
            "{'accuracy': 0.5105263157894737, 'log_loss': 0.9771168177934654, 'brier': 0.5769733083507897, 'n_test': 380, 'season_min': 2011, 'season_max': 2011}\n",
            "[smote] Season 2011: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5096491228070176, 'log_loss': 0.97590862387272, 'brier': 0.5845873701303743, 'n_train': 2280}\n",
            "\n",
            "=== Test (Seasons 2012..2012) ===\n",
            "{'accuracy': 0.4842105263157895, 'log_loss': 1.040399031759994, 'brier': 0.6175421005994366, 'n_test': 380, 'season_min': 2012, 'season_max': 2012}\n",
            "[smote] Season 2012: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5041353383458647, 'log_loss': 0.9802743722034526, 'brier': 0.5861631073521839, 'n_train': 2660}\n",
            "\n",
            "=== Test (Seasons 2013..2013) ===\n",
            "{'accuracy': 0.5210526315789473, 'log_loss': 0.9985909620757426, 'brier': 0.5879411633551468, 'n_test': 380, 'season_min': 2013, 'season_max': 2013}\n",
            "[smote] Season 2013: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4986842105263158, 'log_loss': 0.9822385614162494, 'brier': 0.5862491705072447, 'n_train': 3040}\n",
            "\n",
            "=== Test (Seasons 2014..2014) ===\n",
            "{'accuracy': 0.4921052631578947, 'log_loss': 0.9773017801375603, 'brier': 0.5799711471576002, 'n_test': 380, 'season_min': 2014, 'season_max': 2014}\n",
            "[smote] Season 2014: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5017543859649123, 'log_loss': 0.9769318565787618, 'brier': 0.5819318209939401, 'n_train': 3420}\n",
            "\n",
            "=== Test (Seasons 2015..2015) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0201056970455966, 'brier': 0.6096891852890882, 'n_test': 380, 'season_min': 2015, 'season_max': 2015}\n",
            "[smote] Season 2015: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5073684210526316, 'log_loss': 0.9751363501458438, 'brier': 0.5806150912443517, 'n_train': 3800}\n",
            "\n",
            "=== Test (Seasons 2016..2016) ===\n",
            "{'accuracy': 0.5026315789473684, 'log_loss': 0.9896952314442939, 'brier': 0.5900975669319269, 'n_test': 380, 'season_min': 2016, 'season_max': 2016}\n",
            "[smote] Season 2016: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.509090909090909, 'log_loss': 0.9738670025605136, 'brier': 0.5795921462562429, 'n_train': 4180}\n",
            "\n",
            "=== Test (Seasons 2017..2017) ===\n",
            "{'accuracy': 0.46842105263157896, 'log_loss': 1.0361571241346643, 'brier': 0.6191830548101391, 'n_test': 380, 'season_min': 2017, 'season_max': 2017}\n",
            "[smote] Season 2017: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5002192982456141, 'log_loss': 0.9761191080844202, 'brier': 0.580814327111802, 'n_train': 4560}\n",
            "\n",
            "=== Test (Seasons 2018..2018) ===\n",
            "{'accuracy': 0.4236842105263158, 'log_loss': 1.0995343481482975, 'brier': 0.6615797894442955, 'n_test': 380, 'season_min': 2018, 'season_max': 2018}\n",
            "[smote] Season 2018: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4937246963562753, 'log_loss': 0.9814033465905685, 'brier': 0.58439312240206, 'n_train': 4940}\n",
            "\n",
            "=== Test (Seasons 2019..2019) ===\n",
            "{'accuracy': 0.3894736842105263, 'log_loss': 1.0926288947626823, 'brier': 0.6578723586331475, 'n_test': 380, 'season_min': 2019, 'season_max': 2019}\n",
            "[smote] Season 2019: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.4945488721804511, 'log_loss': 0.9836560793909735, 'brier': 0.586074995190767, 'n_train': 5320}\n",
            "\n",
            "=== Test (Seasons 2020..2020) ===\n",
            "{'accuracy': 0.48157894736842105, 'log_loss': 1.037038894314774, 'brier': 0.6204726960453463, 'n_test': 380, 'season_min': 2020, 'season_max': 2020}\n",
            "[smote] Season 2020: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.49719298245614035, 'log_loss': 0.9843959634335476, 'brier': 0.5862963313024286, 'n_train': 5700}\n",
            "\n",
            "=== Test (Seasons 2021..2021) ===\n",
            "{'accuracy': 0.45789473684210524, 'log_loss': 1.0478320292176597, 'brier': 0.6311686912927778, 'n_test': 380, 'season_min': 2021, 'season_max': 2021}\n",
            "[smote] Season 2021: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5008223684210527, 'log_loss': 0.9852508119370434, 'brier': 0.5870315398506273, 'n_train': 6080}\n",
            "\n",
            "=== Test (Seasons 2022..2022) ===\n",
            "{'accuracy': 0.47368421052631576, 'log_loss': 1.0385185408567015, 'brier': 0.6180350209925748, 'n_test': 380, 'season_min': 2022, 'season_max': 2022}\n",
            "[smote] Season 2022: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5006191950464396, 'log_loss': 0.9871463455394053, 'brier': 0.5881696407419167, 'n_train': 6460}\n",
            "\n",
            "=== Test (Seasons 2023..2023) ===\n",
            "{'accuracy': 0.5289473684210526, 'log_loss': 0.9727078891544718, 'brier': 0.5855019659681104, 'n_test': 380, 'season_min': 2023, 'season_max': 2023}\n",
            "[smote] Season 2023: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5043859649122807, 'log_loss': 0.9848871796512613, 'brier': 0.5864816514331854, 'n_train': 6840}\n",
            "\n",
            "=== Test (Seasons 2024..2024) ===\n",
            "{'accuracy': 0.5184210526315789, 'log_loss': 0.9921047463371278, 'brier': 0.5899477319521216, 'n_test': 380, 'season_min': 2024, 'season_max': 2024}\n",
            "[smote] Season 2024: guardado match-log (380 filas)\n",
            "Logistic Regression con SMOTE (con cuotas)\n",
            "\n",
            "=== Train ===\n",
            "{'accuracy': 0.5055401662049861, 'log_loss': 0.9840539889616619, 'brier': 0.5857954241176414, 'n_train': 7220}\n",
            "\n",
            "=== Test (Seasons 2025..2025) ===\n",
            "{'accuracy': 0.3902439024390244, 'log_loss': 1.0702587835009612, 'brier': 0.6495968867502313, 'n_test': 41, 'season_min': 2025, 'season_max': 2025}\n",
            "[smote] Season 2025: guardado match-log (41 filas)\n",
            "Guardados:\n",
            "- outputs/matchlog_season_summary_smote.csv\n",
            "- outputs/matchlog_season_summary_smote.json\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# MATCH-LOG por temporada (predicción vs valor) + export\n",
        "# =========================\n",
        "\n",
        "# --- Mapas y utilidades ---\n",
        "CLASS2TXT = {0:\"A\", 1:\"D\", 2:\"H\"}   # 0=Away,1=Draw,2=Home\n",
        "TXT2CLASS = {\"A\":0, \"D\":1, \"H\":2}\n",
        "\n",
        "def _edge_bins(edge: pd.Series,\n",
        "               bins=(-np.inf, 0.0, 0.02, 0.05, np.inf),\n",
        "               labels=(\"<0%\", \"0–2%\", \"2–5%\", \"≥5%\")):\n",
        "    \"\"\"Tramos discretos para facilitar filtros por 'valor esperado' en la app.\"\"\"\n",
        "    return pd.cut(edge, bins=bins, labels=labels, include_lowest=True, right=False)\n",
        "\n",
        "def _ensure_probs_adh(y_proba: np.ndarray, classes_model: np.ndarray) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Devuelve DataFrame de probabilidades con columnas A/D/H,\n",
        "    completando columnas ausentes con NaN si el modelo no las tuvo en train.\n",
        "    \"\"\"\n",
        "    name_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "    cols = [name_map.get(int(c), str(c)) for c in classes_model]\n",
        "    proba_df = pd.DataFrame(y_proba, columns=cols)\n",
        "    for c in [\"A\",\"D\",\"H\"]:\n",
        "        if c not in proba_df.columns:\n",
        "            proba_df[c] = np.nan\n",
        "    return proba_df[[\"A\",\"D\",\"H\"]]\n",
        "\n",
        "def _make_matchlog_from_eval(\n",
        "    df: pd.DataFrame,\n",
        "    y_test: pd.Series,\n",
        "    y_pred: np.ndarray,\n",
        "    y_proba: np.ndarray,\n",
        "    idx_test: pd.Index,\n",
        "    *,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Construye el match-log (una fila por partido del TEST de esa temporada).\n",
        "    Incluye columnas para comparar estrategia de 'Predicción' vs 'Valor'.\n",
        "    \"\"\"\n",
        "    # 1) Meta-información del propio df (alineación por índice)\n",
        "    need = [\"Date\",\"Season\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    missing = [c for c in need if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"df necesita columnas {missing} para construir el match-log.\")\n",
        "    meta = df.loc[idx_test, need].copy()\n",
        "\n",
        "    # 2) Probabilidades A/D/H y odds en mismo orden (A,D,H)\n",
        "    proba_df = _ensure_probs_adh(y_proba, classes_model=np.array([0,1,2][:y_proba.shape[1]]))\n",
        "    proba_df.index = idx_test\n",
        "    odds_df = meta[[\"B365A\",\"B365D\",\"B365H\"]].rename(columns={\"B365A\":\"A\",\"B365D\":\"D\",\"B365H\":\"H\"})\n",
        "\n",
        "    # 3) Predicción del modelo + EV de la predicción\n",
        "    pred_txt = pd.Series(y_pred, index=idx_test).map(CLASS2TXT)\n",
        "    idx_of = {\"A\":0,\"D\":1,\"H\":2}\n",
        "    pred_idx = pred_txt.map(idx_of).to_numpy()\n",
        "\n",
        "    P = proba_df.to_numpy()\n",
        "    O = odds_df[[\"A\",\"D\",\"H\"]].to_numpy()\n",
        "\n",
        "    out = meta.copy()\n",
        "    out[\"true_result\"]      = pd.Series(y_test, index=idx_test).values\n",
        "    out[\"predicted_result\"] = pd.Series(y_pred, index=idx_test).values\n",
        "    out[\"Pred\"]             = pred_txt.values\n",
        "\n",
        "    out[\"predicted_prob\"] = P[np.arange(len(out)), pred_idx]\n",
        "    out[\"predicted_odds\"] = O[np.arange(len(out)), pred_idx]\n",
        "    out[\"edge\"] = out[\"predicted_prob\"] * out[\"predicted_odds\"] - 1.0      # EV de la PREDICCIÓN\n",
        "\n",
        "    # 4) Estrategia de VALOR: máxima EV entre H/D/A (sin mirar la predicción)\n",
        "    ev_df = proba_df * odds_df - 1.0                                      # EV por clase\n",
        "    best_idx = ev_df[[\"A\",\"D\",\"H\"]].to_numpy().argmax(axis=1)\n",
        "    labels  = np.array([\"A\",\"D\",\"H\"])\n",
        "    out[\"value_pick\"] = labels[best_idx]\n",
        "    out[\"value_ev\"]   = ev_df.to_numpy()[np.arange(len(out)), best_idx]\n",
        "    out[\"value_prob\"] = P[np.arange(len(out)), best_idx]\n",
        "    out[\"value_odds\"] = O[np.arange(len(out)), best_idx]\n",
        "\n",
        "    # 5) Requiere cuotas completas y filtros de edge\n",
        "    mask_ok_odds = out[[\"B365H\",\"B365D\",\"B365A\"]].notna().all(axis=1)\n",
        "    out = out.loc[mask_ok_odds].copy()\n",
        "    if min_edge_pred > 0:\n",
        "        out = out.loc[out[\"edge\"] >= min_edge_pred].copy()\n",
        "    if out.empty:\n",
        "        return out\n",
        "\n",
        "    if min_edge_value is None:\n",
        "        min_edge_value = min_edge_pred\n",
        "    # Nota: para comparar estrategias, NO filtramos por value_ev por defecto (se puede activar):\n",
        "    if min_edge_value and (min_edge_value > 0):\n",
        "        out[\"use_value\"] = out[\"value_ev\"] >= min_edge_value\n",
        "    else:\n",
        "        out[\"use_value\"] = True\n",
        "\n",
        "    # 6) Beneficios de cada estrategia (stake fijo)\n",
        "    out[\"bet_return\"] = np.where(\n",
        "        out[\"predicted_result\"] == out[\"true_result\"], out[\"predicted_odds\"] * stake, 0.0\n",
        "    )\n",
        "    out[\"net_profit\"] = out[\"bet_return\"] - stake\n",
        "\n",
        "    value_idx = out[\"value_pick\"].map(idx_of).to_numpy()\n",
        "    value_hit = (value_idx == out[\"true_result\"])\n",
        "    value_ret = np.where(value_hit, out[\"value_odds\"] * stake, 0.0)\n",
        "    out[\"value_bet_return\"] = np.where(out[\"use_value\"], value_ret, 0.0)\n",
        "    out[\"value_net_profit\"] = np.where(out[\"use_value\"], out[\"value_bet_return\"] - stake, 0.0)\n",
        "\n",
        "    # 7) Columnas de apoyo para filtros en la app\n",
        "    out[\"Correct\"]       = np.where(out[\"predicted_result\"] == out[\"true_result\"], \"✓\", \"✗\")\n",
        "    out[\"value_correct\"] = np.where(value_hit, \"✓\", \"✗\")\n",
        "    out[\"edge_bin\"]      = _edge_bins(out[\"edge\"])\n",
        "    out[\"value_bin\"]     = _edge_bins(out[\"value_ev\"])\n",
        "\n",
        "    # 8) Orden temporal + formato fecha amigable\n",
        "    out[\"Date\"] = pd.to_datetime(out[\"Date\"], errors=\"coerce\")\n",
        "    out = out.sort_values([\"Date\", out.index.name or \"Season\"]).reset_index(drop=True)\n",
        "    out[\"Date\"] = out[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_matchlog_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    *,\n",
        "    model: str = \"base\",          # \"base\" | \"smote\"\n",
        "    with_odds: bool = True,\n",
        "    random_state: int = 42,\n",
        "    stake: float = 1.0,\n",
        "    min_edge_pred: float = 0.00,\n",
        "    min_edge_value: float | None = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Para cada temporada S (train ≤ S-1, test = S) entrena/evalúa el modelo escogido,\n",
        "    construye el match-log (partido a partido) con columnas de Predicción y Valor,\n",
        "    y exporta CSV/JSON por temporada + un resumen por temporada con ROI de ambas estrategias.\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    per_season_dir = out_dir / f\"matchlogs_{model}\"\n",
        "    per_season_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    season_summary = []\n",
        "\n",
        "    for test_season in seasons_all:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            if model == \"base\":\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval_no_smote(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "            else:\n",
        "                mdl, _, (mtr_tr, mtr_te), y_test, y_pred, y_proba, idx_test = run_logreg_eval(\n",
        "                    df, train_until_season=train_until, test_until_season=test_season,\n",
        "                    with_odds=with_odds, random_state=random_state\n",
        "                )\n",
        "\n",
        "            # Si no hay test válido, sigue\n",
        "            if (mtr_te is None) or (y_test is None) or (y_pred is None) or (y_proba is None) or (len(y_test) == 0):\n",
        "                continue\n",
        "\n",
        "            # Construye match-log para esa temporada\n",
        "            ml = _make_matchlog_from_eval(\n",
        "                df, y_test, y_pred, y_proba, idx_test,\n",
        "                stake=stake, min_edge_pred=min_edge_pred, min_edge_value=min_edge_value\n",
        "            )\n",
        "            if ml.empty:\n",
        "                continue\n",
        "\n",
        "            # ROI/beneficio de cada estrategia en esa temporada\n",
        "            n_pred = len(ml)                        # pred: una apuesta por fila tras filtro\n",
        "            roi_pred = float(ml[\"net_profit\"].sum() / (stake * n_pred))\n",
        "            n_val = int(ml[\"use_value\"].sum())      # valor: si filtras por value_ev, puede ser menor\n",
        "            roi_val = float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() / (stake * n_val)) if n_val > 0 else np.nan\n",
        "\n",
        "            # Guardados por temporada\n",
        "            csv_path  = per_season_dir / f\"matchlog_{test_season}.csv\"\n",
        "            json_path = per_season_dir / f\"matchlog_{test_season}.json\"\n",
        "            ml.to_csv(csv_path, index=False)\n",
        "            ml.to_json(json_path, orient=\"records\", force_ascii=False, indent=2)\n",
        "\n",
        "            season_summary.append({\n",
        "                \"model\": model,\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"n_pred_bets\": int(n_pred),\n",
        "                \"roi_pred\": roi_pred,\n",
        "                \"profit_pred\": float(ml[\"net_profit\"].sum()),\n",
        "                \"n_value_bets\": int(n_val),\n",
        "                \"roi_value\": roi_val,\n",
        "                \"profit_value\": float(ml.loc[ml[\"use_value\"], \"value_net_profit\"].sum() if n_val > 0 else 0.0),\n",
        "                \"min_edge_pred\": float(min_edge_pred),\n",
        "                \"min_edge_value\": float(min_edge_value if (min_edge_value is not None) else min_edge_pred),\n",
        "                \"n_test\": int(mtr_te[\"n_test\"]),\n",
        "            })\n",
        "            print(f\"[{model}] Season {test_season}: guardado match-log ({len(ml)} filas)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[MATCHLOG {model.upper()} SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    # Resumen por temporada (tabla plana + index JSON para la app)\n",
        "    if season_summary:\n",
        "        df_sum = pd.DataFrame(season_summary).sort_values(\"test_season\")\n",
        "        df_sum.to_csv(out_dir / f\"matchlog_season_summary_{model}.csv\", index=False)\n",
        "        (out_dir / f\"matchlog_season_summary_{model}.json\").write_text(\n",
        "            json.dumps(season_summary, ensure_ascii=False, indent=2),\n",
        "            encoding=\"utf-8\"\n",
        "        )\n",
        "        print(f\"Guardados:\\n- {out_dir/f'matchlog_season_summary_{model}.csv'}\\n- {out_dir/f'matchlog_season_summary_{model}.json'}\")\n",
        "    else:\n",
        "        print(\"Sin temporadas válidas para exportar matchlogs.\")\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO\n",
        "# =========================\n",
        "# Asumimos:\n",
        "# - df = df_final (con HomeTeam_norm y AwayTeam_norm)\n",
        "# - OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# BASE (sin SMOTE). Puedes ajustar min_edge_pred para exigir EV mínimo en la estrategia de predicción\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"base\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,   # prueba 0.02 / 0.05 si quieres “apostar solo cuando hay valor en la predicción”\n",
        "    min_edge_value=None   # None = no filtrar la estrategia de valor; pon 0.02/0.05 si quieres filtrarla también\n",
        ")\n",
        "\n",
        "# SMOTE (si ya tienes definidas run_logreg_eval y funciona análogo)\n",
        "build_matchlog_grid(\n",
        "    df=df,\n",
        "    out_dir=OUT,\n",
        "    model=\"smote\",\n",
        "    with_odds=True,\n",
        "    random_state=42,\n",
        "    stake=1.0,\n",
        "    min_edge_pred=0.00,\n",
        "    min_edge_value=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JposElvmrlP"
      },
      "source": [
        "## **COMPARACIÓN CON EL MODELO DE BET365**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4yDpcqQz-6"
      },
      "source": [
        "El modelo basado en las cuotas de Bet365 consiste en predecir siempre el resultado más probable según la probabilidad implícita."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjgMWmkQ7Dro",
        "outputId": "b079c684-f022-41ab-bc15-1ea7433ff842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2007..2007 | n=380 | ROI: -3.47% | Profit: -13.19\n",
            "[Bet365] Season 2007: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2008..2008 | n=380 | ROI: 7.91% | Profit: 30.05\n",
            "[Bet365] Season 2008: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2009..2009 | n=380 | ROI: 4.28% | Profit: 16.28\n",
            "[Bet365] Season 2009: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2010..2010 | n=380 | ROI: 9.04% | Profit: 34.36\n",
            "[Bet365] Season 2010: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2011..2011 | n=380 | ROI: -7.91% | Profit: -30.06\n",
            "[Bet365] Season 2011: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2012..2012 | n=380 | ROI: -3.74% | Profit: -14.20\n",
            "[Bet365] Season 2012: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2013..2013 | n=380 | ROI: -9.91% | Profit: -37.66\n",
            "[Bet365] Season 2013: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2014..2014 | n=380 | ROI: -6.01% | Profit: -22.84\n",
            "[Bet365] Season 2014: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2015..2015 | n=380 | ROI: -6.26% | Profit: -23.78\n",
            "[Bet365] Season 2015: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2016..2016 | n=380 | ROI: 0.06% | Profit: 0.22\n",
            "[Bet365] Season 2016: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2017..2017 | n=380 | ROI: -2.87% | Profit: -10.90\n",
            "[Bet365] Season 2017: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2018..2018 | n=380 | ROI: -12.71% | Profit: -48.30\n",
            "[Bet365] Season 2018: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2019..2019 | n=380 | ROI: -6.13% | Profit: -23.29\n",
            "[Bet365] Season 2019: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2020..2020 | n=380 | ROI: -1.94% | Profit: -7.36\n",
            "[Bet365] Season 2020: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2021..2021 | n=380 | ROI: -4.51% | Profit: -17.15\n",
            "[Bet365] Season 2021: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2022..2022 | n=380 | ROI: 1.82% | Profit: 6.93\n",
            "[Bet365] Season 2022: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2023..2023 | n=380 | ROI: 2.18% | Profit: 8.28\n",
            "[Bet365] Season 2023: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2024..2024 | n=380 | ROI: -1.80% | Profit: -6.84\n",
            "[Bet365] Season 2024: OK (380 partidos)\n",
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2025..2025 | n=41 | ROI: -3.39% | Profit: -1.39\n",
            "[Bet365] Season 2025: OK (41 partidos)\n",
            "Guardados:\n",
            "- outputs/bet365_grid.json\n",
            "- outputs/bet365_metrics_by_season.csv\n",
            "- outputs/bet365_matchlogs/matchlog_<SEASON>.csv/json\n",
            "Guardados comparativos temporada:\n",
            "- outputs/comparison_season_base_vs_bet365.csv\n",
            "- outputs/comparison_season_base_vs_bet365.json\n",
            "Guardados comparativos por partido (2025):\n",
            "- outputs/comparison_matchlog_2025_base_vs_bet365.csv\n",
            "- outputs/comparison_matchlog_2025_base_vs_bet365.json\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Bet365 Baseline + Export + Comparaciones\n",
        "# =========================\n",
        "\n",
        "# --- Split temporal (idéntico a tu flujo) ---\n",
        "def _prep_test_split(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int,\n",
        "    with_odds: bool,\n",
        "    test_until_season: int | None = None\n",
        "):\n",
        "    drop_common = ['FTR','target','Date','has_xg_data',\n",
        "                   'a_squad_size_prev_season','away_form_gd_6','home_form_gd_6']\n",
        "    drop_mode = (['overround','pimp2','B365D'] if with_odds else\n",
        "                 ['fase_temporada_inicio','fase_temporada_mitad',\n",
        "                  'B365H','B365D','B365A','overround','pimp1','pimpx','pimp2'])\n",
        "    drop_cols = list(dict.fromkeys(drop_common + drop_mode))\n",
        "\n",
        "    y_all = df['target']\n",
        "    X_all = df.drop(columns=[c for c in drop_cols if c in df.columns], errors='ignore')\n",
        "\n",
        "    valid = y_all.notna()\n",
        "    if with_odds:\n",
        "        for c in ['B365H','B365A']:\n",
        "            if c in X_all.columns:\n",
        "                valid &= X_all[c].notna()\n",
        "    valid &= X_all.notna().all(axis=1)\n",
        "\n",
        "    X_all = X_all.loc[valid].copy()\n",
        "    y_all = y_all.loc[valid].astype(int)\n",
        "\n",
        "    if 'Season' not in X_all.columns:\n",
        "        raise ValueError(\"Falta 'Season' para el split temporal.\")\n",
        "\n",
        "    test_mask = X_all['Season'] > train_until_season\n",
        "    if test_until_season is not None:\n",
        "        test_mask &= (X_all['Season'] <= test_until_season)\n",
        "\n",
        "    idx_test = X_all.index[test_mask]\n",
        "    X_test = X_all.loc[idx_test].drop(columns=['Season'])\n",
        "    y_test = y_all.loc[idx_test]\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "\n",
        "# --- Evaluación Bet365 en un rango temporal ---\n",
        "def evaluate_bet365_baseline(\n",
        "    df: pd.DataFrame,\n",
        "    train_until_season: int = 2023,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    round_decimals: int = 4,\n",
        "    stake: float = 1.0,\n",
        "):\n",
        "    \"\"\"\n",
        "    Baseline Bet365:\n",
        "      - TEST: (train_until, test_until]\n",
        "      - Prob implícitas normalizadas\n",
        "      - Métricas: accuracy, log_loss, brier\n",
        "      - ROI apostando al favorito Bet365\n",
        "      - Devuelve (tabla partido a partido, métricas)\n",
        "    \"\"\"\n",
        "    # 1) TEST\n",
        "    X_test, y_test, idx = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "        print(f\"⚠️ No hay TEST disponible tras filtrar (Seasons {rng}).\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 2) Cuotas desde df\n",
        "    need_cols = ['B365H','B365D','B365A']\n",
        "    missing = [c for c in need_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"df debe contener columnas de cuotas {missing}\")\n",
        "\n",
        "    odds_df = df.loc[idx, need_cols].copy()\n",
        "    mask_ok = odds_df.notna().all(axis=1)\n",
        "    for c in need_cols:\n",
        "        mask_ok &= (pd.to_numeric(odds_df[c], errors='coerce') > 0)\n",
        "    odds_df = odds_df.loc[mask_ok].astype(float)\n",
        "    y_test  = y_test.loc[mask_ok]\n",
        "    idx     = odds_df.index\n",
        "\n",
        "    if odds_df.empty:\n",
        "        print(\"⚠️ No hay partidos con cuotas B365 completas en el TEST.\")\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 3) Prob implícitas normalizadas\n",
        "    inv = 1.0 / odds_df[need_cols]\n",
        "    overround = inv.sum(axis=1).replace(0, np.nan)\n",
        "    prob_norm = inv.div(overround, axis=0)\n",
        "\n",
        "    # 4) Proba en orden de clases (0=A,1=D,2=H) y pick\n",
        "    bet365_proba = np.column_stack([\n",
        "        prob_norm['B365A'].to_numpy(),\n",
        "        prob_norm['B365D'].to_numpy(),\n",
        "        prob_norm['B365H'].to_numpy()\n",
        "    ])\n",
        "    bet365_pred = bet365_proba.argmax(axis=1)\n",
        "\n",
        "    # 5) Métricas\n",
        "    classes = [0,1,2]\n",
        "    acc = float(accuracy_score(y_test, bet365_pred))\n",
        "    ll  = float(log_loss(y_test, bet365_proba, labels=classes))\n",
        "    y_bin = label_binarize(y_test, classes=classes)\n",
        "    brier = float(np.mean(np.sum((bet365_proba - y_bin)**2, axis=1)))\n",
        "\n",
        "    # 6) Tabla partido a partido\n",
        "    out = pd.DataFrame(index=idx)\n",
        "    extra = {}\n",
        "    for c in ['Date','Season','HomeTeam_norm','AwayTeam_norm']:\n",
        "        extra[c] = df.loc[idx, c] if c in df.columns else pd.Series(index=idx, dtype='object')\n",
        "\n",
        "    out['Date'] = pd.to_datetime(extra['Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "    if 'Season' in df.columns:\n",
        "        out['Season'] = extra['Season'].astype('Int64')\n",
        "    out['HomeTeam_norm'] = extra['HomeTeam_norm'].astype('string')\n",
        "    out['AwayTeam_norm'] = extra['AwayTeam_norm'].astype('string')\n",
        "\n",
        "    out['B365H'] = odds_df['B365H'].round(round_decimals)\n",
        "    out['B365D'] = odds_df['B365D'].round(round_decimals)\n",
        "    out['B365A'] = odds_df['B365A'].round(round_decimals)\n",
        "    out['p_H']   = prob_norm['B365H'].round(round_decimals)\n",
        "    out['p_D']   = prob_norm['B365D'].round(round_decimals)\n",
        "    out['p_A']   = prob_norm['B365A'].round(round_decimals)\n",
        "    out['true_result'] = y_test.values\n",
        "    out['bet365_pred'] = bet365_pred\n",
        "\n",
        "    # 7) ROI del favorito Bet365\n",
        "    pick_idx = bet365_pred\n",
        "    odds_mat = np.column_stack([odds_df['B365A'], odds_df['B365D'], odds_df['B365H']])\n",
        "    picked_odds = odds_mat[np.arange(len(odds_mat)), pick_idx]\n",
        "    out['picked_odds'] = picked_odds\n",
        "    out['bet_return']  = np.where(out['bet365_pred'] == out['true_result'], out['picked_odds'] * stake, 0.0)\n",
        "    out['net_profit']  = out['bet_return'] - stake\n",
        "    out['Cum_net_profit'] = out['net_profit'].cumsum()\n",
        "\n",
        "    # Edge informativo del pick\n",
        "    pA = prob_norm['B365A'].to_numpy()\n",
        "    pD = prob_norm['B365D'].to_numpy()\n",
        "    pH = prob_norm['B365H'].to_numpy()\n",
        "    p_mat = np.column_stack([pA,pD,pH])\n",
        "    out['edge_b365_pick'] = (p_mat[np.arange(len(p_mat)), pick_idx] * picked_odds) - 1.0\n",
        "\n",
        "    n_eval = int(len(out))\n",
        "    total_profit = float(out['net_profit'].sum())\n",
        "    investment_total = float(stake * n_eval)\n",
        "    roi = float(total_profit / investment_total) if investment_total > 0 else np.nan\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": acc,\n",
        "        \"log_loss\": ll,\n",
        "        \"brier\": brier,\n",
        "        \"n_test_with_odds\": n_eval,\n",
        "        \"roi\": roi,\n",
        "        \"profit_total\": total_profit,\n",
        "        \"investment_total\": investment_total,   # << añadido\n",
        "        \"stake\": float(stake)\n",
        "    }\n",
        "\n",
        "    rng = f\"{train_until_season+1}..{test_until_season}\" if test_until_season is not None else f\">{train_until_season}\"\n",
        "    print(\"Baseline Bet365 — Prob. implícitas normalizadas\")\n",
        "    print(f\"Rango TEST: Seasons {rng} | n={n_eval} | ROI: {roi*100:.2f}% | Profit: {total_profit:.2f}\")\n",
        "\n",
        "    return out.reset_index(drop=True), metrics\n",
        "\n",
        "\n",
        "# --- Grid por temporada + export ---\n",
        "def build_bet365_grid(\n",
        "    df: pd.DataFrame,\n",
        "    out_dir: Path,\n",
        "    seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 4,\n",
        "    save_matchlogs: bool = True\n",
        "):\n",
        "    \"\"\"\n",
        "    Para cada temporada S (train ≤ S-1, test = S):\n",
        "      - matchlog Bet365 (opcional CSV/JSON)\n",
        "      - resumen por temporada (JSON+CSV) con ROI y investment_total\n",
        "    \"\"\"\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    per_season_dir = out_dir / \"bet365_matchlogs\"\n",
        "    if save_matchlogs:\n",
        "        per_season_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    rows_json, rows_flat = [], []\n",
        "\n",
        "    for test_season in seasons:\n",
        "        train_until = test_season - 1\n",
        "        if train_until < seasons_all[0]:  # sin historial\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tbl, met = evaluate_bet365_baseline(\n",
        "                df,\n",
        "                train_until_season=train_until,\n",
        "                test_until_season=test_season,\n",
        "                with_odds=with_odds,\n",
        "                round_decimals=round_decimals,\n",
        "                stake=stake\n",
        "            )\n",
        "            if tbl.empty:\n",
        "                continue\n",
        "\n",
        "            if save_matchlogs:\n",
        "                (per_season_dir / f\"matchlog_{test_season}.csv\").write_text(\n",
        "                    tbl.to_csv(index=False), encoding=\"utf-8\"\n",
        "                )\n",
        "                (per_season_dir / f\"matchlog_{test_season}.json\").write_text(\n",
        "                    tbl.to_json(orient=\"records\", force_ascii=False, indent=2),\n",
        "                    encoding=\"utf-8\"\n",
        "                )\n",
        "\n",
        "            rows_json.append({\n",
        "                \"train_until\": int(train_until),\n",
        "                \"test_season\": int(test_season),\n",
        "                \"metrics\": {\n",
        "                    \"accuracy\": float(met[\"accuracy\"]),\n",
        "                    \"log_loss\": float(met[\"log_loss\"]),\n",
        "                    \"brier\":    float(met[\"brier\"]),\n",
        "                    \"roi\":      float(met[\"roi\"]),\n",
        "                    \"profit_total\": float(met[\"profit_total\"]),\n",
        "                    \"investment_total\": float(met[\"investment_total\"]),  # << añadido\n",
        "                    \"n_test\":   int(met[\"n_test_with_odds\"]),\n",
        "                    \"stake\":    float(met[\"stake\"])\n",
        "                }\n",
        "            })\n",
        "            rows_flat.append({\n",
        "                \"test_season\": int(test_season),\n",
        "                \"train_until\": int(train_until),\n",
        "                \"acc\": float(met[\"accuracy\"]),\n",
        "                \"logloss\": float(met[\"log_loss\"]),\n",
        "                \"brier\": float(met[\"brier\"]),\n",
        "                \"roi\": float(met[\"roi\"]),\n",
        "                \"profit_total\": float(met[\"profit_total\"]),\n",
        "                \"investment_total\": float(met[\"investment_total\"]),      # << añadido\n",
        "                \"n_test\": int(met[\"n_test_with_odds\"]),\n",
        "            })\n",
        "\n",
        "            print(f\"[Bet365] Season {test_season}: OK ({len(tbl)} partidos)\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[BET365 SKIP] test={test_season} → {e}\")\n",
        "\n",
        "    (out_dir / \"bet365_grid.json\").write_text(json.dumps(rows_json, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "    pd.DataFrame(rows_flat).sort_values(\"test_season\").to_csv(out_dir / \"bet365_metrics_by_season.csv\", index=False)\n",
        "\n",
        "    print(\"Guardados:\")\n",
        "    print(f\"- {out_dir/'bet365_grid.json'}\")\n",
        "    print(f\"- {out_dir/'bet365_metrics_by_season.csv'}\")\n",
        "    if save_matchlogs:\n",
        "        print(f\"- {out_dir/'bet365_matchlogs'}/matchlog_<SEASON>.csv/json\")\n",
        "\n",
        "\n",
        "# --- Comparación modelo vs Bet365 por temporada ---\n",
        "def build_season_comparison_model_vs_bet365(\n",
        "    out_dir: Path,\n",
        "    model_tag: str = \"base\"  # coincide con el nombre usado en roi_by_season_<tag>.csv\n",
        "):\n",
        "    \"\"\"\n",
        "    Une outputs/roi_by_season_<model_tag>.csv (tu modelo) con\n",
        "    outputs/bet365_metrics_by_season.csv y calcula deltas.\n",
        "    \"\"\"\n",
        "    df_m = pd.read_csv(out_dir / f\"roi_by_season_{model_tag}.csv\")\n",
        "    df_b = pd.read_csv(out_dir / \"bet365_metrics_by_season.csv\")\n",
        "\n",
        "    # Normaliza nombres por si difieren\n",
        "    df_m = df_m.rename(columns={\"profit_total\":\"profit_model\", \"roi\":\"roi_model\", \"n_bets\":\"n_bets_model\"})\n",
        "    df_b = df_b.rename(columns={\"profit_total\":\"profit_bet365\", \"roi\":\"roi_bet365\", \"n_test\":\"n_bets_bet365\"})\n",
        "\n",
        "    if \"stake\" not in df_m.columns:\n",
        "        df_m[\"stake\"] = 1.0  # fallback si faltara\n",
        "    if \"stake\" not in df_b.columns:\n",
        "        df_b[\"stake\"] = 1.0\n",
        "\n",
        "    df_m[\"investment_total_model\"] = df_m[\"stake\"] * df_m[\"n_bets_model\"]\n",
        "    df_b[\"investment_total_bet365\"] = df_b[\"stake\"] * df_b[\"n_bets_bet365\"]\n",
        "\n",
        "    comp = pd.merge(df_m, df_b, on=[\"test_season\",\"train_until\"], how=\"inner\", suffixes=(\"_m\",\"_b\"))\n",
        "    comp[\"delta_roi\"]    = comp[\"roi_model\"]    - comp[\"roi_bet365\"]\n",
        "    comp[\"delta_profit\"] = comp[\"profit_model\"] - comp[\"profit_bet365\"]\n",
        "\n",
        "    comp_sorted = comp.sort_values(\"test_season\")\n",
        "    comp_sorted.to_csv(out_dir / f\"comparison_season_{model_tag}_vs_bet365.csv\", index=False)\n",
        "    (out_dir / f\"comparison_season_{model_tag}_vs_bet365.json\").write_text(\n",
        "        comp_sorted.to_json(orient=\"records\", force_ascii=False, indent=2),\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(f\"Guardados comparativos temporada:\\n- {out_dir/f'comparison_season_{model_tag}_vs_bet365.csv'}\\n- {out_dir/f'comparison_season_{model_tag}_vs_bet365.json'}\")\n",
        "\n",
        "\n",
        "# --- Comparación por partido (una temporada) modelo vs Bet365 ---\n",
        "def build_match_comparison_for_season(\n",
        "    out_dir: Path,\n",
        "    season: int,\n",
        "    model_tag: str = \"base\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Une matchlogs:\n",
        "      - outputs/matchlogs_<model_tag>/matchlog_<season>.csv\n",
        "      - outputs/bet365_matchlogs/matchlog_<season>.csv\n",
        "    por (Date, HomeTeam_norm, AwayTeam_norm) y calcula deltas por partido.\n",
        "    \"\"\"\n",
        "    ml_model = pd.read_csv(out_dir / f\"matchlogs_{model_tag}\" / f\"matchlog_{season}.csv\")\n",
        "    ml_b365  = pd.read_csv(out_dir / \"bet365_matchlogs\" / f\"matchlog_{season}.csv\")\n",
        "\n",
        "    key = [\"Date\",\"HomeTeam_norm\",\"AwayTeam_norm\"]\n",
        "    both = pd.merge(ml_model, ml_b365, on=key, how=\"inner\", suffixes=(\"_model\",\"_b365\"))\n",
        "\n",
        "    # Columnas mínimas de interés\n",
        "    keep = key + [\n",
        "        \"Season_model\",\"true_result_model\",\"predicted_result\",\"Pred\",\"edge\",\n",
        "        \"predicted_odds\",\"net_profit\",\"Cum_net_profit\",\n",
        "        \"bet365_pred\",\"picked_odds\",\"net_profit_b365\",\"Cum_net_profit_b365\"\n",
        "    ]\n",
        "    # Renombra si no existen exactamente\n",
        "    if \"net_profit_model\" in both.columns:\n",
        "        both[\"net_profit\"] = both[\"net_profit_model\"]\n",
        "    if \"Cum_net_profit_model\" in both.columns:\n",
        "        both[\"Cum_net_profit\"] = both[\"Cum_net_profit_model\"]\n",
        "    if \"net_profit_b365\" not in both.columns and \"net_profit_b365\" not in keep:\n",
        "        if \"net_profit_b365\" in both.columns:\n",
        "            pass\n",
        "\n",
        "    # Deltas por partido\n",
        "    both[\"delta_profit\"] = both[\"net_profit\"] - both[\"net_profit_b365\"]\n",
        "\n",
        "    # Orden temporal\n",
        "    both[\"Date\"] = pd.to_datetime(both[\"Date\"], errors=\"coerce\")\n",
        "    both = both.sort_values([\"Date\"]).reset_index(drop=True)\n",
        "    both[\"Date\"] = both[\"Date\"].dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    out_csv  = out_dir / f\"comparison_matchlog_{season}_{model_tag}_vs_bet365.csv\"\n",
        "    out_json = out_dir / f\"comparison_matchlog_{season}_{model_tag}_vs_bet365.json\"\n",
        "    both.to_csv(out_csv, index=False)\n",
        "    both.to_json(out_json, orient=\"records\", force_ascii=False, indent=2)\n",
        "    print(f\"Guardados comparativos por partido ({season}):\\n- {out_csv}\\n- {out_json}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# EJEMPLOS DE USO\n",
        "# =========================\n",
        "# OUT = ROOT / \"outputs\"\n",
        "# OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1) Generar baseline Bet365 por temporada (incluye investment_total y matchlogs)\n",
        "build_bet365_grid(df, out_dir=OUT, seasons=None, with_odds=True, stake=1.0, save_matchlogs=True)\n",
        "\n",
        "# 2) Comparar tu modelo vs Bet365 por temporada (usa tu CSV: roi_by_season_base.csv)\n",
        "build_season_comparison_model_vs_bet365(OUT, model_tag=\"base\")\n",
        "\n",
        "# 3) Comparar por partido en una temporada concreta (usa tus matchlogs y los de Bet365)\n",
        "build_match_comparison_for_season(OUT, season=2025, model_tag=\"base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E9eX18fI5ox",
        "outputId": "7856d766-2002-453d-d907-4f3c5ddba994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline Bet365 — Prob. implícitas normalizadas\n",
            "Rango TEST: Seasons 2025..2025 | n=41 | ROI: -3.39% | Profit: -1.39\n"
          ]
        }
      ],
      "source": [
        "tabla_bet365, met_bet365 = evaluate_bet365_baseline(df, train_until_season=2024, test_until_season=2025, with_odds=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Pd1LJtEb5Lh"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# Datos para GRAFICAR en la web: Modelo vs Bet365 (curvas acumuladas)\n",
        "# Compatible con _prep_test_split que devuelve 2 o 3 valores\n",
        "# ============================================\n",
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "CLASS2LABEL = {0: \"Away\", 1: \"Draw\", 2: \"Home\"}\n",
        "\n",
        "def _ensure_probs_adh(y_proba: np.ndarray, classes_model) -> pd.DataFrame:\n",
        "    name_map = {0:\"A\", 1:\"D\", 2:\"H\"}\n",
        "    cols = [name_map.get(int(c), str(c)) for c in classes_model]\n",
        "    proba_df = pd.DataFrame(y_proba, columns=cols)\n",
        "    for c in [\"A\",\"D\",\"H\"]:\n",
        "        if c not in proba_df.columns:\n",
        "            proba_df[c] = np.nan\n",
        "    return proba_df[[\"A\",\"D\",\"H\"]]\n",
        "\n",
        "def _prep_test_split_flex(df, train_until_season, with_odds, test_until_season):\n",
        "    \"\"\"Envuelve tu _prep_test_split y devuelve siempre (X_test, y_test, idx_test).\"\"\"\n",
        "    out = _prep_test_split(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if not isinstance(out, tuple):\n",
        "        raise ValueError(\"Respuesta inesperada de _prep_test_split.\")\n",
        "    if len(out) == 3:\n",
        "        X_test, y_test, idx_test = out\n",
        "    elif len(out) == 2:\n",
        "        X_test, y_test = out\n",
        "        idx_test = X_test.index\n",
        "    else:\n",
        "        raise ValueError(\"Respuesta inesperada de _prep_test_split (ni 2 ni 3 elementos).\")\n",
        "    return X_test, y_test, idx_test\n",
        "\n",
        "def build_cumprofit_series_one_season(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    *, train_until_season: int,\n",
        "    test_until_season: int | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3\n",
        ") -> tuple[pd.DataFrame, dict]:\n",
        "\n",
        "    # 1) TEST (flex)\n",
        "    X_test, y_test, idx = _prep_test_split_flex(\n",
        "        df, train_until_season=train_until_season,\n",
        "        with_odds=with_odds, test_until_season=test_until_season\n",
        "    )\n",
        "    if len(X_test) == 0:\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # 2) Alinear + predecir modelo\n",
        "    X_test = _align_to_fit_columns(X_test, scaler)\n",
        "    Xs   = scaler.transform(X_test)\n",
        "    yhat = model.predict(Xs)\n",
        "    proba = model.predict_proba(Xs)\n",
        "    classes_used = getattr(model, \"classes_\", np.array([0,1,2]))\n",
        "\n",
        "    # 3) Meta y cuotas\n",
        "    need = [\"Date\",\"Season\",\"HomeTeam_norm\",\"AwayTeam_norm\",\"B365H\",\"B365D\",\"B365A\"]\n",
        "    miss = [c for c in need if c not in df.columns]\n",
        "    if miss:\n",
        "        raise ValueError(f\"df necesita columnas {miss}\")\n",
        "    meta = df.loc[idx, need].copy()\n",
        "\n",
        "    mask_ok = meta[[\"B365H\",\"B365D\",\"B365A\"]].notna().all(axis=1)\n",
        "    for c in [\"B365H\",\"B365D\",\"B365A\"]:\n",
        "        mask_ok &= (pd.to_numeric(meta[c], errors=\"coerce\") > 0)\n",
        "    if not mask_ok.any():\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    meta   = meta.loc[mask_ok].copy()\n",
        "    y_test = y_test.loc[mask_ok]\n",
        "    # re-alinear pred y proba a las filas válidas\n",
        "    yhat   = pd.Series(yhat, index=idx).loc[mask_ok].to_numpy()\n",
        "    proba  = proba[mask_ok.values, :]\n",
        "\n",
        "    # 4) Prob implícitas Bet365 normalizadas y predicción Bet365\n",
        "    odds = meta[[\"B365H\",\"B365D\",\"B365A\"]].astype(float)\n",
        "    inv  = 1.0 / odds\n",
        "    over = inv.sum(axis=1).replace(0, np.nan)\n",
        "    pnorm = inv.div(over, axis=0)\n",
        "    bet365_proba_mat = np.column_stack([\n",
        "        pnorm[\"B365A\"].to_numpy(),  # Away -> 0\n",
        "        pnorm[\"B365D\"].to_numpy(),  # Draw -> 1\n",
        "        pnorm[\"B365H\"].to_numpy(),  # Home -> 2\n",
        "    ])\n",
        "    bet365_pred = bet365_proba_mat.argmax(axis=1)\n",
        "\n",
        "    # 5) Retornos por partido y acumulados (stake=1)\n",
        "    odds_matrix = np.column_stack([odds[\"B365A\"], odds[\"B365D\"], odds[\"B365H\"]])  # A,D,H\n",
        "    idx_map = {0:0,1:1,2:2}\n",
        "    idx_model  = pd.Series(yhat).map(idx_map).to_numpy()\n",
        "    idx_b365   = pd.Series(bet365_pred).map(idx_map).to_numpy()\n",
        "\n",
        "    model_ret = np.where(yhat == y_test.values, odds_matrix[np.arange(len(yhat)), idx_model]-1.0, -1.0)\n",
        "    b365_ret  = np.where(bet365_pred == y_test.values, odds_matrix[np.arange(len(yhat)), idx_b365]-1.0, -1.0)\n",
        "\n",
        "    # 6) Orden temporal y acumulados\n",
        "    dates = pd.to_datetime(meta[\"Date\"], errors=\"coerce\")\n",
        "    order = np.argsort(dates.fillna(pd.Timestamp(\"1970-01-01\")).values)\n",
        "    dates = dates.iloc[order].dt.strftime(\"%Y-%m-%d\").reset_index(drop=True)\n",
        "\n",
        "    model_ret = pd.Series(model_ret).iloc[order].reset_index(drop=True).round(round_decimals)\n",
        "    b365_ret  = pd.Series(b365_ret ).iloc[order].reset_index(drop=True).round(round_decimals)\n",
        "    model_cum = model_ret.cumsum().round(round_decimals)\n",
        "    b365_cum  = b365_ret.cumsum().round(round_decimals)\n",
        "\n",
        "    home = meta[\"HomeTeam_norm\"].iloc[order].astype(\"string\").reset_index(drop=True)\n",
        "    away = meta[\"AwayTeam_norm\"].iloc[order].astype(\"string\").reset_index(drop=True)\n",
        "    true_txt  = pd.Series(y_test.values).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "    model_txt = pd.Series(yhat).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "    b365_txt  = pd.Series(bet365_pred).iloc[order].map(CLASS2LABEL).reset_index(drop=True)\n",
        "\n",
        "    series_df = pd.DataFrame({\n",
        "        \"match_num\": np.arange(1, len(model_cum)+1, dtype=int),\n",
        "        \"date\": dates,\n",
        "        \"model_cum\": model_cum,\n",
        "        \"bet365_cum\": b365_cum,\n",
        "        \"model_ret\": model_ret,\n",
        "        \"bet365_ret\": b365_ret,\n",
        "        \"home\": home,\n",
        "        \"away\": away,\n",
        "        \"true_txt\": true_txt,\n",
        "        \"model_txt\": model_txt,\n",
        "        \"bet365_txt\": b365_txt,\n",
        "    })\n",
        "\n",
        "    n = int(len(series_df))\n",
        "    final_model = float(model_cum.iloc[-1]) if n else 0.0\n",
        "    final_b365  = float(b365_cum.iloc[-1]) if n else 0.0\n",
        "    summary = {\n",
        "        \"train_until\": int(train_until_season),\n",
        "        \"test_season\": int(test_until_season if test_until_season is not None else df.loc[idx, \"Season\"].max()),\n",
        "        \"n_matches\": n,\n",
        "        \"profit_model\": final_model,\n",
        "        \"profit_bet365\": final_b365,\n",
        "        \"roi_model\": (final_model / n) if n else np.nan,\n",
        "        \"roi_bet365\": (final_b365 / n) if n else np.nan,\n",
        "    }\n",
        "    return series_df, summary\n",
        "\n",
        "def export_cumprofit_curves_for_streamlit(\n",
        "    df: pd.DataFrame,\n",
        "    model, scaler,\n",
        "    out_dir: Path,\n",
        "    *, seasons: list[int] | None = None,\n",
        "    with_odds: bool = True,\n",
        "    stake: float = 1.0,\n",
        "    round_decimals: int = 3\n",
        "):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    curves_dir = out_dir / \"cumprofit_curves\"\n",
        "    curves_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    seasons_all = sorted(df[\"Season\"].dropna().astype(int).unique())\n",
        "    if seasons is None:\n",
        "        seasons = seasons_all\n",
        "\n",
        "    index_rows = []\n",
        "    for season in seasons:\n",
        "        train_until = season - 1\n",
        "        if train_until < seasons_all[0]:\n",
        "            continue\n",
        "\n",
        "        series_df, summary = build_cumprofit_series_one_season(\n",
        "            df, model, scaler,\n",
        "            train_until_season=train_until,\n",
        "            test_until_season=season,\n",
        "            with_odds=with_odds,\n",
        "            stake=stake,\n",
        "            round_decimals=round_decimals\n",
        "        )\n",
        "        if series_df.empty:\n",
        "            continue\n",
        "\n",
        "        # CSV\n",
        "        csv_path = curves_dir / f\"cumprofit_{season}.csv\"\n",
        "        series_df.to_csv(csv_path, index=False)\n",
        "\n",
        "        # JSON compacto\n",
        "        payload = {\n",
        "            \"train_until\": summary[\"train_until\"],\n",
        "            \"test_season\": summary[\"test_season\"],\n",
        "            \"n_matches\": summary[\"n_matches\"],\n",
        "            \"series\": [\n",
        "                {\n",
        "                    \"i\": int(r.match_num),\n",
        "                    \"d\": str(r.date),\n",
        "                    \"m\": float(r.model_cum),\n",
        "                    \"b\": float(r.bet365_cum),\n",
        "                    \"hm\": str(r.home),\n",
        "                    \"aw\": str(r.away),\n",
        "                    \"t\":  str(r.true_txt),\n",
        "                    \"pm\": str(r.model_txt),\n",
        "                    \"pb\": str(r.bet365_txt),\n",
        "                } for _, r in series_df.iterrows()\n",
        "            ],\n",
        "            \"final\": {\n",
        "                \"model\": float(summary[\"profit_model\"]),\n",
        "                \"bet365\": float(summary[\"profit_bet365\"]),\n",
        "                \"roi_model\": float(summary[\"roi_model\"]),\n",
        "                \"roi_bet365\": float(summary[\"roi_bet365\"]),\n",
        "            }\n",
        "        }\n",
        "        (curves_dir / f\"cumprofit_{season}.json\").write_text(\n",
        "            json.dumps(payload, ensure_ascii=False), encoding=\"utf-8\"\n",
        "        )\n",
        "\n",
        "        index_rows.append({\n",
        "            \"test_season\": int(season),\n",
        "            \"train_until\": int(train_until),\n",
        "            \"n_matches\": int(summary[\"n_matches\"]),\n",
        "            \"profit_model\": float(summary[\"profit_model\"]),\n",
        "            \"profit_bet365\": float(summary[\"profit_bet365\"]),\n",
        "            \"roi_model\": float(summary[\"roi_model\"]),\n",
        "            \"roi_bet365\": float(summary[\"roi_bet365\"]),\n",
        "            \"csv_file\": f\"cumprofit_{season}.csv\",\n",
        "            \"json_file\": f\"cumprofit_{season}.json\",\n",
        "        })\n",
        "        print(f\"[CURVA] Season {season}: {len(series_df)} puntos → guardado CSV/JSON.\")\n",
        "\n",
        "    if index_rows:\n",
        "        idx_df = pd.DataFrame(index_rows).sort_values(\"test_season\")\n",
        "        idx_df.to_csv(out_dir / \"cumprofit_index.csv\", index=False)\n",
        "        (out_dir / \"cumprofit_index.json\").write_text(\n",
        "            json.dumps(index_rows, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
        "        )\n",
        "        print(\"Guardados:\\n-\", out_dir / \"cumprofit_index.csv\",\n",
        "              \"\\n-\", out_dir / \"cumprofit_index.json\",\n",
        "              f\"\\n- {curves_dir}/cumprofit_<SEASON>.csv / .json\")\n",
        "    else:\n",
        "        print(\"No se generaron curvas (no hubo TEST válido con cuotas).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYev8_lXX1Sc",
        "outputId": "b6a0ea22-9ebb-4f1f-98c7-51c001fed5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CURVA] Season 2007: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2008: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2009: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2010: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2011: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2012: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2013: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2014: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2015: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2016: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2017: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2018: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2019: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2020: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2021: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2022: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2023: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2024: 380 puntos → guardado CSV/JSON.\n",
            "[CURVA] Season 2025: 41 puntos → guardado CSV/JSON.\n",
            "Guardados:\n",
            "- outputs/cumprofit_index.csv \n",
            "- outputs/cumprofit_index.json \n",
            "- outputs/cumprofit_curves/cumprofit_<SEASON>.csv / .json\n"
          ]
        }
      ],
      "source": [
        "# OUT = ROOT / \"outputs\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "export_cumprofit_curves_for_streamlit(\n",
        "    df=df,\n",
        "    model=model,\n",
        "    scaler=scaler,\n",
        "    out_dir=OUT,\n",
        "    seasons=None,\n",
        "    with_odds=True,\n",
        "    stake=1.0,\n",
        "    round_decimals=3\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ny_spsZP25IM",
        "u-LZWUpHKgiI",
        "_AUraRaeqPH_",
        "LKjn9DwWtgyl",
        "DmmpBR0ity_a",
        "pp0H3HmVus9U",
        "tpTI1gP6z03D",
        "CoH2Hx_s2EqC",
        "F3OYzHaq3CeB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}